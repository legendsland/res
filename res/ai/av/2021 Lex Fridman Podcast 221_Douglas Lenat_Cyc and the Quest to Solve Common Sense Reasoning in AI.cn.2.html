<!DOCTYPE html><html class="translated-ltr" style=""><!--
 Page saved with SingleFile 
 url: file:///home/zy/ws/res/res/ai/av/2021%20Lex%20Fridman%20Podcast%20221_Douglas%20Lenat_Cyc%20and%20the%20Quest%20to%20Solve%20Common%20Sense%20Reasoning%20in%20AI.html 
 saved date: Wed Apr 02 2025 21:09:16 GMT+0800 (Hong Kong Standard Time)
--><head>
<meta name="dc.identifier" content="res/01cd5e76841c7a5c15a002e5b399c0247799a222">
<meta charset="utf-8">
    
    <title>2021 Lex Fridman 播客 221_Douglas Lenat_Cyc 和解决人工智能常识推理的探索</title>
<style>.VIpgJd-ZVi9od-ORHb-OEVmcd{left:0;top:0;height:39px;width:100%;z-index:10000001;position:fixed;border:none;border-bottom:1px solid #6B90DA;margin:0;box-shadow:0 0 8px 1px #999}.VIpgJd-ZVi9od-xl07Ob-OEVmcd{z-index:10000002;border:none;position:fixed;box-shadow:0 3px 8px 2px #999}.VIpgJd-ZVi9od-SmfZ-OEVmcd{z-index:10000000;border:none;margin:0}.goog-te-gadget{font-family:arial;font-size:11px;color:#666;white-space:nowrap}.goog-te-gadget img{vertical-align:middle;border:none}.goog-te-gadget-simple{background-color:#FFF;border-left:1px solid #D5D5D5;border-top:1px solid #9B9B9B;border-bottom:1px solid #E8E8E8;border-right:1px solid #D5D5D5;font-size:10pt;display:inline-block;padding-top:1px;padding-bottom:2px;cursor:pointer}.goog-te-gadget-icon{margin-left:2px;margin-right:2px;width:19px;height:19px;border:none;vertical-align:middle}.goog-te-combo{margin-left:4px;margin-right:4px;vertical-align:baseline}.goog-te-gadget .goog-te-combo{margin:4px 0}.VIpgJd-ZVi9od-l4eHX-hSRGPd,.VIpgJd-ZVi9od-l4eHX-hSRGPd:link,.VIpgJd-ZVi9od-l4eHX-hSRGPd:visited,.VIpgJd-ZVi9od-l4eHX-hSRGPd:hover,.VIpgJd-ZVi9od-l4eHX-hSRGPd:active{font-size:12px;font-weight:bold;color:#444;text-decoration:none}.VIpgJd-ZVi9od-ORHb .VIpgJd-ZVi9od-l4eHX-hSRGPd,.VIpgJd-ZVi9od-TvD9Pc-hSRGPd{display:block;margin:0 10px}.VIpgJd-ZVi9od-ORHb .VIpgJd-ZVi9od-l4eHX-hSRGPd{padding-top:2px;padding-left:4px}.goog-te-combo,.VIpgJd-ZVi9od-ORHb *,.VIpgJd-ZVi9od-SmfZ *,.VIpgJd-ZVi9od-xl07Ob *,.VIpgJd-ZVi9od-vH1Gmf *,.VIpgJd-ZVi9od-l9xktf *{font-family:arial;font-size:10pt}.VIpgJd-ZVi9od-ORHb{margin:0;background-color:#E4EFFB;overflow:hidden}.VIpgJd-ZVi9od-ORHb img{border:none}.VIpgJd-ZVi9od-ORHb-bN97Pc{color:#000}.VIpgJd-ZVi9od-ORHb-bN97Pc img{vertical-align:middle}.VIpgJd-ZVi9od-ORHb-Tswv1b{color:#666;vertical-align:top;margin-top:0;font-size:7pt}.VIpgJd-ZVi9od-ORHb-KE6vqe{width:8px}.VIpgJd-ZVi9od-LgbsSe{border-color:#E7E7E7;border-style:none solid solid none;border-width:0 1px 1px 0}.VIpgJd-ZVi9od-LgbsSe div{border-color:#CCC #999 #999 #CCC;border-right:1px solid #999;border-style:solid;border-width:1px;height:20px}.VIpgJd-ZVi9od-LgbsSe button{background:transparent;border:none;cursor:pointer;height:20px;overflow:hidden;margin:0;vertical-align:top;white-space:nowrap}.VIpgJd-ZVi9od-LgbsSe button:active{background:none repeat scroll 0 0#CCC}.VIpgJd-ZVi9od-SmfZ{margin:0;background-color:#FFF;white-space:nowrap}.VIpgJd-ZVi9od-SmfZ-hSRGPd{text-decoration:none;font-weight:bold;font-size:10pt;border:1px outset #888;padding:6px 10px;white-space:nowrap;position:absolute;left:0;top:0}.VIpgJd-ZVi9od-SmfZ-hSRGPd img{margin-left:2px;margin-right:2px;width:19px;height:19px;border:none;vertical-align:middle}.VIpgJd-ZVi9od-SmfZ-hSRGPd span{text-decoration:underline;margin-left:2px;margin-right:2px;vertical-align:middle}.goog-te-float-top .VIpgJd-ZVi9od-SmfZ-hSRGPd{padding:2px;border-top-width:0}.goog-te-float-bottom .VIpgJd-ZVi9od-SmfZ-hSRGPd{padding:2px;border-bottom-width:0}.VIpgJd-ZVi9od-xl07Ob-lTBxed{text-decoration:none;color:#00C;white-space:nowrap;margin-left:4px;margin-right:4px}.VIpgJd-ZVi9od-xl07Ob-lTBxed span{text-decoration:underline}.VIpgJd-ZVi9od-xl07Ob-lTBxed img{margin-left:2px;margin-right:2px}.goog-te-gadget-simple .VIpgJd-ZVi9od-xl07Ob-lTBxed{color:#000}.goog-te-gadget-simple .VIpgJd-ZVi9od-xl07Ob-lTBxed span{text-decoration:none}.VIpgJd-ZVi9od-xl07Ob{background-color:#FFF;text-decoration:none;border:2px solid #C3D9FF;overflow-y:scroll;overflow-x:hidden;position:absolute;left:0;top:0}.VIpgJd-ZVi9od-xl07Ob-ibnC6b{padding:3px;text-decoration:none}.VIpgJd-ZVi9od-xl07Ob-ibnC6b,.VIpgJd-ZVi9od-xl07Ob-ibnC6b:link{color:#00C;background:#FFF}.VIpgJd-ZVi9od-xl07Ob-ibnC6b:visited{color:#551A8B}.VIpgJd-ZVi9od-xl07Ob-ibnC6b:hover{background:#C3D9FF}.VIpgJd-ZVi9od-xl07Ob-ibnC6b:active{color:#00C}.VIpgJd-ZVi9od-vH1Gmf{background-color:#FFF;text-decoration:none;border:1px solid #6B90DA;overflow:hidden;padding:4px}.VIpgJd-ZVi9od-vH1Gmf-KrhPNb{width:16px}.VIpgJd-ZVi9od-vH1Gmf-hgDUwe{margin:6px 0;height:1px;background-color:#aaa;overflow:hidden}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd div{padding:4px}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b .uDEFge{display:none}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd .uDEFge{display:auto}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd .fmcmS{padding-left:4px;padding-right:4px}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd{text-decoration:none}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b:link div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b:visited div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b:active div{color:#00C;background:#FFF}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b:hover div{color:#FFF;background:#36C}.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd:link div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd:visited div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd:hover div,.VIpgJd-ZVi9od-vH1Gmf-ibnC6b-gk6SMd:active div{color:#000;font-weight:bold}.VIpgJd-ZVi9od-l9xktf{background-color:#FFF;overflow:hidden;padding:8px;border:none;border-radius:10px}.VIpgJd-ZVi9od-l9xktf-OEVmcd{background-color:#FFF;border:1px solid #6B90DA;box-shadow:0 3px 8px 2px #999;border-radius:8px}.VIpgJd-ZVi9od-l9xktf img{border:none}.VIpgJd-ZVi9od-l9xktf-fmcmS{margin-top:6px}.VIpgJd-ZVi9od-l9xktf-VgwJlc{margin-top:6px;white-space:nowrap}.VIpgJd-ZVi9od-l9xktf-VgwJlc *{vertical-align:middle}.VIpgJd-ZVi9od-l9xktf-VgwJlc .DUGJie{background-image:url(data:,)}.VIpgJd-ZVi9od-l9xktf-VgwJlc .TdyTDe{background-image:url(data:,)}.VIpgJd-ZVi9od-l9xktf-VgwJlc span{color:#00C;text-decoration:underline;cursor:pointer;margin:0 4px}.VIpgJd-ZVi9od-l9xktf-I9GLp{margin:6px 0 0}.VIpgJd-ZVi9od-l9xktf-I9GLp form{margin:0}.VIpgJd-ZVi9od-l9xktf-I9GLp form textarea{margin-bottom:4px;width:100%}.VIpgJd-ZVi9od-l9xktf-yePe5c{margin:6px 0 4px}.VIpgJd-ZVi9od-aZ2wEe-wOHMyf{z-index:1000;position:fixed;-webkit-transition-delay:.6s;transition-delay:.6s;left:-1000px;top:-1000px}.VIpgJd-ZVi9od-aZ2wEe-wOHMyf-ti6hGc{-webkit-transition-delay:0s;transition-delay:0s;left:-14px;top:-14px}.VIpgJd-ZVi9od-aZ2wEe-OiiCO{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-box-align:center;-webkit-align-items:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;justify-content:center;width:104px;height:104px;border-radius:50px;background:#FFF url(data:image/png;base64,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)50% 50%no-repeat;-webkit-transition:all .6s ease-in-out;transition:all .6s ease-in-out;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}.VIpgJd-ZVi9od-aZ2wEe-OiiCO-ti6hGc{-webkit-transform:scale(.5);transform:scale(.5);opacity:1}.VIpgJd-ZVi9od-aZ2wEe{margin:2px 0 0 2px;-webkit-animation:spinner-rotator 1.4s linear infinite;animation:spinner-rotator 1.4s linear infinite}@-webkit-keyframes spinner-rotator{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}100%{-webkit-transform:rotate(270deg);transform:rotate(270deg)}}@keyframes spinner-rotator{0%{-webkit-transform:rotate(0deg);transform:rotate(0deg)}100%{-webkit-transform:rotate(270deg);transform:rotate(270deg)}}.VIpgJd-ZVi9od-aZ2wEe-Jt5cK{stroke-dasharray:187;stroke-dashoffset:0;stroke:#4285F4;-webkit-transform-origin:center;transform-origin:center;-webkit-animation:spinner-dash 1.4s ease-in-out infinite;animation:spinner-dash 1.4s ease-in-out infinite}@-webkit-keyframes spinner-dash{0%{stroke-dashoffset:187}50%{stroke-dashoffset:46.75;-webkit-transform:rotate(135deg);transform:rotate(135deg)}100%{stroke-dashoffset:187;-webkit-transform:rotate(450deg);transform:rotate(450deg)}}@keyframes spinner-dash{0%{stroke-dashoffset:187}50%{stroke-dashoffset:46.75;-webkit-transform:rotate(135deg);transform:rotate(135deg)}100%{stroke-dashoffset:187;-webkit-transform:rotate(450deg);transform:rotate(450deg)}}.VIpgJd-yAWNEb-L7lbkb html,.VIpgJd-yAWNEb-L7lbkb body,.VIpgJd-yAWNEb-L7lbkb div,.VIpgJd-yAWNEb-L7lbkb span,.VIpgJd-yAWNEb-L7lbkb iframe,.VIpgJd-yAWNEb-L7lbkb h1,.VIpgJd-yAWNEb-L7lbkb h2,.VIpgJd-yAWNEb-L7lbkb h3,.VIpgJd-yAWNEb-L7lbkb h4,.VIpgJd-yAWNEb-L7lbkb h5,.VIpgJd-yAWNEb-L7lbkb h6,.VIpgJd-yAWNEb-L7lbkb p,.VIpgJd-yAWNEb-L7lbkb a,.VIpgJd-yAWNEb-L7lbkb img,.VIpgJd-yAWNEb-L7lbkb ol,.VIpgJd-yAWNEb-L7lbkb ul,.VIpgJd-yAWNEb-L7lbkb li,.VIpgJd-yAWNEb-L7lbkb table,.VIpgJd-yAWNEb-L7lbkb form,.VIpgJd-yAWNEb-L7lbkb tbody,.VIpgJd-yAWNEb-L7lbkb tr,.VIpgJd-yAWNEb-L7lbkb td{margin:0;padding:0;border:0;font:inherit;font-size:100%;vertical-align:baseline;text-align:left;line-height:normal}.VIpgJd-yAWNEb-L7lbkb ol,.VIpgJd-yAWNEb-L7lbkb ul{list-style:none}.VIpgJd-yAWNEb-L7lbkb table{border-collapse:collapse;border-spacing:0}.VIpgJd-yAWNEb-L7lbkb caption,.VIpgJd-yAWNEb-L7lbkb th,.VIpgJd-yAWNEb-L7lbkb td{text-align:left;font-weight:normal}.VIpgJd-yAWNEb-L7lbkb input::-moz-focus-inner{border:0}div>.VIpgJd-yAWNEb-L7lbkb{padding:10px 14px}.VIpgJd-yAWNEb-L7lbkb{color:#222;background-color:#fff;border:1px solid #eee;box-shadow:0 4px 16px rgba(0,0,0,.2);-moz-box-shadow:0 4px 16px rgba(0,0,0,.2);-webkit-box-shadow:0 4px 16px rgba(0,0,0,.2);display:none;font-family:arial;font-size:10pt;width:420px;padding:12px;position:absolute;z-index:10000}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-nVMfcd-fmcmS,.VIpgJd-yAWNEb-yAWNEb-Vy2Aqc-pbTTYe{clear:both;font-size:10pt;position:relative;text-align:justify;width:100%}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-r4nke{color:#999;font-family:arial,sans-serif;margin:4px 0;text-align:left}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TvD9Pc-LgbsSe{display:none}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-l4eHX{float:left;margin:0}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-Z0Arqf-PLDbbf{display:inline-block}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-fw42Ze-Z0Arqf-haAclf{display:none;width:100%}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-Z0Arqf-H9tDt{margin-top:20px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-LK5yu{float:left}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-qwU8Me{float:right}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-cGMI2b{min-height:15px;position:relative;height:1%}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-jOfkMb-Ne3sFf{background:-webkit-linear-gradient(top,#29910d 0,#20af0e 100%);background:-webkit-gradient(linear,left top,left bottom,from(#29910d),to(#20af0e));background:linear-gradient(top,#29910d 0,#20af0e 100%);background:#29910d;border-radius:4px;-moz-border-radius:4px;-webkit-border-radius:4px;box-shadow:inset 0 2px 2px #1e6609;-moz-box-shadow:inset 0 2px 2px #1e6609;-webkit-box-shadow:inset 0 2px 2px #1e6609;color:white;font-size:9pt;font-weight:bolder;margin-top:12px;padding:6px;text-shadow:1px 1px 1px #1e6609}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-Z0Arqf-hSRGPd{color:#15c;cursor:pointer;font-family:arial;font-size:11px;margin-right:15px;text-decoration:none}.VIpgJd-yAWNEb-L7lbkb>textarea{font-family:arial;resize:vertical;width:100%;margin-bottom:10px;border-radius:1px;border:1px solid #d9d9d9;border-top:1px solid silver;font-size:13px;height:auto;overflow-y:auto;padding:1px}.VIpgJd-yAWNEb-L7lbkb textarea:focus{box-shadow:inset 0 1px 2px rgba(0,0,0,.3);border:1px solid #4d90fe;outline:none}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-Z0Arqf-IbE0S{margin-right:10px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp{min-height:25px;vertical-align:middle;padding-top:8px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp{margin-bottom:5px;margin-bottom:0}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input{display:inline-block;min-width:54px;*min-width:70px;border:1px solid #dcdcdc;border:1px solid rgba(0,0,0,.1);text-align:center;color:#444;font-size:11px;font-weight:bold;height:27px;outline:0;padding:0 8px;vertical-align:middle;line-height:27px;margin:0 16px 0 0;box-shadow:0 1px 2px rgba(0,0,0,.1);-moz-box-shadow:0 1px 2px rgba(0,0,0,.1);-webkit-box-shadow:0 1px 2px rgba(0,0,0,.1);border-radius:2px;-webkit-transition:all .218s;transition:all .218s;background-color:#f5f5f5;background-image:-webkit-gradient(linear,left top,left bottom,from(#f5f5f5),to(#f1f1f1));background-image:-webkit-linear-gradient(top,#f5f5f5,#f1f1f1);background-image:linear-gradient(top,#f5f5f5,#f1f1f1);-webkit-user-select:none;-moz-user-select:none;cursor:default}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:hover{border:1px solid #c6c6c6;color:#222;-webkit-transition:all 0s;transition:all 0s;background-color:#f8f8f8;background-image:-webkit-gradient(linear,left top,left bottom,from(#f8f8f8),to(#f1f1f1));background-image:-webkit-linear-gradient(top,#f8f8f8,#f1f1f1);background-image:linear-gradient(top,#f8f8f8,#f1f1f1)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:active{border:1px solid #c6c6c6;color:#333;background-color:#f6f6f6;background-image:-webkit-gradient(linear,left top,left bottom,from(#f6f6f6),to(#f1f1f1));background-image:-webkit-linear-gradient(top,#f6f6f6,#f1f1f1);background-image:linear-gradient(top,#f6f6f6,#f1f1f1)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:focus .VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input.AHmuwe .VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:active,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:focus:active{box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);-webkit-box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);-moz-box-shadow:inset 0 0 0 1px rgba(255,255,255,.5)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:focus,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input.AHmuwe{outline:none;border:1px solid #4d90fe;z-index:4!important}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input.gk6SMd{background-color:#eee;background-image:-webkit-gradient(linear,left top,left bottom,from(#eee),to(#e0e0e0));background-image:-webkit-linear-gradient(top,#eee,#e0e0e0);background-image:linear-gradient(top,#eee,#e0e0e0);box-shadow:inset 0 1px 2px rgba(0,0,0,.1);border:1px solid #ccc;color:#333}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf{color:white;border-color:#3079ed;background-color:#4d90fe;background-image:-webkit-gradient(linear,left top,left bottom,from(#4d90fe),to(#4787ed));background-image:-webkit-linear-gradient(top,#4d90fe,#4787ed);background-image:linear-gradient(top,#4d90fe,#4787ed)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:hover .VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:focus,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf.AHmuwe .VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:active{border-color:#3079ed;background-color:#357ae8;background-image:-webkit-gradient(linear,left top,left bottom,from(#4d90fe),to(#357ae8));background-image:-webkit-linear-gradient(top,#4d90fe,#357ae8);background-image:linear-gradient(top,#4d90fe,#357ae8)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:hover{box-shadow:inset 0 0 0 1px #fff,0 1px 1px rgba(0,0,0,.1);-webkit-box-shadow:inset 0 0 0 1px #fff,0 1px 1px rgba(0,0,0,.1);-moz-box-shadow:inset 0 0 0 1px #fff,0 1px 1px rgba(0,0,0,.1)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:focus,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input.AHmuwe,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:active,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input:hover,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:focus,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf.AHmuwe,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:active,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-L4Nn5e-I9GLp .VIpgJd-yAWNEb-Z0Arqf-I9GLp input .VIpgJd-yAWNEb-Z0Arqf-sFeBqf:hover{border-color:#3079ed}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-mrxPge{color:#999;font-family:arial,sans-serif}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-W0vJo-fmcmS{color:#999;font-size:11px;font-family:arial,sans-serif;margin:15px 0 5px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-u0pjoe-fmcmS{color:#800;display:none;font-size:9pt}.VIpgJd-yAWNEb-VIpgJd-fmcmS-sn54Q{background-color:#c9d7f1;box-shadow:2px 2px 4px #99a;box-sizing:border-box;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;position:relative}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-xl07Ob .VIpgJd-yAWNEb-VIpgJd-xl07Ob{background:#fff;border:1px solid #ddd;box-shadow:0 2px 4px #99a;min-width:0;outline:none;padding:0;position:absolute;z-index:2000}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-xl07Ob .VIpgJd-yAWNEb-VIpgJd-j7LFlb{cursor:pointer;padding:2px 5px 5px;margin-right:0;border-style:none}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-xl07Ob .VIpgJd-yAWNEb-VIpgJd-j7LFlb:hover{background:#ddd}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-xl07Ob .VIpgJd-yAWNEb-VIpgJd-j7LFlb h1{font-size:100%;font-weight:bold;margin:4px 0}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-xl07Ob .VIpgJd-yAWNEb-VIpgJd-j7LFlb strong{color:#345aad}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-VIpgJd-eKm5Fc-hFsbo{text-align:right;position:absolute;right:0;left:auto}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-VIpgJd-j7LFlb-SIsrTd .VIpgJd-yAWNEb-VIpgJd-eKm5Fc-hFsbo{text-align:left;position:absolute;left:0;right:auto}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-yAWNEb-Vy2Aqc-fmcmS,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TVLw9c-ppHlrf-sn54Q{background-color:#f1ea00;border-radius:4px;-webkit-border-radius:4px;-moz-border-radius:4px;box-shadow:rgba(0,0,0,.5) 3px 3px 4px;box-sizing:border-box;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;color:#f1ea00;cursor:pointer;margin:-2px -2px -2px -3px;padding:2px 2px 2px 3px;position:relative}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TVLw9c-ppHlrf-sn54Q{color:#222}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-yAWNEb-Vy2Aqc-pbTTYe{color:white;position:absolute!important}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TVLw9c-ppHlrf,.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TVLw9c-ppHlrf .VIpgJd-yAWNEb-TVLw9c-ppHlrf-sn54Q{background-color:#c9d7f1;border-radius:4px 4px 0 0;-webkit-border-radius:4px 4px 0 0;-moz-border-radius:4px 4px 0 0;box-shadow:rgba(0,0,0,.5) 3px 3px 4px;box-sizing:border-box;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;cursor:pointer;margin:-2px -2px -2px -3px;padding:2px 2px 3px 3px;position:relative}.VIpgJd-yAWNEb-L7lbkb span:focus{outline:none}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-TVLw9c-DyVDA{background-color:transparent;border:1px solid #4d90fe;border-radius:0;-webkit-border-radius:0;-moz-border-radius:0;margin:-2px;padding:1px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-yAWNEb-TVLw9c-sn54Q-LzX3ef{border-left:2px solid red;margin-left:-2px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-yAWNEb-TVLw9c-sn54Q-YIAiIb{border-right:2px solid red;margin-right:-2px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-YPqjbf{padding:2px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-YPqjbf-fmcmS{font-size:11px;padding:2px 2px 3px;margin:0;background-color:#fff;color:#333;border:1px solid #d9d9d9;border-top:1px solid #c0c0c0;display:inline-block;vertical-align:top;height:21px;box-sizing:border-box;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;-webkit-border-radius:1px}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-YPqjbf-fmcmS:hover{border:1px solid #b9b9b9;border-top:1px solid #a0a0a0;box-shadow:inset 0 1px 2px rgba(0,0,0,.1)}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-YPqjbf-fmcmS:focus{box-shadow:inset 0 1px 2px rgba(0,0,0,.3);outline:none;border:1px solid #4d90fe}.VIpgJd-yAWNEb-L7lbkb .VIpgJd-yAWNEb-IFdKyd-YPqjbf-sFeBqf{font-size:11px;padding:2px 6px 3px;margin:0 0 0 2px;height:21px}.VIpgJd-yAWNEb-hvhgNd{font-family:"Google Sans",Arial,sans-serif}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-l4eHX-i3jM8c{position:absolute;top:10px;left:14px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-l4eHX-SIsrTd{position:absolute;top:10px;right:14px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-k77Iif-i3jM8c,.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-k77Iif-SIsrTd{margin:16px;padding:0}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-IuizWc{margin:0 0 0 36px;padding:0;color:#747775;font-size:14px;font-weight:500}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-k77Iif-SIsrTd .VIpgJd-yAWNEb-hvhgNd-IuizWc{text-align:right;margin:0 36px 0 0}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-axAV1{width:auto;padding:12px 0 0;color:#1f1f1f;font-size:16px;text-align:initial}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-axAV1 .VIpgJd-yAWNEb-SIsrTd{text-align:right}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid{border-radius:0 0 12px 12px;margin:0;background:#f1f4f9;position:relative;min-height:50px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid .VIpgJd-yAWNEb-SIsrTd{text-align:right}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid-B7I4Od{display:inline-block;width:77%;padding:12px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid-B7I4Od .VIpgJd-yAWNEb-SIsrTd{text-align:right}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-UTujCb{color:#1f1f1f;font-size:12px;font-weight:500}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid-B7I4Od .VIpgJd-yAWNEb-SIsrTd .VIpgJd-yAWNEb-hvhgNd-UTujCb{text-align:right}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-eO9mKe{color:#444746;font-size:12px;padding-top:4px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-N7Eqid-B7I4Od .VIpgJd-yAWNEb-SIsrTd .VIpgJd-yAWNEb-hvhgNd-eO9mKe{text-align:right}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-xgov5{position:absolute;top:10px;right:5px}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-xgov5 .VIpgJd-yAWNEb-SIsrTd{left:5px;right:auto}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-THI6Vb{fill:#0b57d0}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-bgm6sf{margin:-4px 2px 0 0;padding:2px 0 0;width:48px;height:48px;border:none;border-radius:24px;cursor:pointer;background:none}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-bgm6sf:hover{background:#e8ebec}.VIpgJd-yAWNEb-hvhgNd .VIpgJd-yAWNEb-hvhgNd-aXYTce{display:none}sentinel{}</style><meta name="referrer" content="no-referrer"><link id="res-style" rel="stylesheet" href="/res/dist/res/style.css" type="text/css">
</head>
<body>
    <div id="goog-gt-tt" class="VIpgJd-yAWNEb-L7lbkb skiptranslate" style="border-radius:12px;margin:0 0 0-23px;padding:0;font-family:&quot;Google Sans&quot;,Arial,sans-serif" data-id=""><div id="goog-gt-vt" class="VIpgJd-yAWNEb-hvhgNd"><div class=" VIpgJd-yAWNEb-hvhgNd-l4eHX-i3jM8c"><img src="data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" height="24" viewBox="0 0 24 24" width="24"><path d="M0 0h24v24H0z" fill="none"/><defs><path d="M21.5 5h-9.17L11 1H2.5C1.68 1 1 1.68 1 2.5v15c0 .83.68 1.5 1.5 1.5h9.17L13 23h8.5c.82 0 1.5-.68 1.5-1.5v-15c0-.83-.68-1.5-1.5-1.5z" id="a"/></defs><clipPath id="b"><use overflow="visible" xlink:href="#a"/></clipPath><g clip-path="url(#b)"><image height="31" opacity=".2" overflow="visible" transform="translate(3 1)" width="29" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB0AAAAfCAYAAAAbW8YEAAAACXBIWXMAAAsSAAALEgHS3X78AAAA GXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAABQBJREFUeNq8V8tu20YUvXdm+LCk RKiMwI1TFEXhVZJd1gW66xekv9DPqPsvXdU/UaDroJskKy+CInCcGpKtFy2SM/f2DEXZia0odtKW AkFJ8zhzzn3S0Ycvps+79EMDbj3Yfgv4EM+XTN/fEOb3Zg3AXmq7j64D5/e/x/EfzZMnX5jx+LFZ LLyp6yNDOzskYb6RubFdpbdvKUl2Jc+d9PvP5dmzUyH6TVoYXQOq+H5g9vb+cONsO9maLpIyyZPU kZNAppmh9Vpg5kSXwCSVJ5/Vi/r8Tl73y2F9ePidJ3oaga+B4vkUgF+6EW1ndz11gvNdDdL1bDNr yKkCWO16thyUGWIIeae2ZGvn1of5xFExoGF5eHgM4ANZsW032Tf05MjeW+xmNKeedeWAg9tmywPM 6rGYzOAPBSfQ5Ss0Nf4pAmRrSmBP1ehIxQ6DpxF1aXaSH5X0bDcAR1aOxLRPtPdrZrwnd55Sx3gz IMO72OwBq9kmox0RSkHHRNxrRJWFDbQXKpR1xN4eOfx0NqnMdFHulY/rw/1RAE5crEvvffGCvX/E VUoOC3Mm24eaO6TyNZjeB5E+sDLMt2tCqZEW8lcgPSU2x0IhKlAYoTP4xUTueUMvHvJK3ouQ8ffH HP62JpGeg/VSYciqNADbHQxvY5etdr65yhNXlG2B5xjzgWfHJoSeZ5Olbuaq+czQyYSvxal701dJ SWoigRNqXItjORhsC+x74NfDtPQ6aGPkgAUlGROpTKBQR4gbB1x6fjz3/DK8GsoHj/SVG6pJACi+ NhQdApsQJFPCeliYKImgeEJmylc3Xzw5yp9xnIMYMkZt9HjVhK/GeHtqZI5+KUVJXtSVQcwcYDPo FI93jhW+DWSjzZrGts0NQSwOZTFoMaMBaly6CTFZG2KXUt3Z1aQzC36rKrFJ0cgUb6aZRnuRwjtI lo7Eq3CLWSya4eJ7a+TN2eudvClbk17ItFepoQLrpyQyxkZTjBYIiwqnXwF/1mXerQivtu+Hohp7 tf7cWJnCTgBleCQ3bBEaPiaCTRXkNqBLu955o2kv+NzIIogDkGlAEfuwL51DYh9z3sdK1y1ALyX2 FxJLK3Fj339NYnO16P4fEl8J9HUSaytxTHFRYqrhnJ60AZU2lNpDNOULaZH1FqBXJS4LhN8ECeos MgbLWUx3AK+xv4+ZKN6ACxxlZw0xDzdZKj7Z6E1ALyQ+91WNclwgIU6wwRli7xTkzjA8BQCSBxfL +MUhlnGMDMYlfsPuWsdSF4GZa226io1MW4nzPvkQbWgDnIlGYHSCTU+QbOI9BNtTTB7hxmEIh+FT KDJGZoiVpkA6KmNRj90E0duPNmaNxJ29QVh0RxWsOMNRh0JyDIk7LBK1iw62BV1cLKaXpY2n+HWs GkZidOZEysp3fDK4K3TvK90EisGf6bD/k6CTqDpBZt6EoTWcSXQU5mhX1FvNm/XRiyQiaw0XKmDi EXL9kdV6FMMu9kvpyUDoB3SIB5uYxp2+fSr9P7Na7IOipsUpxZ5BqISNTw1rFy6bGrKoIjAbS9uu EKoT2NowqiWJ7cqM0KD9lT8X2t+lKz3S2l4Z/e4v9ptXzcFyn9Zd8nlHHcjXaNZsaCvKqlW6dWP2 Ibr7sdE2e68H9sy+TvN5J6nwydLUvtuWfmoLugH4Zg34JzbbHwO/wavG+68VdJPXihuC/zcvUJ+0 0W2ufwQYAGHKK2CFMIrzAAAAAElFTkSuQmCC"/><radialGradient cx="7.394" cy="5.437" gradientUnits="userSpaceOnUse" id="c" r="23.416"><stop offset="0" stop-color="#EEE"/><stop offset=".432" stop-color="#E6E6E6"/><stop offset="1" stop-color="#E1E1E1"/></radialGradient><path d="M13 23h8.5c.82 0 1.5-.68 1.5-1.5v-15c0-.83-.68-1.5-1.5-1.5H7l6 18z" fill="url(#c)"/></g><path clip-path="url(#b)" d="M18 11v-1h-1v1h-3.75v1h5.32c-.2.49-.6 1.3-1.32 2.14-.51-.6-.86-1.18-1.1-1.64h-1.11c.36.84.9 1.66 1.52 2.38l-2.6 2.58.71.71 2.58-2.58 2.58 2.58.71-.71-2.6-2.58c.74-.86 1.33-1.85 1.68-2.88H21v-1h-3z" fill="#607D8B"/><linearGradient gradientUnits="userSpaceOnUse" id="d" x1="12.333" x2="23" y1="14" y2="14"><stop offset="0" stop-color="#212121" stop-opacity=".1"/><stop offset="1" stop-color="#212121" stop-opacity=".02"/></linearGradient><path clip-path="url(#b)" d="M12.33 5L23 15.67V23H13" fill="url(#d)"/><g clip-path="url(#b)"><image height="8" opacity=".1" overflow="visible" transform="translate(10.5 17.5)" width="9" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAJCAYAAAALpr0TAAAACXBIWXMAAAsSAAALEgHS3X78AAAA GXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAOFJREFUeNp0UD1LA0EUnLe7JsJh CiFpLVNYaS3411L7Z/InUpgmqRIRLGxEOEVQsoRcbnecu6AGTB4M72vevjdr+DPDf+Nvs3858q7a Fp4oDOZBJ5dJMCVDzJ2T+LYYpeAyTj39UMNXhA00HABXKy89bY6UlqrFoMHm5QK0a/mbXYxSyyZm eCBTe5Kr68+NGq+Kv4QzoSM8q3ZP8imjXjdEv/6Ysnd+q6a7UN4XFsKYlifbUJXvj3ftytAqM1vJ z6UgGvgiIbN90g8RVddFKZ/pzqX+Y5NDtdonHTI71vgWYADzWmdx/4fpmQAAAABJRU5ErkJggg=="/><path d="M17 19l-4 4-1.33-4" fill="#3F51B5"/></g><path clip-path="url(#b)" d="M21.5 5H7l.04.12H21.5c.82 0 1.5.67 1.5 1.5V6.5c0-.83-.68-1.5-1.5-1.5z" fill="#212121" fill-opacity=".02"/><path clip-path="url(#b)" d="M21.5 22.88H13L11.71 19h-.04L13 23h8.5c.82 0 1.5-.68 1.5-1.5v-.12c0 .82-.68 1.5-1.5 1.5z" fill="#212121" fill-opacity=".1"/><path clip-path="url(#b)" d="M12.97 22.91L13 23l4-4h-.12" fill="#1A237E" fill-opacity=".2"/><path clip-path="url(#b)" d="M11.67 19.12h5.21L17 19h-5.33" fill="#1A237E" fill-opacity=".1"/><g clip-path="url(#b)"><image height="22" opacity=".2" overflow="visible" transform="translate(-.5 -.5)" width="20" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABUAAAAXCAYAAADk3wSdAAAACXBIWXMAAAsSAAALEgHS3X78AAAA GXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAUpJREFUeNqslbFOwzAQQO/sQCRc sqAOlRgrMjCVr+Er+IZ+Ax/WTCwVeyVQl9IOQY2Pc2qhNFwcGsdSrHNsP52fpTPCeUP4X6PQZA2Z Pi41lqXRpCYKtA5tsFBVFdo9penh821ZSWsS112X1hBdPXG44BSyQMaEoHcJ6QJLu+LxrguKQDQB UAuOn3nfLATlqc0psmvuvyQVibfARyaXoQPeh6Hk9Mw4uL2bv3xs31+P7UWq5Rd7LsvN8akg5zBP KTPSIgWXN3OCQo6ARkpiCNQd36maegV6DGgjW1lBJFRWMBQaVDAUGlQwAvSvghhop4IYaKeCkaDn CmKhooJYqKhAtao59VV1od3w99BU4EsfcQVXruBuPBMvgJIv1sdmPSVA3HOhLvy/bCC0qDk8rjP9 TtWB36gVv1Hrvjeq792SjokRF/Z7Fz8CDAC8EmWDKVGDLgAAAABJRU5ErkJggg=="/><path d="M11 1H2.5C1.68 1 1 1.68 1 2.5v15c0 .83.68 1.5 1.5 1.5H17L11 1z" fill="#4285F4"/></g><path clip-path="url(#b)" d="M2.5 1C1.68 1 1 1.68 1 2.5v.12c0-.82.68-1.5 1.5-1.5H11V1H2.5z" fill="#FFF" fill-opacity=".02"/><path clip-path="url(#b)" d="M11 1v.12l5.92 17.75H2.5c-.82 0-1.5-.67-1.5-1.5v.12c0 .84.68 1.51 1.5 1.51H17L11 1z" fill="#212121" fill-opacity=".1"/><g clip-path="url(#b)"><path d="M7.5 10v1.2h1.98c-.08.52-.6 1.51-1.98 1.51-1.2 0-2.17-.99-2.17-2.21S6.3 8.29 7.5 8.29c.68 0 1.13.29 1.39.54l.95-.92C9.24 7.35 8.44 7 7.5 7 5.57 7 4 8.57 4 10.5S5.57 14 7.5 14c2.02 0 3.36-1.42 3.36-3.42 0-.23-.02-.41-.06-.58H7.5z" fill="#EEE"/><path d="M4 7h7v7H4z" fill="none"/></g><radialGradient cx="1.457" cy="1.42" gradientUnits="userSpaceOnUse" id="e" r="29.792"><stop offset="0" stop-color="#FFF" stop-opacity=".1"/><stop offset="1" stop-color="#FFF" stop-opacity="0"/></radialGradient><path d="M21.5 5h-9.17L11 1H2.5C1.68 1 1 1.68 1 2.5v15c0 .83.68 1.5 1.5 1.5h9.17L13 23h8.5c.82 0 1.5-.68 1.5-1.5v-15c0-.83-.68-1.5-1.5-1.5z" fill="url(#e)"/></svg>" width="24" height="24" alt=""></div><div class=" VIpgJd-yAWNEb-hvhgNd-k77Iif-i3jM8c"><div class="VIpgJd-yAWNEb-hvhgNd-IuizWc" dir="ltr">Original text</div><div id="goog-gt-original-text" class="VIpgJd-yAWNEb-nVMfcd-fmcmS VIpgJd-yAWNEb-hvhgNd-axAV1"></div></div><div class="VIpgJd-yAWNEb-hvhgNd-N7Eqid ltr"><div class="VIpgJd-yAWNEb-hvhgNd-N7Eqid-B7I4Od ltr" dir="ltr"><div class="VIpgJd-yAWNEb-hvhgNd-UTujCb">Rate this translation</div><div class="VIpgJd-yAWNEb-hvhgNd-eO9mKe">Your feedback will be used to help improve Google Translate</div></div><div class="VIpgJd-yAWNEb-hvhgNd-xgov5 ltr"><button id="goog-gt-thumbUpButton" type="button" class="VIpgJd-yAWNEb-hvhgNd-bgm6sf" title="Good translation" aria-label="Good translation" aria-pressed="false"><span id="goog-gt-thumbUpIcon"><svg width="24" height="24" viewBox="0 0 24 24" focusable="false" class="VIpgJd-yAWNEb-hvhgNd-THI6Vb NMm5M"><path d="M21 7h-6.31l.95-4.57.03-.32c0-.41-.17-.79-.44-1.06L14.17 0S7.08 6.85 7 7H2v13h16c.83 0 1.54-.5 1.84-1.22l3.02-7.05c.09-.23.14-.47.14-.73V9c0-1.1-.9-2-2-2zM7 18H4V9h3v9zm14-7l-3 7H9V8l4.34-4.34L12 9h9v2z"></path></svg></span><span id="goog-gt-thumbUpIconFilled"><svg width="24" height="24" viewBox="0 0 24 24" focusable="false" class="VIpgJd-yAWNEb-hvhgNd-THI6Vb NMm5M"><path d="M21 7h-6.31l.95-4.57.03-.32c0-.41-.17-.79-.44-1.06L14.17 0S7.08 6.85 7 7v13h11c.83 0 1.54-.5 1.84-1.22l3.02-7.05c.09-.23.14-.47.14-.73V9c0-1.1-.9-2-2-2zM5 7H1v13h4V7z"></path></svg></span></button><button id="goog-gt-thumbDownButton" type="button" class="VIpgJd-yAWNEb-hvhgNd-bgm6sf" title="Poor translation" aria-label="Poor translation" aria-pressed="false"><span id="goog-gt-thumbDownIcon"><svg width="24" height="24" viewBox="0 0 24 24" focusable="false" class="VIpgJd-yAWNEb-hvhgNd-THI6Vb NMm5M"><path d="M3 17h6.31l-.95 4.57-.03.32c0 .41.17.79.44 1.06L9.83 24s7.09-6.85 7.17-7h5V4H6c-.83 0-1.54.5-1.84 1.22l-3.02 7.05c-.09.23-.14.47-.14.73v2c0 1.1.9 2 2 2zM17 6h3v9h-3V6zM3 13l3-7h9v10l-4.34 4.34L12 15H3v-2z"></path></svg></span><span id="goog-gt-thumbDownIconFilled"><svg width="24" height="24" viewBox="0 0 24 24" focusable="false" class="VIpgJd-yAWNEb-hvhgNd-THI6Vb NMm5M"><path d="M3 17h6.31l-.95 4.57-.03.32c0 .41.17.79.44 1.06L9.83 24s7.09-6.85 7.17-7V4H6c-.83 0-1.54.5-1.84 1.22l-3.02 7.05c-.09.23-.14.47-.14.73v2c0 1.1.9 2 2 2zm16 0h4V4h-4v13z"></path></svg></span></button></div></div><div id="goog-gt-votingHiddenPane" class="VIpgJd-yAWNEb-hvhgNd-aXYTce"><form id="goog-gt-votingForm" action="//translate.googleapis.com/translate_voting?client=te_lib" method="post" target="votingFrame" class="VIpgJd-yAWNEb-hvhgNd-aXYTce"><input type="text" name="sl" id="goog-gt-votingInputSrcLang" value=""><input type="text" name="tl" id="goog-gt-votingInputTrgLang" value=""><input type="text" name="query" id="goog-gt-votingInputSrcText" value=""><input type="text" name="gtrans" id="goog-gt-votingInputTrgText" value=""><input type="text" name="vote" id="goog-gt-votingInputVote" value=""></form><iframe name="votingFrame" frameborder="0" sandbox="allow-popups allow-top-navigation-by-user-activation" srcdoc="<html><head><meta charset=&quot;utf-8&quot;><meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;></head><body></body></html>"></iframe></div></div></div><div id="book-container">

        <h1 id="douglas-lenat-cyc-and-the-quest-to-solve-common-sense-reasoning-in-ai-lex-fridman-podcast-221"><font style="vertical-align:inherit"><font style="vertical-align:inherit">道格拉斯·莱纳特 (Douglas Lenat)：Cyc 和解决人工智能常识推理的探索 | Lex Fridman 播客 #221</font></font></h1><h1>Douglas
            Lenat: Cyc and the Quest to Solve Common Sense Reasoning in AI | Lex
            Fridman Podcast #221</h1>
        <p><img src="data:image/jpeg;base64,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"><font style="vertical-align:inherit"><font style="vertical-align:inherit">4 年前 (2021 年 9 月 16 日) — 2:52:56 </font></font><a href="https://youtube.com/watch?v=3wMKoSRbGVs"><font style="vertical-align:inherit"><font style="vertical-align:inherit">https://youtube.com/watch?v=3wMKoSRbGVs</font></font></a></p><p> 4
            years ago (Sep 16, 2021) — 2:52:56 <a href="https://youtube.com/watch?v=3wMKoSRbGVs">https://youtube.com/watch?v=3wMKoSRbGVs</a></p>
        <h2 id="summary"><font style="vertical-align:inherit"><font style="vertical-align:inherit">概括</font></font></h2><h2>Summary</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">Cyc 的创始人道格拉斯·莱纳特 (Douglas Lenat) 讨论了他于 1984 年启动的人工智能项目 Cyc。Cyc 旨在创建一个常识知识库，这是一项复杂的任务。莱纳特解释说，早期的人工智能系统缺乏常识，而理解需要分层的知识基础。他描述了获取这些知识的技术，包括分析文本中的隐含假设和识别矛盾。Cyc 最初的目标是一百万条规则，但该项目需要数千万条规则。莱纳特讨论了知识库中局部一致性的重要性以及使用高阶逻辑的重要性。他还谈到了机器学习和语义网在扩展 Cyc 知识库中的作用。对话以莱纳特对项目挑战的反思、他对人工智能未来的愿景以及对年轻人的建议结束。</font></font></p><p>Douglas Lenat, creator of Cyc, discusses his AI project Cyc, launched
            in 1984. Cyc aims to create a knowledge base of common sense knowledge,
            a complex task. Lenat explains that early AI systems lacked common
            sense, and that understanding requires a layered foundation of
            knowledge. He describes techniques for acquiring this knowledge,
            including analyzing text for implicit assumptions and identifying
            contradictions. Cyc initially aimed for a million rules, but the project
            needed tens of millions. Lenat discusses the importance of local
            consistency in the knowledge base and the use of higher-order logic. He
            also touches on the role of machine learning and the semantic web in
            expanding Cyc’s knowledge base. The conversation concludes with Lenat’s
            reflections on the project’s challenges, his vision for the future of
            AI, and advice for young people.</p>
        <h2 id="introduction"><font style="vertical-align:inherit"><font style="vertical-align:inherit">介绍</font></font></h2><h2>Introduction</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">以下是与 Cyc 系统创始人道格拉斯·莱纳特 (Douglas Lenat) 的对话。近 40 年来，Cyc 系统一直致力于解决人工智能的核心问题：获取常识性知识，并利用这些知识思考、推理和理解世界。</font></font></p><p>The following is a conversation with Douglas Lenat, creator of Cyc, a
            system that, for close to 40 years and still today, has sought to solve
            the core problem of artificial intelligence: the acquisition of common
            sense knowledge and the use of that knowledge to think, to reason, and
            to understand the world.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">为了支持这个播客，请查看描述中的赞助商。</font></font></p><p>To support this podcast, please check out our sponsors in the
            description.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">顺便说一句，在现代机器学习时代的兴奋中，我们很容易忘记我们对如何构建与人类思维相匹配的智能的理解是多么的少。对我来说，Cyc 背后的许多核心思想，无论是在某种形式上、在现实中还是在精神上，都可能成为实现通用超级智能的人工智能系统的一部分。但也许更重要的是，解决这个常识性知识问题将帮助我们人类理解我们自己的思想、真理的本质，以及最终如何更加理性、更加友善地对待彼此。</font></font></p><p>As a side note, let me say that in the excitement of the modern era
            of machine learning, it is easy to forget just how little we understand
            exactly how to build the kind of intelligence that matches the power of
            the human mind. To me, many of the core ideas behind Cyc, in some form,
            in actuality, or in spirit, will likely be part of the AI system that
            achieves general superintelligence. But perhaps more importantly,
            solving this problem of common sense knowledge will help us humans
            understand our own minds, the nature of truth, and finally, how to be
            more rational and more kind to each other.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这是 Lex Fridman 的播客，以下是我与 Douglas Lenat 的对话。</font></font></p><p>This is the Lex Fridman podcast, and here is my conversation with
            Douglas Lenat.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">Cyc 是您于 1984 年发起的一个项目，至今仍然活跃。</font></font></p><p>Cyc is a project launched by you in 1984 and is still active
            today.</p>
        <h2 id="what-is-cyc"><font style="vertical-align:inherit"><font style="vertical-align:inherit">什么是 Cyc？</font></font></h2><h2>What is Cyc?</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">它的目标是建立一个涵盖世界运作的基本概念和规则的知识库。换句话说，它希望掌握常识性知识，但这比听起来要困难得多。您能详细阐述一下这个使命吗？也许可以谈谈这个使命中的各个子目标？</font></font></p><p>Its goal is to assemble a knowledge base that spans the basic
            concepts and rules about how the world works. In other words, it hopes
            to capture common sense knowledge, which is a lot harder than it sounds.
            Can you elaborate on this mission and maybe speak to the various
            subgoals within this mission?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">当我在斯坦福大学计算机科学系任教时，我和同事们研究了各种人工智能程序——自然语言理解程序、机器人、专家系统等等。我们不断遇到同样的障碍。我们的系统在早期取得了令人印象深刻的成功。所以，如果你的唯一目标是学术性的——即获得足够的材料来写一篇期刊文章——这可能就足够了。但如果你真的想获得人工智能，那么你必须以某种方式越过障碍。障碍在于这些程序没有我们所谓的常识；它们没有一般的世界知识；它们并不真正理解它们在做什么、在说什么或被问到什么。</font></font></p><p>When I was a faculty member in the computer science department at
            Stanford, my colleagues and I did research in all sorts of artificial
            intelligence programs—natural language understanding programs, robots,
            expert systems, and so on. We kept hitting the very same brick wall. Our
            systems would have impressive early successes. So, if your only goal was
            academic—namely, to get enough material to write a journal article—that
            might actually suffice. But if you’re really trying to get AI, then you
            have to somehow get past the brick wall. And the brick wall was that the
            programs didn’t have what we would call common sense; they didn’t have
            general world knowledge; they didn’t really understand what they were
            doing, what they were saying, or what they were being asked.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，就像聪明的狗表演杂技一样，我们可以让它们表演杂技，但它们从来都不明白自己在做什么。有点像你让狗去取你的早报。狗可能会成功做到这一点，但它不知道报纸是什么，也不知道报纸上写了什么，或者诸如此类的事情。</font></font></p><p>So, very much like a clever dog performing tricks, we could get them
            to do tricks, but they never really understood what they were doing.
            Sort of like when you get a dog to fetch your morning newspaper. The dog
            might do that successfully, but the dog has no idea what a newspaper is,
            or what it says, or anything like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">理解某件事意味着什么？您能详细解释一下吗？理解是一种将小事情组合在一起的行为，比如通过推理，还是理解是您随着时间的推移而获得的智慧，从而形成知识库？</font></font></p><p>What does it mean to understand something? Can you maybe elaborate on
            that a little bit? Is understanding an action of like combining little
            things together, like through inference, or is understanding the wisdom
            you gain over time that forms a knowledge base?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为应该更多地理解……把它想象成你脚下的地面，它可能非常不稳定，可能非常不安全，但大多数时候并非如此。因为在它下面还有更多的地面，最终，你知道，还有岩石和其他东西。但一层又一层，坚实的基础就在那里。你很少需要考虑它。你很少需要依赖它。但偶尔，你需要。</font></font></p><p>I think of understanding more like… Think of it more like the ground
            you stand on, which could be very shaky, could be very unsafe, but most
            of the time is not. Because underneath it is more ground, and
            eventually, you know, rock and other things. But layer after layer after
            layer, that solid foundation is there. And you rarely need to think
            about it. You rarely need to count on it. But occasionally, you do.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">嗯，我以前从未用过这个比喻，所以请耐心听我说，但我认为在让计算机理解事物方面也是如此。也就是说：你问计算机一个问题，例如 Alexa，或者某个机器人，或者其他什么东西，也许它会得到正确的答案。但如果你问的是人类，你也可以说“为什么？”或“你怎么会错？”之类的话。你知道，那个人会回答你。你知道，如果你有一个小孩，他们会不停地问“为什么”的问题，这可能会有点烦人。最终，你会举起手说：“我不知道。这就是世界本来的样子。”但对于很多层面来说，你实际上都有那种分层的、坚实的支持基础。这样当你需要它时，你就可以依靠它。</font></font></p><p>Um, I’ve never used this analogy before, so bear with me, but I think
            the same thing is true in terms of getting computers to understand
            things. Which is: you ask a computer a question, for instance, Alexa, or
            some robot, or something, and maybe it gets the right answer. But if you
            were asking that of a human, you could also say things like, “Why?” or
            “How might you be wrong about this?” or something like that. And the
            person, you know, would answer you. And you know, it might be a little
            annoying if you have a small child, and they keep asking “why” questions
            in series. Eventually, you get to the point where you throw up your
            hands and say, “I don’t know. It’s just the way the world is.” But for
            many layers, you actually have that layered, solid foundation of
            support. So that when you need it, you can count on it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">什么时候需要它？嗯，当事情出乎意料时。当你遇到一种新情况时。例如，当你开车时，有一个小程序、一套小规则来覆盖 99% 的情况可能就没问题了。但当有 1% 的奇怪事情发生时，你真的需要依靠常识。</font></font></p><p>When do you need it? Well, when things are unexpected. When you come
            up against a situation which is novel. For instance, when you’re
            driving, it may be fine to have a small program, a small set of rules
            that cover, you know, 99% of the cases. But that 1% of the time when
            something strange happens, you really need to draw on common sense.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">例如，最近我和妻子开车时，前面有一辆垃圾车。我猜他们把车装得太满，车尾爆炸了。垃圾袋散落得到处都是。我们必须在瞬间做出决定：是猛踩刹车吗？还是转向另一条车道？还是直接碾过它？因为周围都是车。你知道，我们前面有一个大垃圾袋。我们知道垃圾袋里装的都是我们扔的东西——碾过它可能不安全。左边是一堆快餐店的垃圾袋。我们想，“哦，好吧，那些东西就像泡沫塑料和剩菜剩饭。我们会碾过那些东西的。”所以这对我们来说是一件安全的事情。</font></font></p><p>For instance, my wife and I were driving recently, and there was a
            trash truck in front of us. And I guess they had packed it too full, and
            the back exploded. And trash bags went everywhere. And we had to make a
            split second decision: are we going to slam on our brakes? Are we going
            to swerve into another lane? Are we going to just run it over? Because
            there were cars all around us. And, you know, in front of us was a large
            trash bag. And we know what we throw away in trash bags—probably not a
            safe thing to run over. On the left was a bunch of fast food restaurant
            trash bags. And it’s like, “Oh, well, those things are just like
            styrofoam and leftover food. We’ll run over that.” And so that was a
            safe thing for us to do.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">现在，这种事情也许一生中都会发生一次。但关键在于，几乎无法预测在无法预见的某些情况下，你实际上可能需要多少关于世界的点滴知识。但是，当你坐在那座山上，或者那片拥有深厚知识的土地上，为了在瞬间做出关于快餐垃圾或垃圾车后面的随机垃圾的决定时，你需要能够以某种方式利用你所站立的地面。你知道，这不仅仅是拥有很多立足之地是不够的；而是你利用它的能力，在一瞬间利用它，比如把它们整合在一起，做出那一瞬间的决定。</font></font></p><p>Now, that’s the kind of thing that’s going to happen maybe once in
            your life. But the point is that there’s almost no telling what little
            bits of knowledge about the world you might actually need in some
            situations which were unforeseen. But see, when you sit on that
            mountain, or that ground that goes deep with knowledge, in order to make
            a split second decision about fast food trash or random trash from the
            back of a trash truck, you need to be able to leverage the ground you
            stand on in some way. It’s not merely, you know, it’s not enough to just
            have a lot of ground to stand on; it’s your ability to leverage it, to
            utilize it in a split second like integrate it all together to make that
            split second decision.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为理解不仅仅是拥有获取常识性知识的能力；它是一种以某种方式获取知识的行为，比如正确地找出知识中无用的部分，只选择有用的部分，并有效地做出结论性的决定。</font></font></p><p>And I suppose understanding isn’t just having common sense knowledge
            to access it; it’s the act of accessing it somehow, like correctly
            figuring out the parts of the knowledge that are not useful, selecting
            only the useful parts, and effectively making conclusive decisions.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，让我们来区分一下两个不同的任务，实际上，如果你想以一种可用、有用的方式使用它，这两项任务都非常重要，甚至是必要的，而不是像图书馆的书那样放在书架上。对吧？知识可能在那里，但你知道，如果发生火灾，这些书就会被烧毁，因为他们不知道里面有什么，它们就放在那里等着被烧毁。</font></font></p><p>So, let’s tease apart two different tasks, really, both of which are
            incredibly important and even necessary if you’re going to have this in
            a usable, useful fashion, as opposed to, say, like library books sitting
            on a shelf. Right? And so on, where the knowledge might be there, but
            you know, if a fire comes, the books are going to burn because they
            don’t know what’s in them, and they’re just going to sit there while
            they burn.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，运用知识有两个方面。一个是理论层面：这怎么可能？第二个方面是：你如何才能足够快地做到这一点？对吗？</font></font></p><p>So, there are two aspects of using the knowledge. One is a kind of
            theoretical: how is it possible at all? And then the second aspect of
            what you said is: how can you do it quickly enough? Right?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如何才能做到这一点，是哲学家们一直在努力解决的问题。幸运的是，一百年前甚至更早，哲学家们就开发了一种形式语言，就像英语一样。它被称为谓词逻辑，或一阶逻辑，或谓词演算之类的东西，等等。因此，有一种用这种形式语言来表示事物的方法，它使机械程序能够通过算法产生所有相同的逻辑蕴涵，所有相同的逻辑结论，这些结论都是你或我从用这种方式表示的同一组信息中得出的。</font></font></p><p>How can you do it at all is something that philosophers have grappled
            with. And fortunately, philosophers, a hundred years ago and even
            earlier, developed a kind of formal language, like English. It’s called
            predicate logic, or first order logic, or something like predicate
            calculus, and so on. So, there’s a way of representing things in this
            formal language which enables a mechanical procedure to sort of grind
            through and algorithmically produce all the same logical entailments,
            all the same logical conclusions that you or I would from that same set
            of pieces of information that are represented that way.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这引发了几个问题。一是：你如何从观察和英语等中获得所有这些信息，并将其转化为逻辑形式？对吗？其次，你如何有效地运行这些算法，以实际获得所需的信息，在我提到的情况下，在十分之一秒内，而不是在 10 小时或 10,000 年的计算中？这两个都是非常重要的问题。</font></font></p><p>So, that sort of raises a couple of questions. One is: how do you get
            all this information from, say, observations and English, and so on,
            into this logical form? Right? And secondly, how can you then
            efficiently run these algorithms to actually get the information you
            need, in the case I mentioned, in a tenth of a second rather than, say,
            in, you know, 10 hours or 10,000 years of computation? And those are
            both really important questions.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">并且，与第一个问题相辅相成的是：你需要收集多少这样的东西才能在某些情况下发挥作用？</font></font></p><p>And, like a corollary addition to the first one is: how many such
            things do you need to gather for it to be useful in certain
            contexts?</p>
        <h2 id="how-to-form-a-knowledge-base-of-the-universe"><font style="vertical-align:inherit"><font style="vertical-align:inherit">如何形成宇宙知识库</font></font></h2><h2>How to form a
            knowledge base of the universe</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，您提到的哲学家，为了捕捉这个世界并以合乎逻辑的方式、以形式逻辑的方式呈现它，需要多少个陈述？是五个吗？是十​​个吗？是十​​万亿个吗？是这样的吗？据我所知，这可能仍然是一个悬而未决的问题。关于如何完美地描述宇宙，这可能永远是一个悬而未决的问题。你需要多少事实？我想我会给你一个实际的答案，让你失望的。</font></font></p><p>So, like, what, in order, you mentioned philosophers, in order to
            capture this world and present it in a logical way, in a formal logic,
            like how many statements are required? Is it five? Is it ten? Is it 10
            trillion? Is it like that? That’s, as far as I understand, is probably
            still an open question. It may forever be an open question to say
            definitively about describing the universe perfectly. How many facts do
            you need? I guess I’m going to disappoint you by giving you an actual
            answer to your question.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">好吧，这听起来很令人兴奋。是的，好的。所以，现在我们有三件事要谈。继续添加更多，虽然没关系。第一点和第三点是相关的。是的，所以我们暂时把效率问题放在一边。那么，所有这些信息如何以逻辑形式表示出来，以便这些算法——解析定理证明和其他算法——能够真正解决你所说的所有逻辑后果？这和你的问题有关，嗯，你需要多少个这些东西？因为如果答案足够小，那么你可以手写一个一个地写出来。</font></font></p><p>Okay, well, no, this sounds exciting. Yes, okay. So, so now we have
            like three, three things to talk about. Keep adding more, although
            that’s okay. The first and third are related. Yes, so let’s leave the
            efficiency question aside for now. So, how does all this information get
            represented in logical form so that these algorithms—resolution theorem
            proving and other algorithms—can actually grind through all the logical
            consequences of what you said? And that ties into your question about,
            well, how many of these things do you need? Because if the answer is
            small enough, then by hand, you could write them out one at a time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，在 1984 年初，我在斯坦福大学召开了一次会议，当时我是那里的一名教员，我们召集了我认识的六位最聪明的人——比如艾伦·纽厄尔、马文·明斯基、艾伦·凯，还有其他几个人。莱克斯·弗里德曼是不是碰巧在那里，因为他喜欢你的——他当时评论了你的系统，URI？不，不，他没有参加这次会议，但无论如何，这是一次非常棒的会议。我认为埃德·费根鲍姆也在那里。</font></font></p><p>So, in the early 1984, I held a meeting at Stanford, where I was a
            faculty member there, where we assembled about half a dozen of the
            smartest people I know—people like Alan Newell and Marvin Minsky, and
            Alan Kay, and um, a few others. Was Lex Fridman there by chance, ’cause
            he liked your—he commented about your system, URIs, at the time? No, no,
            he wasn’t part of this meeting, but that’s a heck of a meeting anyway. I
            think Ed Feigenbaum was there.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为 Josh Leberg 也在那里。所以，我们聚集了所有这些不同的聪明人，我们聚在一起解决你提出的问题，即：如果为了使人工智能不脆弱，为了使人工智能不只是具有智能的外表，表示常识和世界知识很重要，那么，例如，为了从根本上涵盖人们期望完全陌生的人已经知道的世界知识，我们实际上需要编写多少条常识、多少条“如果”规则？</font></font></p><p>I think Josh Leberg was there. So, we have um, all these different
            smart people, and we came together to address the question that you
            raised, which is: if it’s important to represent common sense knowledge
            and world knowledge in order for AIs to not be brittle, in order for AIs
            not to just have the veneer of intelligence, well, how many pieces of
            common sense, how many if then rules, for instance, would we have to
            actually write in order to essentially cover what people expect perfect
            strangers to already know about the world?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我预计意见和计算会有巨大分歧。但令人惊讶的是，每个人都得到了答案，大约一百万个。一个人回答说：“嗯，你看，你只能在单位时间内将一定数量的事情刻入人类的长期记忆中，比如每 30 秒一个。除此之外，它只是短期记忆，它会像水一样流走，等等。”那么，到你 10 岁左右的时候，你可能已经将多少事情刻入你的长期记忆中了？</font></font></p><p>I expected there would be an enormous divergence of opinion and
            computation. But amazingly, everyone got an answer, which was around a
            million. One person got the answer by saying, “Well, look, you can only
            burn into human long term memory a certain number of things per unit
            time, like maybe one every 30 seconds or something. And other than that,
            it’s just short term memory, and it flows away like water, and so on.”
            So, by the time you’re, say, 10 years old or so, how many things could
            you possibly have burned into your long term memory?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">大约是一百万。另一个人则从完全不同的角度说：“好吧，如果你看看字典中的单词数量——不是整本字典，而是对于一个被认为精通某种语言的人来说，他们需要知道多少个单词，然后你需要告诉每个单词多少个内容？”他们用这种方式得到了一百万。另一个人说：“好吧，让我们实际上看一篇简短的、一卷的百科全书文章。”所以，我们来看看，你知道的，像四段文章之类的东西。</font></font></p><p>And it’s like about a million. Another person went in a completely
            different direction and said, “Well, if you look at the number of words
            in a dictionary—not a whole dictionary, but for someone to essentially
            be considered fluent in a language, how many words would they need to
            know, and then about how many things about each word would you have to
            tell it?” So they got to a million that way. Another person said, “Well,
            let’s actually look at one single short, one volume desk encyclopedia
            article.” So, we’ll look at, you know, what was like a four paragraph
            article or something.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我想到的是贪婪。GBS 是一种水禽。如果我们要坐在那里，代表那里的每一件事情，我们需要用这种逻辑语言写出多少断言、规则或陈述？然后，将其乘以所有文章的数量，等等。所以，所有这些估计值都为一百万。所以，如果你算一下，结果可能是，哦，好吧，那么也许在 100 个人年、一两个人世纪内，我们实际上可以手写这些。</font></font></p><p>I think about greed. GBS are a type of waterfowl. And if we were
            going to sit there and represent every single thing that was there, how
            many assertions or rules or statements would we have to write in this
            logical language? And so, and then multiply that by all of the number of
            articles that there were, and so on. So, all of these estimates came out
            with a million. And so, if you do the math, it turns out that like, oh,
            well, then maybe in something like 100 person years, in one or two
            person centuries, we could actually get this written down by hand.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">当时恰好有一个绝妙的巧合机会，即 20 世纪 80 年代初。当时日本正在开展第五代计算机计划。日本曾威胁要在计算机、人工智能和硬件领域做他们刚刚在消费电子和汽车行业做的事情，也就是从美国和西方手中夺取控制权。因此，美国感到害怕。国会采取了一些行动——你知道那是很久以前的事情了——因为国会采取了一些行动。</font></font></p><p>And a marvelous coincidence opportunity existed right at that point
            in time, the early 1980s. There was something called the Japanese Fifth
            Generation Computing Effort. Japan had threatened to do in computing and
            AI and hardware what they had just finished doing in consumer
            electronics and the automotive industry, namely wresting control away
            from the United States and more generally away from the West. And so,
            America was scared. And Congress did something—that’s how you know it
            was a long time ago—because Congress did something.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">国会通过了一项名为《国家合作研究法案》（NCRA）的法案。法案的内容是：“嘿，所有美国大公司——这也是你们知道很久以前的事情的原因，因为它们是美国公司而不是跨国公司——嘿，所有美国大公司。通常情况下，如果你们在研发方面合谋，就会违反反垄断法。但我们承诺，在未来 10 年内，如果你们这样做，我们不会起诉任何人，以帮助应对这一威胁。”</font></font></p><p>Congress passed something called the National Cooperative Research
            Act (NCRA). And what it said was, “Hey, all you big American
            companies—that’s also how you know it was a long time ago because they
            were American companies rather than multinational companies—hey, all you
            big American companies. Normally, it would be an antitrust violation if
            you colluded on R&amp;D. But we promise for the next 10 years we won’t
            prosecute any of you if you do that to help combat this threat.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">于是，一夜之间，美国出现了两个研究联盟。它们恰好都位于德克萨斯州奥斯汀。一个叫 Semitech，专注于硬件芯片等。另一个叫 MCC，即微电子和计算机技术公司，更专注于软件、数据库、人工智能和自然语言理解等。多亏了我的朋友 Woody Bledsoe（他是该联盟的创始人之一），我有机会成为其首席科学家。</font></font></p><p>And so, overnight, the first two consortia, research consortia, in
            America sprang up. Both of them coincidentally in Austin, Texas. One
            called Semitech, focused on hardware chips and so on. And then one
            called MCC, the Microelectronics and Computer Technology Corporation,
            focusing more on software, on databases, and AI and natural language
            understanding and things like that. And I got the opportunity, thanks to
            my friend Woody Bledsoe, who was one of the people who founded that, to
            come and be its principal scientist.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">他说——他派海军上将鲍勃·英曼（负责管理 MCC）来找我谈话，说：“教授，你知道你在说这个项目。它将需要几个世纪的努力。你只有少数几个研究生。你算算看。完成这个项目需要的时间比你余生都要长。但如果你搬到德克萨斯州奥斯汀的荒野，那么，投入 10 倍的人手，你知道几年后就能完成，所以这非常令人兴奋，所以我就这么做了。我从斯坦福大学离开了。</font></font></p><p>And he said—and he sent Admiral Bob Inman, who was the person running
            MCC, came and talked to me and said, “Look, Professor, you know you’re
            talking about doing this project. It’s going to involve person centuries
            of effort. You’ve only got a handful of graduate students. You do the
            math. It’s going to take you like, you know, longer than the rest of
            your life to finish this project. But if you move to the wilds of
            Austin, Texas, well, put 10 times as many people on it, and you know
            you’ll be done in a few years, and so that was pretty exciting, and so I
            did that. I took my leave from Stanford.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我来到奥斯汀，为 MCC 工作。有好消息也有坏消息。坏消息是，我们所有人的认知都相差了一个数量级。事实证明，你需要的是数千万条关于日常事物的知识。这有点像如果你有一个咖啡杯，里面有东西，你把它倒过来，里面的东西就会掉出来。所以你需要数千万条这样的知识，即使你费尽心思让每一条知识都尽可能通用。</font></font></p><p>I came to Austin. I worked for MCC. Good news and bad news. The bad
            news is that all of us were off by an order of magnitude. That it turns
            out what you need are tens of millions of these pieces of knowledge
            about everyday things. Sort of like if you have a coffee cup with stuff
            in it and you turn it upside down, the stuff in it is going to fall out.
            So you need tens of millions of pieces of knowledge like that, even if
            you take the trouble to make each one as general as it possibly could
            be.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但好消息是，得益于最初的第五代计算机的努力，以及后来美国政府机构的资助等，我们能够获得足够的资金，不是几个世纪的时间，而是几个千年的时间。自 1984 年以来，我们一直在努力让 Cyc 包含数千万条规则，以便真正捕捉和涵盖并非所有人类知识，但您认为其他人知道的东西，您指望其他人知道的东西。</font></font></p><p>But the good news was that, thanks to initially the Fifth Generation
            effort and then later US government agency funding, and so on, we were
            able to get enough funding, not for a couple of person centuries of
            time, but for a couple of person millennia of time. Which is what we’ve
            spent since 1984 getting Cyc to contain the tens of millions of rules
            that it needs in order to really capture and span, sort of, not all of
            human knowledge, but the things that you assume other people know, the
            things you count on other people knowing.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，到现在为止，我们已经做到了。好消息是，既然你已经等了 38 年才准备跟我谈话，我们，我们即将完成这个过程。所以我们现在所做的大部分工作甚至不是加入你认为的常识，而是加入特定领域、特定应用的知识，比如某家医院的医疗保健，或者石油管道堵塞，或者其他任何应用。所以我们几乎已经完成了整个过程，我们做的事情非常像 20 世纪 70 年代和 80 年代的专家系统，只不过它们不再是毫无根据的脆弱系统，而是建立在一个巨大的金字塔上，如果你愿意的话，这个巨大的常识知识网格上。</font></font></p><p>And so, by now, we’ve done that. And the good news is, since you’ve
            waited 38 years just about to talk to me, we’re, we’re about at the end
            of that process. So most of what we’re doing now is not putting in even
            what you would consider common sense, but more putting in domain
            specific, application specific knowledge about healthcare in a certain
            hospital, or about oil pipes getting clogged up, or whatever the
            applications happen to be. So we’ve almost come full circle, and we’re
            doing things very much like the expert systems of the 1970s and 1980s,
            except instead of resting on nothing and being brittle, they’re now
            resting on this massive pyramid, if you will, this massive lattice of
            common sense knowledge.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这样，当出现问题、发生意外情况时，他们就可以依靠越来越多的一般原则，最终找到解决问题的办法，例如，如果我们的麦克风出现问题，你会做的事情之一就是拔掉插头，再插上，然后祈祷一切顺利，对吧？因为你在处理电子设备或软件系统或类似事物时所掌握的一般知识之一就是有这样的基本原则吗？</font></font></p><p>So that when things go wrong, when something unexpected happens, they
            can fall back on more and more and more general principles, eventually
            bottoming out in things like, for instance, if we have a problem with
            the microphone, one of the things you’ll do is unplug it, plug it in
            again, and hope for the best, right? Because one of the general pieces
            of knowledge you have in dealing with electronic equipment or software
            systems or things like that is there a basic principle like that?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">比如，是否有可能对某些东西进行编码，通常可以捕捉到关闭它然后再打开的想法，看看它是否能解决问题？哦，当然。这是 Cyc 知道的事情之一。我相信，这实际上是自然界的基本法则之一。我不会，我不会称它为法则。它更像是——似乎每次都有效。所以它肯定看起来像一条法则。我不知道。基本上，我们涵盖了所需的资源，然后我们必须设计一种方法来真正弄清楚，好吧，我们需要告诉系统的数千万件事是什么。</font></font></p><p>Like is there, is it possible to encode something that generally
            captures this idea of turn it off and turn it back on and see if it
            fixes it? Oh, absolutely. That’s one of the things that Cyc knows.
            That’s actually one of the fundamental laws of nature, I believe. I
            wouldn’t, I wouldn’t call it a law. It’s more like a—seems to work every
            time. So it’s sure, sure, like looks like a law. I don’t know.
            Basically, we covered the resources needed, and then we had to devise a
            method to actually figure out, well, what are the tens of millions of
            things that we need to tell the system.</p>
        <h2 id="how-to-train-an-ai-knowledge-base"><font style="vertical-align:inherit"><font style="vertical-align:inherit">如何训练人工智能知识库</font></font></h2><h2>How to train an AI knowledge
            base</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">为此，我们发现了一些非常有效的技巧。其中之一是选取任何一段文字——几乎任何东西——可以是广告、成绩单、小说或文章。不要关注那里的实际类型——白页上的黑色空间。如果你愿意的话，关注它的补充，即空白。</font></font></p><p>For that, we found a few techniques that worked really well. One is
            to take any piece of text—almost anything—could be an advertisement, it
            could be a transcript, it could be a novel, it could be an article.
            Don’t pay attention to the actual type that’s there—the black space on
            the white page. Pay attention to the complement of that, the white
            space, if you will.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，这句话的作者认为读者已经了解了什么呢？例如，如果他们使用代词，他们怎么会知道你——为什么他们认为你能够理解这个代词的预期指称是什么？如果他们使用了一个模棱两可的词，他们怎么会认为你能够弄清楚他们用这个词的意思？</font></font></p><p>So, what did the writer of this sentence assume that the reader
            already knew about the world? For instance, if they used a pronoun, how
            did they figure out that you—why did they think that you would be able
            to understand what the intended referent of that pronoun was? If they
            used an ambiguous word, how did they think that you would be able to
            figure out what they meant by that word?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们还要看一个句子和下一个句子之间的空隙。作者希望你填写和推断一个句子的结尾和另一个句子的开头之间发生了什么？</font></font></p><p>The other thing we look at is the gap between one sentence and the
            next one. What are all the things that the writer expected you to fill
            in and infer that occurred between the end of one sentence and the
            beginning of the other?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，如果句子是“弗雷德·史密斯抢劫了第三国民银行。”“他被判处 20 年监禁。”那么，在第一句和第二句之间，你应该推断出这样的事情：弗雷德被抓了；弗雷德被捕了；弗雷德进了监狱；弗雷德接受了审判；弗雷德被判有罪；等等。如果我的下一句话以“法官……”开头，那么你假设这是审判他的法官。如果我的下一句话以“逮捕警官……”开头，那么你假设这是在他犯罪后逮捕他的警官，等等。</font></font></p><p>So, like, if the sentence says, “Fred Smith robbed the Third National
            Bank.” “He was sentenced to 20 years in prison.” Well, between the first
            sentence and the second, you’re expected to infer things like: Fred got
            caught; Fred got arrested; Fred went to jail; Fred had a trial; Fred was
            found guilty; and so on. If my next sentence starts out with something
            like, “The judge…”, then you assume it’s the judge at his trial. If my
            next sentence starts out something like, “The arresting officer…”, you
            assume that it was the police officer who arrested him after he
            committed the crime, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，这是获取知识的两种技术。</font></font></p><p>So, those are two techniques for getting that knowledge.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们有时看到的另一件事有点像假新闻，或者有点幽默的洋葱新闻标题，或者《世界新闻周刊》（如果你知道那是什么的话）或《国家询问报》的标题，上面写着：“哦，我们不相信这个。”然后我们反省为什么我们不相信它。所以，有这样的东西，“B7 登陆月球。”你知道，就像是，“为什么我们不——我们对这个世界了解多少，以至于我们相信那只是愚蠢的，或者诸如此类的事情？”</font></font></p><p>The other thing we sometimes look at is sort of like fake news or,
            sort of, humorous Onion headlines, or headlines in the Weekly World
            News, if you know what that is, or the National Enquirer, where it’s
            like, “Oh, we don’t believe this.” Then we introspect on why don’t we
            believe it. So, there are things like, “B7 lands on the moon.” You know,
            it’s like, “Why don’t we—what do we know about the world that causes us
            to believe that that’s just silly, or something like that?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">或者我们寻找的另一种东西是矛盾，即某些事情不可能同时为真，我们会对自己说：“比如，我们知道什么，让我们知道这两者不可能同时为真？”例如，在《世界新闻周刊》的其中一篇文章中，它谈到了埃尔维斯是如何被引用的……即使他已经上了年纪，等等。同一篇文章中的另一篇文章谈到人们看到了埃尔维斯的鬼魂。好吧，那么问题来了，我们为什么会相信这一点？你知道，这些文章中至少有一篇一定是错的，等等。</font></font></p><p>Or another thing we look for are contradictions, where with things
            which can’t both be true, and we say to ourselves, “Like, what is it
            that we know that causes us to know that both of these can’t be true at
            the same time?” For instance, in one of the Weekly World News editions,
            in one article, it talked about how Elvis was cited… Even though he was,
            you know, getting on in years, and so on. Another article in the same
            one talked about people seeing Elvis’s ghost. Okay, so it’s like, why,
            why do we believe that? At least one of these articles, you know, must
            be wrong, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，我们有一系列类似的技术，可以帮助我们的员工。到目前为止，我们大约有 50 人全职从事这项工作，而且已经工作了几十年。因此，我们投入了数千人年的努力。我们制定了数千万条规则。我们不断监督系统，以确保我们所说的内容尽可能通用。</font></font></p><p>So, we have a series of techniques like that that enable our people.
            By now, we have about 50 people working full time on this, and have for
            decades. So, we’ve put in the thousands of person years of effort. We’ve
            built up these tens of millions of rules. We constantly police the
            system to make sure that we’re saying things as generally as we possibly
            can.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，你不想说“没有老鼠也是驼鹿”这样的话，因为如果你说这样的话，那么你就必须在你实际必须拥有的断言数量上再添加一个或两个或三个零。</font></font></p><p>So, you don’t want to say things like, “No mouse is also a moose,”
            because if you said things like that, then you’d have to add another one
            or two or three zeros onto the number of assertions you’d actually have
            to have.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，在某个时候，我们会越来越多地概括事物，然后我们会说：“哦，是的。对于任何两个生物分类单元，如果我们不能明确知道其中一个是另一个的概括，那么几乎可以肯定它们是不相交的。一个成员不会是另一个成员。”等等。</font></font></p><p>So, at some point, we generalize things more and more, and we get to
            a point where we say, “Oh, yeah. For any two biological taxons, if we
            don’t know explicitly that one is a generalization of another, then
            almost certainly they’re disjoint. A member of one is not going to be a
            member of the other.” And so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，猫王和鬼魂之间也存在同样的问题。这与猫王无关；它更多的是关于人性和死亡，而且一般来说，事物不可能同时既活着又死去。</font></font></p><p>So, and the same thing with Elvis and the ghost. It has nothing to do
            with Elvis; it’s more about human nature and mortality, and, in general,
            things are not both alive and dead at the same time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，除非特殊情况，比如理论物理学的例子。</font></font></p><p>Yeah, unless in special cases, like in theoretical physics
            examples.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">好吧，这引出了几个重要的观点。这就是“洋葱新闻”的情况。好吧，抱歉。但不是，不是。</font></font></p><p>Well, that raises a couple of important points. That’s the “onion
            headline” situation type of thing. Okay, sorry. But no, no.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，您提出的这个非常重要的观点是，例如，如何处理异常和不一致等等？</font></font></p><p>So, what you bring up is this really important point of, like, well,
            how do you handle exceptions and inconsistencies, and so on?</p>
        <h2 id="global-consistency-versus-local-consistency"><font style="vertical-align:inherit"><font style="vertical-align:inherit">全局一致性与局部一致性</font></font></h2><h2>Global consistency
            versus local consistency</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们学到的最艰难的教训之一（我们花了大约五年时间才真正咬紧牙关，学会喜欢它）是，我们必须放弃全球一致性。因此，知识库不再保持一致。</font></font></p><p>And one of the hardest lessons for us to learn—it took us about five
            years to really grit our teeth and learn to love it—is that we had to
            give up global consistency. So, the knowledge base can no longer be
            consistent.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这个想法有点吓人。我从小看着《星际迷航》，每当计算机出现不一致的情况时，它要么会死机，要么会爆炸，要么会接管世界，要么会发生一些糟糕的事情。或者，如果你有数学背景，一旦你能证明错误，你就能证明任何事情。所以，这不是好事。等等。</font></font></p><p>This is a kind of scary thought. I grew up watching Star Trek, and
            anytime a computer was inconsistent, it would either freeze up or
            explode or take over the world, or something bad would happen. Or, if
            you come from a mathematics background, once you can prove false, you
            can prove anything. So, that’s not good. And so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这就是为什么旧的知识体系都非常一致。但问题是，总的来说，我们的世界模型、我们谈论世界的方式，到处都存在着各种各样的不一致之处，这些不一致之处会扼杀任何建立庞大的、全球一致的知识库的尝试。</font></font></p><p>So, that’s why the old knowledge based systems were all very, very
            consistent. But the trouble is that, by and large, our models of the
            world, the way we talk about the world, there are all sorts of
            inconsistencies that creep in here and there that will sort of kill any
            attempt to build some enormous, globally consistent knowledge base.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，我们必须转向一个局部一致性系统。一个很好的类比是，地球表面在全球范围内或多或少是球形的，但你每天的生活都好像地球表面是平的一样。你知道，当你和澳大利亚人交谈时，你不会认为他们的方向与你相反。当你计划一次旅行时，你知道，即使距离一千英里，你可能会考虑一点时区，但你很少考虑地球的曲率等等。</font></font></p><p>And so, what we had to move to was a system of local consistency. A
            good analogy is that the surface of the Earth is more or less spherical
            globally, but you live your life every day as though the surface of the
            Earth were flat. You know, when you’re talking to someone in Australia,
            you don’t think of them as being oriented upside down to you. When
            you’re planning a trip, you know, even if it’s a thousand miles away,
            you may think a little bit about time zones, but you rarely think about
            the curvature of the Earth and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">在大多数情况下，您一辈子都无需担心这一点，因为地球是局部平坦的。同样，Cyc 知识库被划分为几乎像构造板块一样的独立上下文。每个上下文或多或少是一致的，但一个上下文与下一个上下文之间的边界可能会有细微的不一致，依此类推。当您将 20 个上下文移到那里时，可能会出现明显的不一致。</font></font></p><p>For most purposes, you can live your whole life without really
            worrying about that because the Earth is locally flat. In much the same
            way, the Cyc knowledge base is divided up into almost like tectonic
            plates, which are individual contexts. Each context is more or less
            consistent, but there can be small inconsistencies at the boundary
            between one context and the next one, and so on. By the time you move,
            say, 20 contexts over there, there could be glaring inconsistencies.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，最终，你会从我们现在所处的正常、现代、现实世界的背景转变为类似《公路赛跑者》卡通片的背景，那里的物理非常不同，事实上，生与死也非常不同。因为无论他被杀了多少次，你知道，土狼都会在下一个场景中回来，依此类推。这是一个很难学到的教训，我们必须确保我们的表征语言——我们实际编码和表示知识的方式——具有足够的表达能力，这样我们就可以谈论在一种情况下为真而在另一种情况下为假的事情，在某一时刻为真而在另一时刻为假的事情，比如说，在一个地区（比如一个国家）为真，但在另一个国家为假的事情。</font></font></p><p>So, eventually, you get from the normal, modern, real world context
            that we’re in right now to something like a Road Runner cartoon context,
            where physics is very different, and in fact, life and death are very
            different. Because no matter how many times he’s killed, you know, the
            coyote comes back in the next scene, and so on. That was a hard lesson
            to learn, and we had to make sure that our representation language—the
            way we actually encode the knowledge and represent it—was expressive
            enough that we could talk about things being true in one context and
            false in another, things that are true at one time and false in another,
            things that are true, let’s say, in one region, like one country, but
            false in another.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有些事情在一个人的信仰体系中是正确的，但在另一个人的信仰体系中却是错误的。有些事情在某个抽象层次上是正确的，而在另外一个抽象层次上是错误的。例如，在某个抽象层次上，你会认为这张桌子是一个固体物体，但在原子层面上，它大部分是空的，等等。所以，这很有趣。但这给语境带来了很大的压力，需要做很多工作。</font></font></p><p>Other things that are true in one person’s belief system but false in
            another person’s belief system. Things that are true at one level of
            abstraction and false at another. For instance, at one level of
            abstraction, you think of this table as a solid object, but at, you
            know, down at the atomic level, it’s mostly empty space, and so on. So,
            then that’s fascinating. But it puts a lot of pressure on context to do
            a lot of work.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，你说的是“板块”。是否有可能制定出一般而大的上下文，用于这种知识库的捕获，或者你是否再次将乌龟放在乌龟之上，那里有大量的上下文？</font></font></p><p>So, you say “tectonic plates.” Is it possible to formulate contexts
            that are general and big that do this kind of capture of knowledge
            bases, or do you then get turtles on top of turtles again, where there’s
            just a huge number of contexts?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你问这个问题很好，因为你指出了正确的方向。你希望上下文成为你的系统（尤其是知识库）中的第一类对象，尤其是在 Cyc 的知识库中。我所说的“第一类对象”是指它应该能够让 Cyc 思考、讨论和推理一个或另一个上下文，就像它推理咖啡杯、桌子、人、钓鱼等等一样。上下文只是其语言中的术语，就像我提到的那些一样，因此 Cyc 可以推理上下文。上下文可以按层次排列，等等。</font></font></p><p>It’s good you ask that question because you’re pointing in the right
            direction. You want contexts to be first class objects in your systems,
            knowledge base, in particular, in Cyc’s knowledge base. By “first class
            object,” I mean that it should be able to have Cyc think about, talk
            about, and reason about one context or another context the same way it
            reasons about coffee cups, tables, people, fishing, and so on. Contexts
            are just terms in its language, just like the ones I mentioned, and so
            Cyc can reason about context. Context can be arranged hierarchically,
            and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你可以说一些关于现代时代真实的事情。某一年真实的事情将成为广泛意义上真实事情的子上下文，比如说，一个世纪或一千年或类似的时间。德克萨斯州奥斯汀的真实事情通常是德克萨斯州真实事情的特例，而德克萨斯州真实事情的特例又将成为美国真实事情的特例，等等。所以你不必在所有这些层面上一遍又一遍地重复这些事情。你只需在最普遍的层面上说这些事情，而且你只需要说一次。然后它基本上会继承到所有这些更具体的上下文中。</font></font></p><p>You can say things about, let’s say, things that are true in the
            modern era. Things that are true in a particular year would then be a
            subcontext of the things that are true in a broad, let’s say, century or
            millennium or something like that. Things that are true in Austin,
            Texas, are generally going to be a specialization of things that are
            true in Texas, which is going to be a specialization of things that are
            true in the United States, and so on. And so you don’t have to say
            things over and over again at all these levels. You just say things at
            the most general level that it applies to, and you only have to say it
            once. Then it essentially inherits to all these more specific
            contexts.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">问一个稍微技术性的问题：这个继承是树还是图？</font></font></p><p>To ask a slightly technical question: is this inheritance a tree or a
            graph?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">哦，你一定要把它想象成一个图表。</font></font></p><p>Oh, you definitely have to think of it as a graph.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">例如，我们可以讨论一下日本第五代计算机项目为何失败。原因大概有六七种。其中一个原因是他们试图将知识表示为树状结构，而不是图形。因此，其表示中的每个节点只能有一个父节点。因此，如果你有一张桌子，它由木制物体、黑色物体、扁平物体等组成，那么你必须选择一个，这是它唯一的父节点。当然，这取决于你需要推理的内容，有时知道它是木头做的很重要，比如我们在谈论火的时候。有时，如果我们谈论的是在上面放置某物，那么知道它是平的也很重要，等等。</font></font></p><p>So, we could talk about, for instance, why the Japanese Fifth
            Generation Computing effort failed. There were about half a dozen
            different reasons. One of the reasons they failed was because they tried
            to represent knowledge as a tree rather than as a graph. And so, each
            node in their representation could only have one parent node. So, if you
            had a table that was a wooden object, a black object, a flat object, and
            so on, you have to choose one, and that’s the only parent it could have.
            When, of course, you know, depending on what it is you need to reason
            about, sometimes it’s important to know that it’s made out of wood, like
            if we’re talking about a fire. Sometimes it’s important to know that
            it’s flat if we’re talking about resting something on it, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，嗯，其中一个问题是他们想要一种杜威十进制编号系统来记录所有的概念，这意味着每个节点最多只能有 10 个子节点，每个节点只能有一个父节点。虽然这确实可以实现杜威十进制类型的概念编号，标记概念，但它阻止你表示我们世界中物体的所有信息。这是他们永远无法克服的问题之一。我认为这是该项目失败的主要原因之一。</font></font></p><p>So, um, one of the problems was that they wanted a kind of Dewey
            Decimal numbering system for all of their concepts, which meant that
            each node could only have at most 10 children, and each node could only
            have one parent. While that does enable the Dewey Decimal type numbering
            of concepts, labeling of concepts, it prevents you from representing all
            the things you need to about objects in our world. And that was one of
            the things which they never were able to overcome. And I think that was
            one of the main reasons that that project failed.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，我们会回到你打开过的一些门，但如果我们可以回到 1984 年的那个房间，在那里，和 Marvin Minsky 和 ​​Stafford......</font></font></p><p>So, we’ll return to some of the doors you’ve opened, but if we can go
            back to that room in 1984, around there, with Marvin Minsky and
            Stafford…</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但顺便说一句，我应该说一下，马文不会做他的估算，直到有人给他拿来一个信封，这样他才能在信封背面进行计算，得出他的数字。嗯，因为我……我觉得那个房间里的谈话很重要，你知道。有时科学就是这样做的。几个人聚在一起，种下思想的种子，它们在历史中回荡。有些……有些消散了，消失了。还有一些，你知道，德雷克方程，你知道，他们……你知道……看起来像一个毫无意义的方程，有点毫无意义，但我认为它驱动和激励了很多科学家。当外星人最终出现时，这个方程将变得更有价值，因为那时我们将能够……在漫长的历史长河中，德雷克方程将得到回报……我认为将被证明非常有用。</font></font></p><p>But by the way, I should mention that Marvin wouldn’t do his estimate
            until someone brought him an envelope so that he could literally do a
            back of the envelope calculation to come up with his number. Well,
            because I… I feel like the conversation in that room is an important
            one, you know. This is how sometimes science is done in this way. A few
            people get together and plant the seed of ideas, and they reverberate
            throughout history. And some… some kind of dissipate and disappear. And
            some, you know, the Drake equation, and you know, they… you know… seems
            like a meaningless equation, somewhat meaningless, but I think it drives
            and motivates a lot of scientists. And when the aliens finally show up,
            that equation will get even more valuable, because then we’ll be able
            to… in the long arc of history, the Drake equation will pay… will prove
            to be quite useful, I think.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">同样，关于需要多少事实才能捕捉到世界的基本常识的讨论……这是一个有趣的问题。我想区分你认为的事实和我们所代表的东西。因此，我们映射到 Cyc，并确保它能够读取和访问你可能在 Wikidata 中找到的或维基百科文章中陈述的事实或类似的东西。</font></font></p><p>And in that same way, the conversation of just how many facts are
            required to capture the basic common sense knowledge of the world…
            that’s a fascinating question. I want to distinguish between what you
            think of as facts and the kind of things that we represent. So, we map
            to and essentially make sure that Cyc has the ability to, as it were,
            read and access the kind of facts you might find, say, in Wikidata or
            stated in a Wikipedia article or something like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，我们所代表的……我们需要的少数东西（数千万）更像是经验法则、良好猜测的规则，这些通常是正确的东西，可以帮助您理解存在于某个数据库或其他更静态的存储中的事实。所以，它们几乎就像柏拉图式的形式。所以，当你在维基百科上阅读内容时，它们就像是这些想法的投影。你读到一篇关于猫王去世的文章；这是对人类终有一死这一想法的投影。而且，很少有维基百科文章会准确地写出“人类终有一死”。这就是我所说的找出文本中未说明的内容。所有假设的事情是什么？</font></font></p><p>So, what we’re representing… the things that we need a small number
            of—tens of millions of—are more like rules of thumb, rules of good
            guessing, things which are usually true and which help you to make sense
            of the facts that are on sort of sitting off in some database or some
            other more static store. So, they’re almost like platonic forms. So,
            like when you read stuff on Wikipedia, that’s going to be like
            projections of those ideas. You read an article about the fact that
            Elvis died; that’s a projection of the idea that humans are mortal. And,
            like, very few Wikipedia articles will write “humans are mortal”
            exactly. And that’s what I meant about finding out the unstated things
            in text. What are all the things that were assumed?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，这些事情包括：如果你遇到某个问题，出于我们并不真正理解并且不满意的原因，将其关闭然后再打开通常可以解决问题；或者人不能同时活着和死去；或者水往低处流。如果你在线搜索“水往上流”和“水往下流”，你会发现更多关于“水往上流”的引用，因为它被用作某种不太可能发生的事情的隐喻。因为，当然，每个人都已经知道水往低处流。那么，为什么有人会费心这么说呢？你有你喜欢的词吗，因为我们说“事实”不是正确的词？有没有像“概念”这样的词......我会说“断言”或“规则”，因为我说的不是严格的规则，而是经验法则。但“断言”是一个很好的词，它涵盖了所有这些内容。</font></font></p><p>So, those are things like: if you have a problem with something,
            turning it off and on often fixes it, for reasons we don’t really
            understand and we’re not happy about; or people can’t be both alive and
            dead at the same time; or water flows downhill. If you search online for
            “water flowing uphill” and “water flowing downhill,” you’ll find more
            references for “water flowing uphill” because it’s used as a kind of a
            metaphorical reference for some unlikely thing. Because, of course,
            everyone already knows that water flows downhill. So, why would anyone
            bother saying that? Do you have a word you prefer, because we said
            “facts” isn’t the right word? Is there a word like “concepts” or… I
            would say “assertions” or “rules,” because I’m not talking about rigid
            rules, but rules of thumb. But “assertions” is a nice one that covers
            all of these things.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，作为一名程序员，对我来说，“断言”给他们一种非常教条、专制的感觉。对不起。真的很抱歉，但断言确实有效。所以，如果我们回到那个房间，和 Marvin Minsky 在一起，和你一起，和所有这些开创性的人物一起——呃，Ed，你在思考这个非常哲学但也是工程学的问题——我们也可以回到那之前的几十年，广泛地思考人工智能。当人们思考如何创造超级智能系统、通用智能时，我认为当时人们的直觉是错误的。</font></font></p><p>Yeah, as a programmer, to me, “assert” has a very dogmatic,
            authoritarian feel to them. I’m sorry. I’m so sorry, okay, but
            assertions work okay. So, if we go back to that room with Marvin Minsky,
            with you, all these seminal figures—uh, Ed, you thinking about this very
            philosophical but also engineering question—we can also go back a couple
            of decades before then and thinking about artificial intelligence
            broadly. When people were thinking about, you know, how do you create
            super intelligent systems, general intelligence, I think people’s
            intuition was off at the time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我的意思是，这种情况一直存在，当我们努力理解这些极其困难的想法时，我们并不总是这样，当我们思考人类的思想时，我们很难真正理解自己。反思一下，设计智能、解决智能有多难，我们不太擅长估计这一点。而您是几十年来一直在思考这个问题的人。您——从 1984 年到今天，您的感觉是什么？您是否对需要多少知识有了更强烈的认识？</font></font></p><p>And I mean, this continues to be the case that we’re not—when we’re
            grappling with these exceptionally difficult ideas—we’re not always,
            it’s very difficult to truly understand ourselves when we’re thinking
            about the human mind. To introspect, how difficult it is to engineer
            intelligence, to solve intelligence, we’re not very good at estimating
            that. And you are somebody who has really stayed with this question for
            decades. Do you—what’s your sense from 1984 to today? Have you gotten a
            stronger sense of just how much knowledge is required?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，您肯定地说，这个数量级仍然是几千万，对吧？在最初几年，我会说这个数量级是一两百万。是的。所以我们花了大约五六年的时间才意识到我们相差了 10 倍。但我想问的是：您知道，马文·明斯基在 60 年代非常有信心。您什么时候说是的，对吧？如果 200 年后，您仍然，您知道，您将不再处于这个特定的生物体中，但您的大脑仍将以数字形式存在，而您将回首往事，您会觉得今天您很聪明吗？您的直觉是正确的，还是您认为您可能真的错了？</font></font></p><p>So, you’ve kind of said with some level of certainty that still the
            order of magnitude of tens of millions, right? For the first several
            years, I would have said that it was on the order of one or two million.
            Yeah. And so it took it took us about five or six years to realize that
            we were off by a factor of 10. But I guess what I’m asking: you know,
            Marvin Minsky was very confident in the 60s. When you say yes, right?
            What’s your sense if you, you know, 200 years from now, you’re still,
            you know, you’re you’re not going to be any longer in this particular
            biological body, but your brain will still be in the digital form, and
            you’ll be looking back. Would you think you were smart today? Like your
            intuition was right, or do you think you may be really off?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为我是对的。让我解释一下我的意思。有时候，就像你有一个老式泵，你必须给泵注水。是的，然后它最终会启动。所以，我认为我是对的，因为为了给泵注水——我们已经建造了它，即使它不是你需要的一切——它已经给知识泵注了足够的水，以至于 Cyc 现在可以通过阅读和理解，偶尔像学生一样提问，或者通过做实验和自己发现事物等方式，帮助自己自动学习更多东西。</font></font></p><p>I think I’m right enough. And let me explain what I mean by that.
            Which is sometimes, like if you have an old fashioned pump, you have to
            prime the pump. Yeah, and then eventually it starts. So, I think I’m
            right enough in the sense that to prime the pump—what we’ve built, even
            if it isn’t, so to speak, everything you need—it’s primed the knowledge
            pump enough that Cyc can now itself help to learn more and more
            automatically on its own by reading things and understanding and
            occasionally asking questions like a student would, or something, and by
            doing experiments and discovering things on its own, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，通过结合 Cyc 驱动的发现和 Cyc 驱动的阅读，它将能够自我引导。也许是最后的 2%，也许是最后的 99%。所以，即使我错了，我真正需要做的就是建立一个系统，该系统已经为泵做好了足够的准备，可以开始向上级联，这种自我强化的二次甚至指数增长的路径，例如，我们从彼此交谈中获得的路径。这就是为什么今天的人类比 10 万年前的人类知道得多。</font></font></p><p>So, through a combination of Cyc powered discovery and Cyc powered
            reading, it will be able to bootstrap itself. Maybe it’s the final 2%,
            maybe it’s the final 99%. So, even if I’m wrong, all I really need to do
            to build is a system which has primed the pump enough that it can begin
            that cascade upward, that self reinforcing sort of quadratically or
            maybe even exponentially increasing path upward that we get from, for
            instance, talking with each other. That’s why humans today know so much
            more than humans 100,000 years ago.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们其实并不比 10 万年前的人聪明多少，但知识却丰富得多。我们有语言，可以交流；我们可以在 Google 上查东西等等。所以，实际上，我们拥有这种巨大的力量，只要你想，你可以学到的东西几乎没有限制，因为你对世界的理解已经达到了一定的水平，这让你能够阅读所有这些文章并理解它们。这让你能够出去，如果有必要，可以做实验，尽管这是一种收集数据等的方式，速度较慢。</font></font></p><p>We’re not really that much smarter than people were 100,000 years
            ago, but there’s so much more knowledge. And we have language and we can
            communicate; we can check things on Google and so on. So, effectively,
            we have this enormous power at our fingertips, and there’s almost no
            limit to how much you could learn if you wanted to, because you’ve
            already gotten to a certain level of understanding of the world that
            enables you to read all these articles and understand them. That enables
            you to go out and, if necessary, do experiments, although that’s slower
            as a way of gathering data and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为这一点非常重要，即：如果我们拥有人工智能——真正的通用人工智能，人类级别的人工智能——那么人类将变得更聪明。这并不是说我们将与人工智能对抗；更像是我们和人工智能一起能够做需要更多创造力的事情，而这些事情目前需要花费太长时间。但我们将能够同时做很多事情。我们将能够减少彼此的误解。对于个人来说，各种各样的价值实际上意味着该个人在所有意图和目的上都将变得更聪明。这意味着人类作为一个物种将变得更聪明。</font></font></p><p>And I think this is really an important point, which is: if we have
            artificial intelligence—real general artificial intelligence, human
            level artificial intelligence—then people will become smarter. It’s not
            so much that it’ll be us versus the AIs; it’s more like us and the AIs
            together will be able to do things that require more creativity that
            would take too long right now. But we’ll be able to do lots of things in
            parallel. We’ll be able to misunderstand each other less. There’s all
            sorts of value that effectively, for an individual, would mean that that
            individual will, for all intents and purposes, be smarter. And that
            means that humanity as a species will be smarter.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">上一次有发明在质量上对人类智力产生巨大影响是什么时候？你必须回溯很久以前。它不是像互联网、计算机或数学之类的东西。它一直追溯到语言的发展。我们也可以回顾前语言时代的穴居人。你知道，他们并不是真正的聪明人，不是吗？他们不是真正的人类，不是吗？</font></font></p><p>When was the last time that any invention qualitatively made a huge
            difference in human intelligence? You have to go back a long way. It
            wasn’t like the internet or the computer or mathematics or something. It
            was all the way back to the development of language. We sort of look
            back on pre linguistic cavemen as well. You know, they weren’t really
            intelligent, were they? They weren’t really human, were they?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为，正如你所说，从现在起 50 年、100 年或 200 年后，人们会回顾今天的人们，回顾在这些终生通用人工智能出现之前的人们，并说：“你知道，那些可怜的人——他们并不是真正的人类，不是吗？”</font></font></p><p>And I think that as you said, 50, 100, 200 years from now, people
            will look back on people today, right before the advent of these sort of
            lifelong general AI muses, and say, “You know, those poor, those poor
            people—they weren’t really human, were they?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">嗯，确实如此。</font></font></p><p>Mmm, exactly.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">顺便说一句，你说了很多非常有趣的事情。我可能会试图论证说，互联网的进步与语言的发明一样巨大。当然，这是一个方向的飞跃。我们不确定是向上还是向下。</font></font></p><p>So, you said a lot of really interesting things, by the way. I would
            maybe try to argue that the internet is on the order of the kind of big
            leap in improvement that the invention of language was. Certainly, a big
            leap in one direction. We’re not sure whether it’s upward or
            downward.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">嗯，我的意思是，互联网的某些特定部分，即获取信息，例如维基百科这样的网站，例如世界各地的人们能够如此快速地获取信息。因此，我可以支持这一论点的任何一方，既然您只支持一方，那么我就给您另一方，即几乎没有什么比互联网和获取信息更有害。有两种方式：一是它使人们在全球范围内变得更加无知，就像计算器使我们或多或少变得无知一样。所以，在我成长的过程中，我们必须使用计算尺；我们必须能够估算。</font></font></p><p>Well, I mean, very specific parts of the internet, which is access to
            information—like a website like Wikipedia, like the ability for human
            beings from across the world to access information so very quickly. So,
            I could take either side of this argument, and since you just took one
            side, I’ll give you the other side, which is that almost nothing has
            done more harm than something like the internet and access to that
            information. In two ways: one is it’s made people more globally
            ignorant, in the same way that calculators made us more or less
            ignorant. So, when I was growing up, we had to use slide rules; we had
            to be able to estimate.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，等等。如今，人们并不真正理解数字；他们并不真正理解数学；他们根本不擅长估算。等等。他们并不真正理解万亿、数十亿和数百万之间的区别，因为计算器可以帮我们计算。多亏了互联网和搜索引擎等东西，同样的青少年特质得到了强化，让人们能够过上一辈子，不仅不会算术和估算，而且现在实际上几乎不需要真正了解任何东西，因为任何时候他们需要知道什么，他们都会去查，对吧？</font></font></p><p>Yeah, and so on. Today, people don’t really understand numbers; they
            don’t really understand math; they don’t really estimate very well at
            all. And so on. They don’t really understand the difference between
            trillions, billions, and millions, and so on, very well, because
            calculators do that all for us. And thanks to things like the internet
            and search engines, that same kind of juvenilis is reinforced, in making
            people essentially be able to live their whole lives not just without
            being able to do arithmetic and estimate, but now without actually
            having to really know almost anything, because anytime they need to know
            something, they’ll just go and look it up, right?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我可以告诉你，你可以从两个方面来看待这个问题，这是一把双刃剑。当然，你也可以对语言说同样的话。也许，当人们发明语言时，他们会批评。你知道，以前我们只是——如果我们生气了，我们会杀了人；如果我们恋爱了，我们会和他们发生性关系。而现在每个人都在写诗和胡说八道，你知道。你应该直接一点；你应该有身体接触。</font></font></p><p>And I could tell you, you could play both sides of this, and it is a
            double edged sword. You can, of course, say the same thing about
            language. Probably, people, when they invented language, would
            criticize. You know, it used to be we would just—if we’re angry, we
            would just kill a person; and if we’re in love, we would just have sex
            with them. And now everybody’s writing poetry and bullshit, you know.
            You should just be direct; you should like have physical contact.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">够了，这些话和书就够了。而且，如果你读了一本书，你实际上并没有体验到它。这是胡说八道。没错。如果你读了一本关于如何制作黄油的书，这与你必须学习并自己动手做等是不一样的。所以，我们只能说，每当你对技术产生这种依赖时，你会有所收获，但也会有所损失。</font></font></p><p>Enough of this words and books. And it’s—you’re—you’re not actually
            experiencing like, if you read a book, you’re not experiencing the
            thing. This is nonsense. That’s right. If you read a book about how to
            make butter, that’s not the same as if you had to like learn it and do
            it yourself, and so on. So, so let’s just say that something is gained,
            but something is lost every time you have these sorts of dependencies on
            technology.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">总的来说，我认为拥有更聪明的个体和更聪明的人工智能增强人类物种将是我们能够真正克服一些全球性问题的少数方法之一，这些问题包括贫困、饥饿、全球变暖和过度拥挤——所有其他困扰地球的问题。我们真的需要变得更聪明。而变得更聪明的途径实际上只有两条：一条是通过生物化学和遗传学——基因工程；另一条是通过拥有增强我们智力的通用人工智能。</font></font></p><p>And overall, I think that having smarter individuals and having
            smarter AI augmented human species will be one of the few ways that
            we’ll actually be able to overcome some of the global problems we have,
            involving poverty, starvation, global warming, and overcrowding—all the
            other problems that are besetting the planet. We really need to be
            smarter. And there are really only two routes to being smarter: one is
            through biochemistry and genetics—genetic engineering; the other route
            is through having general AIs that augment our intelligence.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你知道，希望在为时已晚之前，这两种拯救方法中的一种能够实现。是的，绝对如此。我同意你的观点。显然，作为一名工程师，我对技术方面有更好的理解和乐观态度，因为你可以控制那里的事情。更多的生物学就是一个巨大的混乱。我们现在正在经历一场大流行。大自然有太多的方式可以破坏，甚至在你没有注意到的情况下破坏。</font></font></p><p>And you know, hopefully, one of those two paths to salvation will
            come through before it’s too late. Yeah, absolutely. I agree with you.
            And obviously, as an engineer, I have—I have a better sense and an
            optimism about the technology side of things, because you can control
            things there. More biology is just such a giant mess. We’re living
            through a pandemic now. There are so many ways that nature can just be
            just destructive and destructive in a way where it doesn’t even notice
            you.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你不会；这不像是人类与病毒的战斗；就像，嗯，好吧。然后你可能会消灭整个物种。互联网的另一个问题是，它让我们能够被一个回音室包围，一个志同道合的人组成的泡沫。这意味着你可以有真正奇怪的理论、阴谋论、假新闻等等，这些理论、阴谋论、假新闻等等，这些理论和假新闻会传播开来，并让你被那些本质上强化你想要相信或你已经相信的世界的人包围。</font></font></p><p>You’re not; it’s not like a battle of humans versus viruses; it’s
            just like, huh, okay. And then you could just wipe out an entire
            species. The other problem with the internet is that it has enabled us
            to surround ourselves with an echo chamber, a bubble of like minded
            people. This means that you can have truly bizarre theories, conspiracy
            theories, fake news, and so on, promulgate and surround yourself with
            people who essentially reinforce what you want to believe or what you
            already believe about the world.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">在过去，这要困难得多。当你只有三个电视网络时，甚至更早，当你没有电视网络时，你必须真正地观察世界并做出自己的理性决定。我喜欢我们舞蹈中的推拉动作，因为那时我只想说，在旧世界，来自苏联，因为你有一个或几个网络，所以宣传可能更有效。</font></font></p><p>In the old days, that was much harder to do. When you had, say, only
            three TV networks, or even before, when you had no TV networks, and you
            had to actually look at the world and make your own reasoned decisions.
            I like the push and pull of our dance that we’re doing, because then
            I’ll just say, in the old world, having come from the Soviet Union,
            because you had one or a couple of networks, then propaganda could be
            much more effective.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">然后政府就可以压制人民，告诉人们真相，然后让数百万人挨饿、受折磨、把数百万人关进集中营、发动战争。有了宣传机器，人们就会相信自己在为世界做善事。有了互联网，因为所有的阴谋论，其中一些实际上正在挑战权力中心，而这些权力中心在一个世纪前会导致数百万人死亡。</font></font></p><p>And then the government can overpower its people by telling you the
            truth and then starving millions, and torturing millions, and putting
            millions into camps, and starting wars. With a propaganda machine,
            allowing you to believe that you’re actually doing good in the world.
            With the internet, because of all the, quote unquote, conspiracy
            theories, some of them are actually challenging the power centers, the
            very kind of power centers that a century ago would have led to the
            death of millions.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这又是一把双刃剑。我非常同意你关于人工智能的观点。人们通常有一种直觉，认为人工智能可能会被某些特定群体用来压制人类。对我来说，这种情况并不明显。对我来说，可能的情况是，尤其是在观察了技术的发展轨迹之后，它将被用来赋予人们权力。它将被用来扩展世界各地个人的能力，因为这样可以赚很多钱，比如改善人们的生活。</font></font></p><p>So, there’s a—it’s again this double edged sword. And I very much
            agree with you on the AI side. It’s often an intuition that people have
            that somehow AI will be used to maybe overpower people by certain select
            groups. To me, it’s not at all obvious that that’s the likely scenario.
            To me, the likely scenario, especially just having observed the
            trajectory of technology, is that it’ll be used to empower people. It’ll
            be used to extend the capabilities of individuals across the world,
            because there’s a lot of money to be made that way, like improving
            people’s lives.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你可以赚很多钱。我同意。我认为人工智能假肢、人工智能放大器对人们最主要的作用是让他们更容易、甚至不可避免地进行良好的批判性思考。因此，指出他们原本会盲目相信的事情中的逻辑谬误、逻辑矛盾等等。指出他们应该考虑的、如果他们真的想了解某件事的真相，等等。</font></font></p><p>You can make a lot of money. I agree. I think that the main, the main
            thing that AI prostheses, AI amplifiers, will do for people is make it
            easier, maybe even unavoidable, for them to do good critical thinking.
            So, pointing out logical fallacies, logical contradictions, and so on,
            in things that they otherwise would just blindly believe. Pointing out
            essentially data which they should take into consideration if they
            really want to learn the truth about something, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，我认为教育不仅仅是将事实灌输到人们的头脑中，而且是让人们具备批判性思维能力的教育，这种教育具有巨大的力量。美国和世界各地的教育系统在这方面通常做得并不好。但我相信人工智能，人工智能，人工智能将会——就像每个人都可以拥有自己的 Alexa、Siri 或 Google Assistant 或其他东西一样，每个人都将拥有这种从摇篮到坟墓的助手，它会了解你。你会信任它。</font></font></p><p>So, I think doing not just educating in the sense of pouring facts
            into people’s heads, but educating in the sense of arming people with
            the ability to do good critical thinking is enormously powerful. The
            education system that we have in the US and worldwide generally don’t do
            a good job of that. But I believe that AI, the AI, the AI will—the AI
            can and will, the same way that everyone can have their own Alexa or
            Siri or Google Assistant or whatever, everyone will have this sort of
            cradle to grave assistant which will get to know you. You’ll get to
            trust it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">它会塑造你，你也会塑造它。如果你听从它，它会让你注意到一些事情，从某种意义上说，这些事情会让你的生活更美好、更轻松、更少错误、更少遗憾。是的，我完全同意你对这个技术领域的看法，我认为这非常令人兴奋。从我的角度来看，将情商——甚至是友谊、陪伴和爱情之类的东西——融入这些系统，而不是帮助你作为一个人的智力成长，而是让你在情感上成长，这最终会让生活变得精彩。这是对幸福的追求，你知道，对幸福的古老追求。所以这不仅仅是对理性的追求；这也是对幸福的追求。是的，全方位的。</font></font></p><p>It’ll model you; you’ll model it. And it’ll call to your attention
            things which will, in some sense, make your life better, easier, less
            mistake ridden, and so on, less regret ridden, if you listen to it.
            Yeah, I’m in full agreement with you about this space of technologies,
            and I think it’s super exciting. And from my perspective, integrating
            emotional intelligence—so even things like friendship, companionship,
            and love—into those kinds of systems, as opposed to helping you just
            grow intellectually as a human being, allows you to grow emotionally,
            which is ultimately what makes life amazing. It’s the pursuit of
            happiness, you know, the old pursuit of happiness. So it’s not just the
            pursuit of reason; it’s the pursuit of happiness too. Yes, the full
            spectrum.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">好吧，既然你提到了这么多有趣的事情，让我回到自动推理的想法上。</font></font></p><p>Well, let me sort of—because you mentioned so many fascinating
            things—let me jump back to the idea of automated reasoning.</p>
        <h2 id="automated-reasoning"><font style="vertical-align:inherit"><font style="vertical-align:inherit">自动推理</font></font></h2><h2>Automated reasoning</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，新知识的获取方式非常有趣，但主要是由人类完成的。是的，你可以想象中世纪欧洲僧侣在牢房里仔细地绘制手稿等等。这实际上是一个非常困难和神奇的过程，因为它让你真正地问出关于空白处的问题：假设是什么？我认为这种练习就像很少有人能正确做到这一点；他们只是下意识地这样做。</font></font></p><p>So the acquisition of new knowledge has been done in this very
            interesting way, but primarily by humans doing this. Yes, you could
            think of monks in their cells in medieval Europe, you know, carefully
            illuminating manuscripts and so on. It’s a very difficult and amazing
            process actually, because it allows you to truly ask the question about
            the in the white space: What is assumed? I think this exercise is like
            very few people do this right; they just do it subconsciously.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">根据定义，他们之所以这样做，是因为那些被省略的信息和缺失的步骤都是常识。如果你真的把它们都包括进去，那几乎会让读者感到冒犯或困惑。就像是，“他们为什么要告诉我这些事情？当然，我知道你知道这些事情。”所以，这是其中一件几乎从本质上来说从未在任何地方明确写下来的事情，因为当你长大到可以和其他人交谈的时候，你知道，如果你活到了那个年龄，想必你已经有了一些常识，比如，你知道，如果某件事让你每次做都会感到痛苦，那么继续做下去可能不是一个好主意。</font></font></p><p>They perform this, by definition, because those pieces of elided, of
            omitted information, of those missing steps, as it were, are pieces of
            common sense. If you actually included all of them, it would—it would
            almost be offensive or confusing to the reader. It’s like, “Why are they
            telling me all these things? Of course, I know that you know all these
            things.” And so, so it’s one of these things which almost by its very
            nature has almost never been explicitly written down anywhere, because
            by the time you’re old enough to talk to other people and so on, you
            know, if you survived to that age, presumably you already got pieces of
            common sense, like, you know, if something causes you pain whenever you
            do it, probably not a good idea to keep doing it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，考虑到这一步的难度，您有什么想法？您有什么想法可以自动完成这一步，而无需使用人类，或者至少不用人类做大部分工作，而人类只做非常高水平的监督工作？事实上，我们目前在 Cyc 大力推进两个方向。一个涉及自然语言理解和阅读人们明确写下的内容并以此方式提取知识的能力，另一个是构建一系列知识编辑工具、知识输入工具、知识捕获工具、知识测试工具等。将它们视为软件工具的用户界面套件。如果您想要某种东西可以帮助人们或多或少自动扩展和扩展系统，例如，他们想要构建一些应用程序或类似的东西。</font></font></p><p>So, what ideas do you have, given how difficult this step is? What
            ideas are there for how to do it automatically, without using humans, or
            at least not, you know, doing like a large percentage of the work for
            humans, and then humans only do the very high level supervisory work?
            So, we have, in fact, two directions we’re pushing on very, very heavily
            currently at Cyc. One involves natural language understanding and the
            ability to read what people have explicitly written down and to pull
            knowledge in that way, but the other is to build a series of knowledge
            editing tools, knowledge entry tools, knowledge capture tools, knowledge
            testing tools, and so on. Think of them as a user interface suite of
            software tools. If you want something that will help people to more or
            less automatically expand and extend the system in areas where, for
            instance, they want to build some application or something like
            that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我来举个例子，这就是所谓的溯因推理。你可能听说过演绎推理、归纳推理等等。但溯因推理与它们不同。溯因推理不是合理的，只是有用而已。</font></font></p><p>So, I’ll give you an example of one, which is something called
            abduction. So, you’ve probably heard of deduction, uh, and induction,
            and so on. But abduction is unlike those. Abduction is not sound; it’s
            just useful.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">例如，从演绎上来说，如果有人在雨中，浑身会被淋湿，当他们进入房间时，他们可能会全身湿透，等等。所以，这是演绎。但是，如果有人现在走进房间，浑身湿透，我们会立即向外看，说：“哦，开始下雨了还是什么？”现在，为什么我们会说可能开始下雨了？这不是一个合理的逻辑推论，但肯定是一个合理的溯因跳跃，说一个人全身湿透的最常见原因之一是他们被雨淋湿了或类似的事情。</font></font></p><p>For instance, deductively, if someone is out in the rain and they’re
            going to get all wet, and when they enter a room, they might be all wet,
            and so on. So, that’s deduction. But if someone were to walk into the
            room right now and they were dripping wet, we would immediately look
            outside to say, “Oh, did it start to rain or something like that?” Now,
            why did we say maybe it started to rain? That’s not a sound logical
            inference, but it’s certainly a reasonable abductive leap to say well,
            one of the most common ways that a person would have gotten dripping wet
            is if they had gotten caught out in the rain or something like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，这和我们讨论的内容有什么关系呢？假设你正在构建其中一个应用程序，而系统给出了错误的答案。你说：“哦，是的，这个问题的答案是这个，而不是你想出的那个。”那么系统可以做的是，它可以使用它已经知道的所有常识、一般知识、你已经告诉它的领域和上下文（就像我们讨论过的一样）等等。然后说：“好吧，这里有七种选择，根据我已经知道的一切，我相信每一种都是合理的。如果这七件事中的任何一件是真的，我就会得出你刚刚给我的答案，而不是我得出的错误答案。”这七件事中有一件是真的吗？然后你，作为专家，会看着这七件事说：“哦，是的，第五个答案实际上是真的。”</font></font></p><p>So, what does that have to do with what we were talking about?
            Suppose you’re building one of these applications, and the system gets
            some answer wrong. And you say, “Oh, yeah, the answer to this question
            is this one, not the one you came up with.” Then what the system can do
            is it can use everything it already knows about common sense, general
            knowledge, the domain you’ve already been telling it about, and context,
            like we talked about, and so on. And say, “Well, here are seven
            alternatives, each of which I believe is plausible given everything I
            already know. And if any of these seven things were true, I would have
            come up with the answer you just gave me instead of the wrong answer I
            came up with.” Is one of these seven things true? And then you, the
            expert, will look at those seven things and say, “Oh, yeah, number five
            is actually true.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，实际上无需在逻辑断言等方面进行修改，您就可以以与帮助教育您要教的其他人或类似人员相同的方式教育系统。因此，这大大减少了脑力劳动或大大提高了教师（确切地说是人类教师）的效率。它使几乎任何人都能以这种方式成为教师。</font></font></p><p>So, without actually having to tinker down at the level of logical
            assertions and so on, you’ll be able to educate the system in the same
            way that you would help educate another person whom you were trying to
            apprentice or something like that. So, that significantly reduces the
            mental effort or significantly increases the efficiency of the teacher,
            the human teacher, exactly. And it makes more or less anyone able to be
            a teacher in that way.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这就是答案的一部分。另一个是，系统本身将能够通过阅读与其他人的对话等，以与您或我或其他人类相同的方式学习。首先，这是一个美好的愿景。我稍后要问您有关语义网的问题。但首先，当我们谈论具体技术时，您是否从整个机器学习、深度学习领域中找到了鼓舞人心或直接有用的东西，这些技术领域在最近十年左右已被证明对某些类型的问题有效？</font></font></p><p>So, that’s that’s part of the answer. And then the other is that the
            system on its own will be able to, through reading through conversations
            with other people and so on, learning the same way that you or I or
            other humans do. First of all, that’s a beautiful vision. And I’ll have
            to ask you about the semantic web in a second. But first, are there,
            when we talk about specific techniques, do you find something inspiring
            or directly useful from the whole space of machine learning, deep
            learning, these kinds of spaces of techniques that have been shown
            effective for certain kinds of problems in the recent now decade or
            so?</p>
        <h2 id="direct-uses-of-ai-and-machine-learning"><font style="vertical-align:inherit"><font style="vertical-align:inherit">人工智能和机器学习的直接应用</font></font></h2><h2>Direct uses of AI and
            machine learning</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为机器学习的工作或多或少就是我们右脑的工作。它能够获取大量数据并识别模式，能够从统计上推断事物，等等。你知道，我当然不想没有右脑，但我也很高兴我有一个左脑。它可以比喻性地坐下来，抽着烟斗思考这件事。比如，为什么这可能是真的，这意味着什么？我应该对此有何感受，为什么，等等？所以思考得更深、更慢，柯南称之为慢思考而不是快思考。你希望机器学习能够快速思考，但你也希望它有深入思考的能力，即使速度慢一点。</font></font></p><p>I think of machine learning work as more or less what our right brain
            hemispheres do. So being able to take a bunch of data and recognize
            patterns, being able to statistically infer things, and so on. And you
            know, I certainly wouldn’t want to not have a right brain hemisphere,
            but I’m also glad that I have a left brain hemisphere as well. Something
            that can metaphorically sit back and puff on its pipe and think about
            this thing over here. It’s like, why might this have been true, and what
            are the implications of it? How should I feel about that, and why, and
            so on? So thinking more deeply and slowly, what Conan called thinking
            slowly versus thinking quickly. Whereas you want machine learning to
            think quickly, but you want the ability to think deeply, even if it’s a
            little slower.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我举个例子，我们最近与 NIH 合作开展了一个项目，该项目涉及克利夫兰诊所和其他几家我们为其开展项目的机构。该项目开展的是全基因组关联研究，即医院收治患者的大型数据库。患者需要对 DNA 进行测序，因为测序成本已从无穷大上升到数十亿美元，再上升到数百美元左右。因此，现在患者会定期进行 DNA 测序。因此，您拥有 SNP（单核苷酸多态性，患者 DNA 中的点突变）以及导致他们入院的疾病的大型数据库。因此，现在您可以进行相关性研究、机器学习研究，了解哪些突变与哪些生理问题和疾病相关，并导致这些疾病，例如关节炎等。</font></font></p><p>I’ll give you an example of a project we did recently with NIH,
            involving the Cleveland Clinic and a couple of other institutions that
            we ran a project for. What it did was it took genome wide association
            studies—those are sort of big databases of patients that came into a
            hospital. They got their DNA sequenced because the cost of doing that
            has gone from infinity to billions of dollars to hundreds of dollars or
            so. And so now patients routinely get their DNA sequenced. So you have
            these big databases of the SNPs—the single nucleotide polymorphisms, the
            point mutations in a patient’s DNA—and the disease that happened to
            bring them into the hospital. So now you can do correlation studies,
            machine learning studies, of which mutations are associated with and led
            to which physiological problems and diseases, and so on, like getting
            arthritis, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">问题是这些相关性非常虚假。它们非常嘈杂。其中很多都让医生徒劳无功，等等。所以他们想要一种方法来消除不好的相关性或专注于好的相关性。这就是 Cyc 的作用所在。Cyc 会从点突变和需要治疗的疾病之间获取从 A 到 Z 的相关性。嗯。我们会说，好吧，让我们利用所有这些关于人体中发生什么反应、什么聚合什么、什么催化什么反应等的公共知识和常识知识，让我们尝试整合出一个 10 步、20 步或 30 步的因果解释，说明为什么该突变可能导致该疾病。</font></font></p><p>The problem is that those correlations turn out to be very spurious.
            They turn out to be very noisy. Very many of them have led doctors onto
            wild goose chases, and so on. And so they wanted a way of eliminating
            the bad ones or focusing on the good ones. And so this is where Cyc
            comes in. Cyc takes those sort of a to z correlations between point
            mutations and medical conditions that need treatment. Mmm hmm. And we
            say, okay, let’s use all this public knowledge and common sense
            knowledge about what reactions occur where in the human body, what
            polymerizes what, what catalyzes what reactions, and so on, and let’s
            try to put together a 10 or 20 or 30 step causal explanation of why that
            mutation might have caused that medical condition.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，从某种意义上说，心理学家会将一些鲁布·戈德堡式的链条组合起来，说：“哦，是的，如果这种突变得到表达，就会产生这种改变的蛋白质，因此，如果这种蛋白质到达身体的这个部位，就会催化这种反应。”顺便说一句，这会导致人体血液中产生更多的生物活性维生素 D。”无论如何，10 个步骤之后，这会破坏骨吸收，这就是这个人早年患上骨质疏松症的原因，等等。所以，这是人类可以解释的，或者至少医生是人类可以解释的。</font></font></p><p>And so, psych would put together, in some sense, some Rube Goldberg
            like chain that would say, “Oh yeah, that mutation, if it got expressed,
            would be this altered protein, which, because of that, if it got to this
            part of the body, would catalyze this reaction.” And, by the way, that
            would cause more bioactive vitamin D in the person’s blood.” Anyway, 10
            steps later, that screws up bone resorption, and that’s why this person
            got osteoporosis early in life, and so on. So, that’s human
            interpretable, or at least doctors are human interpretable.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">没错。更重要的是，你不应该再相信那 20 步“鲁布·戈德堡”链，就像你不应该再相信最初的 A 到 Z 关联一样，除了以下两点：</font></font></p><p>Exactly. And the important thing, even more than that, is you
            shouldn’t really trust that 20 step “Rube Goldberg” chain any more than
            you trust that initial A to Z correlation, except for two things:</p>
        <ul>
            <li>
                <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果你甚至想不出一个因果链来解释这一点，那么这种相关性可能一开始就只是噪音。</font></font></p>
            </li><li>
                <p>If you can’t even think of one causal chain to explain this, then
                    that correlation probably was just noise to begin with.</p>
            </li>
            <li>
                <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">其次，更强大的是，在此过程中，因果谜题链将做出预测，例如关于血液中生物活性维生素 D 含量增加的预测。因此，您现在可以回顾这些患者的数据并说：“顺便问一下，他们血液中的生物活性维生素 D 水平是否略有升高？”等等。</font></font></p>
            </li><li>
                <p>Secondly, and even more powerfully, along the way, that causal
                    puzzle chain will make predictions, like the one about having more
                    bioactive vitamin D in your blood. So, you can now go back to the data
                    about these patients and say, “By the way, did they have slightly
                    elevated levels of bioactive vitamin D in their blood?” and so
                    on.</p>
            </li>
        </ul>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果答案是否定的，那么这强烈否定了你的整个因果链。如果答案是肯定的，那么这在一定程度上证实了因果链。</font></font></p><p>If the answer is no, that strongly disconfirms your whole causal
            chain. If the answer is yes, that somewhat confirms that causal
            chain.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">利用它，我们可以从这个“Guas”数据库中获取这些相关性，并且我们能够将医生的注意力、研究人员的注意力集中在有一定解释的极小比例的相关性上，甚至更好的是，这些解释还可以做出一些独立的预测，他们可以通过查看数据来确认或否定这些预测。</font></font></p><p>Using that, we were able to take these correlations from this “Guas”
            database, and we were able to, um, essentially focus the doctors’ focus,
            the researchers’ attention on the very small percentage of correlations
            that had some explanation, and even better, some explanation that also
            made some independent prediction that they could confirm or disconfirm
            by looking at the data.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，把它想象成这种协同作用，你希望右脑机器学习能够快速得出可能的答案。你希望左脑，也就是人工智能的心理学，能够思考这个问题，而不仅仅是思考为什么会出现这种情况，如果这是真的，还会有什么情况，等等，然后将问题反馈给右脑，让右脑快速再次检查。所以，这就是这种来回的协同作用，我认为这才是真正导致通用人工智能的原因，而不是狭隘、脆弱的机器学习系统，而不仅仅是心理学，好吗？</font></font></p><p>So, think of it like this kind of synergy, where you want the right
            brain machine learning to quickly come up with possible answers. You
            want the left brain, psych like AI to, you know, think about that and
            not just like think about why that might have been the case and what
            else would be the case if that were true, and so on, and then suggest
            things back to the right brain to quickly check out again. To, so it’s
            that kind of synergy back and forth, which I think is really what’s
            going to lead to general AI, not narrow, brittle machine learning
            systems, and not just something like psych, okay?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这是一个绝妙的协同作用，但我也在考虑知识库的自动扩展。你提到了 NLU。这是机器学习领域的早期发展，但自监督学习方法，你知道，你有这些语言模型、GPT 3 等等。他们只是阅读互联网，然后形成表示，然后可以将其映射到有用的东西上。问题是：什么是有用的东西？他们现在正在研究一个很酷的东西，叫做 Open Codex，它可以从文档中生成程序。</font></font></p><p>So, that’s a brilliant synergy, but I was also thinking in terms of
            the automated expansion of the knowledge base. You mentioned NLU. This
            is very early days in the machine learning space of this, but self
            supervised learning methods, you know, you have these language models,
            GPT 3, and so on. They just read the internet, and they form
            representations that can then be mapped to something useful. The
            question is: what is a useful thing? They’re now playing with a pretty
            cool thing called Open Codex, which is generating programs from
            documentation.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">好吧，这很有用；很酷。但我的问题是：它能否在人工监督下，部分用于生成类似心理学的断言？帮助从这个庞大的互联网数据体中为心理学提供更多断言？是的，事实上，这是我们的目标之一：我们如何利用机器学习，如何利用自然语言处理，来日益自动化知识获取过程，促进 Cyc 的发展？这就是我所说的启动泵。你知道，如果你学习你已经知道的东西的边缘知识，你会发现这个新东西与你已经知道的东西相似，这就是它们之间的差异和你必须学习的新东西，等等。</font></font></p><p>Okay, that’s kind of useful; it’s cool. But my question is: can it be
            used to generate, in part, maybe with some human supervision, psych like
            assertions? Help feed psych more assertions from this giant body of
            internet data? Yes, that is, in fact, one of our goals: how can we
            harness machine learning, how can we harness natural language
            processing, to increasingly automate the knowledge acquisition process,
            the growth of Cyc? And that’s what I meant by priming the pump. That you
            know, if you sort of learn things at the fringe of what you know
            already, you learn this new thing is similar to what you know already,
            and here are the differences and the new things you had to learn about
            it, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，你知道的越多，你就能越容易地学到新东西。但不幸的是，相反，如果你真的什么都不知道，那么就很难学到任何东西。所以，如果你不小心，如果你一开始的核心太小，那么这个过程就永远不会真正开始。所以，这就是为什么我把这看作是一种启动练习，以获得足够大的、手工生产的——即使这是一种丑小鸭技术，需要付出很多努力——来生产一个足够大的核心，这样你就可以用它做所有你想象的事情，而不会以我们在 GPT 3 中看到的那种古怪的脆弱性而告终，在那里——你知道，你会给它讲一个故事，你知道，某人密谋毒害某人，等等。</font></font></p><p>So, the more you know, the more and more easily you can learn new
            things. But unfortunately, inversely, if you don’t really know anything,
            it’s really hard to learn anything. And so, if you’re not careful, if
            you start out with too small of a core to start this process, it never
            really takes off. And so, that’s why I view this as a pump priming
            exercise to get a big enough, manually produced—even though that’s kind
            of an ugly duckling technique, put in the elbow grease—to produce a
            large enough core that you will be able to do all the kinds of things
            you’re imagining with it, without sort of ending up with the kind of
            wacky brittleness that we see, for example, in GPT 3, where it—you know,
            you’ll tell it a story about, you know, someone plotting to poison
            someone, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">然后，你知道，GPT 3 说，“哦，下一句话是什么？”下一句话是，“哦，是的，那个人喝了他们刚刚调配的毒药。”这就像，事情可能并非如此。或者，如果你去 Siri 问，“我可以在哪里寻求酒精问题的帮助，或者其他什么？”它会回复说，“我在你附近找到了七家酒类商店”，对吧？你知道，等等。所以，你知道，这是其中之一，是的，它可能在大多数情况下是有帮助的，它甚至可能在大多数情况下是正确的。</font></font></p><p>And then, you know, GPT 3 says, “Oh, what’s the very next sentence?”
            The next sentence is, “Oh, yeah, that person then drank the poison they
            just put together.” It’s like, that’s probably not what happened. Or, if
            you go to Siri and you know, “Where can I go for help with my alcohol
            problem, or something?” It’ll come back and say, “I found seven liquor
            stores near you,” right? You know, and so on. So, you know, it’s one of
            these things where yes, it may be helpful most of the time, it may even
            be correct most of the time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但是如果它不能真正理解自己所说的内容，如果它不能真正理解事物的真相，如果它不能真正理解世界是如何运转的，那么它有一部分时间会出错。现在，如果你的唯一目标是找到相关信息，就像搜索引擎一样，那么 90% 的时间都正确是非常棒的；这​​真是太棒了。但是，如果你的目标是挽救患有疾病的孩子的生命，你的目标是能够在接下来的 10,000 小时的驾驶中不发生致命事故，等等。那么，你知道，低至 10% 甚至 1% 的错误率是不可接受的。</font></font></p><p>But if it doesn’t really understand what it’s saying, and if it
            doesn’t really understand why things are true and doesn’t really
            understand how the world works, then some fraction of the time it’s
            going to be wrong. Now, if your only goal is to sort of find relevant
            information, like search engines do, then being right 90% of the time is
            fantastic; that’s unbelievably great. However, if your goal is to, you
            know, save the life of your child who has some medical problem, where
            your goal is to be able to drive, you know, for the next 10,000 hours of
            driving without getting into a fatal accident, and so on. Then, you
            know, error rates down at the 10% level or even the 1% level are not
            really acceptable.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我喜欢这种学习发生在边缘的模型，然后你可以把知识想象成一个球体。所以，如果你想要一个大球体，因为学习发生在表面，就是这样。所以，随着球体直径的增加，你可以学到的东西会成二次方增加。这很好，因为你会认为当你什么都不知道的时候，你什么都能学到。但事实并非如此。如果你什么都不知道，你真的什么都学不到。你可以假装学到东西。</font></font></p><p>I like the model of how that learning happens at the edge, and then
            you kind of think of knowledge as this sphere. So, if you want a large
            sphere, because the learning is happening on the surface, exactly. So,
            you have the what you can learn next increases quadratically as the
            diameter of that sphere goes up. It’s nice because you think when you
            know nothing, it’s like you can learn anything. But the reality is not
            really right. If you know nothing, you can really learn nothing. You can
            appear to learn.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我还会给你讲一个轶事，说明为什么我个人对此有如此强烈的感受。1980 年，我的女儿妮可出生了，她现在过得很好。但她还是个婴儿时，就被诊断出患有脑膜炎。医生们想做所有这些可怕的事情，我和我的妻子非常担心。我们无法从她的医生那里得到有意义的答案，关于他们为什么相信这一点，有什么替代方案，等等。幸运的是，我的朋友泰德·肖特利夫当时是斯坦福大学计算机科学系的另一位助理教授。</font></font></p><p>I’ll also give you one anecdote about why I feel so strongly about
            this personally. In 1980 81, my daughter, Nicole, was born, and she’s
            actually doing fine now. But when she was a baby, she was diagnosed with
            meningitis. Doctors wanted to do all these scary things, and my wife and
            I were very worried. We could not get a meaningful answer from her
            doctors about, exactly, why they believed this, what the alternatives
            were, and so on. Fortunately, a friend of mine, Ted Shortliffe, was
            another assistant professor in computer science at Stanford at the
            time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">他一直在开发一个名为 MYCIN 的程序，这是一个医学诊断程序，专门研究脑膜炎等血液感染。因此，他在斯坦福医院享有特权，因为他也是一名医学博士。所以我们拿到了她的病历并提交给她。它得出了完全相同的诊断和完全相同的治疗建议。但不同之处在于，因为它是一个基于知识的系统，一个基于规则的系统，它能够一步一步地告诉我们为什么这是诊断，一步一步地告诉我们为什么这是最好的治疗方法，对她来说最好的程序，等等。</font></font></p><p>He’d been building a program called MYCIN, which was a medical
            diagnosis program that happened to specialize in blood infections like
            meningitis. So, he had privileges at Stanford Hospital because he was
            also an MD. So, we got hold of her chart and put in her case. It came up
            with exactly the same diagnosis and exactly the same therapy
            recommendations. But the difference was, because it was a knowledge
            based system, a rule based system, it was able to tell us step by step
            why this was the diagnosis and step by step why this was the best
            therapy, the best procedure to do for her, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那是一个真正的顿悟，因为这让世界变得截然不同。我们不再盲目地相信权威，而是能够理解实际发生的事情。所以，那时我意识到，这正是计算机程序所缺少的。即使它们做对了，因为它们并不真正理解世界运作的方式以及事物为什么会这样，它们也无法解释它们的答案。你知道，使用机器学习系统来告诉你这是你应该做的，你知道，我认为你应该做这个手术，这是一回事。</font></font></p><p>There was a real epiphany because that made all the difference in the
            world. Instead of blindly having to trust in authority, we were able to
            understand what was actually going on. So, at that time, I realized that
            that really is what was missing in computer programs. Even if they got
            things right, because they didn’t really understand the way the world
            works and why things are the way they are, they weren’t able to give
            explanations of their answers. You know, it’s one thing to use a machine
            learning system that says this is what you should, you know, I think you
            should get this operation.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你问为什么，它说你知道 083，你又说不，更详细地说，为什么它说 0831。你知道，好吧。这真的不是很有说服力，也没什么帮助。这就是语义网的想法。</font></font></p><p>And you say why, and it says you know 083, and you say no, in more
            detail, why it says 0831. You know, okay. That’s not really very
            compelling, and that’s not really very helpful. There’s this idea of the
            Semantic Web.</p>
        <h2 id="the-semantic-web"><font style="vertical-align:inherit"><font style="vertical-align:inherit">语义网</font></font></h2><h2>The semantic web</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">当我第一次听说它时，我就爱上了这个想法。这显然是互联网的下一步。也许您可以谈谈什么是语义网？您对此有什么看法？您对 Cyc 的愿景、使命和目标是如何联系在一起、融为一体的——比如，它们是舞伴吗？它们是一致的吗？您对此有什么看法？</font></font></p><p>That, when I first heard about it, I just fell in love with the idea.
            It was the obvious next step for the internet, sure. And maybe you can
            speak about what is this Semantic Web? What are your thoughts about it?
            How your vision and mission and goals with Cyc are connected,
            integrated—like, are they dance partners? Are they aligned? What are
            your thoughts there?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，将语义网视为一种知识图谱。例如，谷歌已经有了他们称之为知识图谱的东西，它有点像节点和链接图。因此，您有这些代表概念、单词或术语的节点。然后有一些连接它们的弧，这些弧可能带有标签。因此，您可能有一个节点，例如，一个人代表一个人。假设一个“丈夫”链接指向该人的丈夫。因此，会有另一个从该人出发的链接，标记为“妻子”，返回到第一个节点，依此类推。</font></font></p><p>So, think of the Semantic Web as a kind of knowledge graph. And
            Google already has something they call a knowledge graph, for example,
            which is sort of like a node and link diagram. So, you have these nodes
            that represent concepts or words, or terms. And then there are some arcs
            that connect them, that might be labeled. So, you might have a node
            with, like, one person that represents one person. And let’s say a
            “husband” link that then points to that person’s husband. And so,
            there’d be then another link that went from that person, labeled “wife,”
            that went back to the first node, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，如果你想表示二元关系（本质上是两件事之间的关系），这种表示方法非常有用。如果你有相当于三个单词的句子，比如“弗雷德的妻子是威尔玛”之类的句子，你可以使用这类图形结构或使用语义网之类的东西很好地表示它。等等。</font></font></p><p>So, having this kind of representation is really good if you want to
            represent binary relations—essentially, relations between two things.
            And if you—if you have the equivalent of like three word sentences, you
            know, like “Fred’s wife is Wilma” or something like that, you can
            represent that very nicely using these kinds of graph structures, or
            using something like the Semantic Web. And so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但问题是，很多时候你想要表达的东西需要的远不止三个词，也远不止这些简单的图形结构。例如，如果你读过或看过《罗密欧与朱丽叶》，你知道，我可以问你这样的话：“还记得朱丽叶喝下药水后进入假死状态吗？当朱丽叶喝下药水时，她认为罗密欧听到别人说她死了会怎么想？”你基本上就能理解我在说什么了。</font></font></p><p>But the problem is that very often what you want to be able to
            express takes a lot more than three words, and a lot more than simple
            graph structures like that to represent. So, for instance, if you’ve
            read or seen Romeo and Juliet, you know, I could say to you something
            like, “Remember when Juliet drank the potion that put her into a kind of
            suspended animation? When Juliet drank that potion, what did she think
            that Romeo would think when he heard from someone that she was dead?”
            And you could basically understand what I’m saying.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你能理解这个问题。你可能还记得答案是，嗯，她以为这个修士会给罗密欧发消息，说她要这么做，但修士没有。所以，你能够表示和推理这些复杂得多的表达方式，这些表达方式远远超出了简单的三个、三个单词或四个单词的英语句子，而这才是语义网真正能够表示的，也是知识图谱真正能够表示的。</font></font></p><p>You could understand the question. You could probably remember the
            answer was, well, she thought that this Friar would have gotten a
            message to Romeo saying that she was going to do this, but the Friar
            didn’t. And so, so you’re able to represent and reason with these much,
            much more complicated expressions that go way, way beyond what simple
            three as it were, three word or four word English sentences are, which
            is really what the Semantic Web can represent, and really what knowledge
            graphs can represent.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果你能退后一步，因为你讲得非常具体，这很有趣，也许你可以详细阐述一下。但我还提到了语义网，即把互联网上的数据转换成机器可以解释和理解的东西。哦，当然。在这个层面上，我们应该说，什么是语义网？我的意思是，你可以说很多东西，但当很多人用谷歌搜索时，可能并不明显。</font></font></p><p>If you could step back for a second, because it’s funny you went into
            specifics, and maybe you can elaborate. But I was also referring to the
            Semantic Web as the vision of converting data on the internet into
            something that’s interpretable, understandable by machines. Oh, of
            course. At that level, so, so, I we should say, like, what is the
            semantic web? I mean, you could say a lot of things, but it might not be
            obvious to a lot of people when they do a Google search.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">就像你说的，虽然可能存在所谓的知识图谱，但它实际上归结为关键字搜索，根据网站质量评估对关键字搜索进行排名，该评估整合了之前人工进行的 Google 搜索以及他们认为有用的内容。这就像一些奇怪的表面黑客组合，效果非常好，但他们并不了解他们正在搜索的网站的全部内容。因此，就我们所说的程度而言，Google 并不了解搜索过程中 Wikipedia 页面的内容。语义网说：“让我们尝试想出一种方法，让计算机能够真正理解这些页面的内容。”这就是梦想。是的。</font></font></p><p>That just, like you said, while there might be something that’s
            called a knowledge graph, it really boils down to keyword search ranked
            by the quality estimate of the website integrating previous human based
            Google searches and what they thought was useful. It’s like some weird
            combination of like surface level hacks that work exceptionally well,
            but they don’t understand the full contents of the websites that they’re
            searching. So, Google does not understand, to the degree we’ve been
            talking about, the contents of Wikipedia pages as part of the search
            process. And the semantic web says, “Let’s try to come up with a way for
            the computer to be able to truly understand the contents of those
            pages.” That’s the dream. Yes.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，让我先给你讲一个轶事，然后我再回答你的问题。有一个名为 Northern Light 的搜索引擎你可能从未听说过。它已经倒闭了，但它的工作方式是一种经验搜索引擎。它所做的就是根本不索引互联网。它所做的只是与大型搜索引擎公司协商并获得有关输入了什么查询以及用户最终在哪里感到满意的数据。</font></font></p><p>So, let me first give you an anecdote, and then I’ll answer your
            question. So, there’s a search engine you’ve probably never heard of
            called Northern Light. It went out of business, but the way it worked
            was a kind of empirical search engine. And what it did was it didn’t
            index the internet at all. All it did was negotiate and get access to
            data from the big search engine companies about what query was typed in
            and where the user ended up being happy.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">实际上，你知道，他们输入的是完全不同的查询，无关的查询，等等。所以，它只是从查询转到最终似乎让他们满意的网页。仅此而已。所以，它实际上并不理解输入的内容。除了我刚才提到的，它没有其他统计数据，但它做得非常出色。它做得非常好，以至于大型搜索引擎公司说：“哦，我们不会再向你出售这些数据了。”所以，它破产了，因为它没有其他方式将用户带到他们想去的地方，等等。当然，搜索引擎现在正在使用这种想法。</font></font></p><p>And actually, then, you know, they type in a completely different
            query, an unrelated query, and so on. So, it just went from query to the
            web page that seemed to satisfy them eventually. And that’s all. So, it
            had actual no understanding of what was being typed in. It had no
            statistical data other than what I just mentioned, and it did a
            fantastic job. It did such a good job that the big search engine company
            said, “Oh, we’re not going to sell you this data anymore.” So, then it
            went out of business because it had no other way of taking users to
            where they wanted to go, and so on. Of course, the search engines are
            now using that kind of idea.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，让我们回到你所说的语义网。所以，Tim Berners Lee 和其他人对语义网的梦想，在一般层面上，当然是令人兴奋和强大的，从某种意义上说，是正确的梦想，即用更有意义、更语义的东西取代互联网上那种统计映射的链接，真正理解内容等等。最后，如果你说，“好吧，我们怎么做？”有一条低级的路，这就是知识图谱正在做的事情，等等。</font></font></p><p>Yes, so let’s go back to what you said about the semantic web. So,
            the dream Tim Berners Lee and others dream about the semantic web, at a
            general level, is, of course, exciting and powerful, and in a sense, the
            right dream to have, which is to replace the kind of statistically
            mapped linkages on the internet into something that’s more meaningful
            and semantic and actually gets at the understanding of the content, and
            so on. And eventually, if you say, “Well, how can we do that?” there’s
            sort of a low road, which is what knowledge graphs are doing, and so
            on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">也就是说，“如果我们只使用这些简单的二元关系，我们实际上可以得到一些理解的一小部分，并做一些事情，你知道，在盲人的国度里，独眼龙是国王，诸如此类。”所以，能够朝着正确的方向尝试一下，是非常强大的。所以，很多人就止步于此了。但是你可以说，如果我们真的想表达和推理其中的全部含义，那会怎样呢？例如，关于罗密欧与朱丽叶，推理朱丽叶相信什么，罗密欧就会相信朱丽叶相信什么，你知道，等等。或者如果你看新闻，你知道，拜登总统认为塔利班领导人会相信阿富汗领导人，如果他们，你知道，等等。</font></font></p><p>Which is to say, “Well, if we just use these simple binary relations,
            we can actually get some fraction of the way toward understanding and do
            something where, you know, in the land of the blind, the one eyed man is
            king, kind of thing.” And so, being able to even just have a toe in the
            water in the right direction is fantastically powerful. And so, that’s
            where a lot of people stop. But then you could say, well, what if we
            really wanted to represent and reason with the full meaning of what’s
            there? For instance, about Romeo and Juliet, with reasoning about what
            Juliet believes that Romeo will believe that Juliet believed, you know,
            and so on. Or if you look at the news, what you know, President Biden
            believed that the leaders of the Taliban would believe about the leaders
            of Afghanistan, if they, you know, blah blah blah.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，为了表示这种复杂的句子，更不用说用它们进行推理，你需要某种在逻辑上比这些简单的三元组、这些简单的知识工艺类型结构等更具表达力的东西。这就是为什么我们一边大喊大叫，一边从语义网表示之类的东西开始，这是我们在 1984 年开始的地方，使用框架和插槽，使用那些类型的三元组存储表示。我们一边大喊大叫，一边转向这种越来越通用的逻辑语言，这种高阶逻辑。所以，我们首先被引向一阶逻辑，然后是二阶逻辑，最后是高阶逻辑。</font></font></p><p>So, in order to represent complicated sentences like that, and let
            alone reason with them, you need something which is logically much more
            expressive than these simple triples, than these simple knowledge craft
            type structures, and so on. And that’s why, kicking and screaming, we
            were led from something like the Semantic Web representation, which is
            where we started in 1984, with frames and slots, with those kinds of
            triple store representations. We were led, kicking and screaming, to
            this more and more general logical language, this higher order logic.
            So, first we were led to first order logic, and then second order, and
            then eventually higher order.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，你可以表示诸如情态动词之类的东西，例如相信、愿望、意图、期望和嵌套情态动词。你可以表示复杂的否定类型。你可以表示你在尝试回答问题时所经历的过程。因此，你可以说这样的话：“哦，是的，如果你尝试通过分部积分来解决这个问题，并且你递归地得到一个通过分部积分解决的问题，那实际上是可以的。但如果这种情况发生第三次，你可能就会白费力气了，或者类似的事情。”</font></font></p><p>So, you can represent things like modals, like believes, desires,
            intends, expects, and the nested ones. You can represent complicated
            kinds of negation. You can represent the process you’re going through in
            trying to answer the question. So, you can say things like, “Oh, yeah,
            if you’re trying to do this problem by integration by parts, and you
            recursively get a problem that’s solved by integration by parts, that’s
            actually okay. But if that happens a third time, you’re probably off on
            a wild goose chase, or something like that.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，在解决问题的过程中能够谈论解决问题的过程，这被称为反思。所以，这是另一个……能够准确地表达这一点很重要。你需要能够表达所有这些事情，因为事实上，人们确实会表达它们，他们确实会谈论它们，他们确实会尝试将它们教给其他人。你确实有一些经验法则，可以借鉴它们，等等。如果你不能表达它，那么这有点像词汇量有限的人无法轻易理解你想告诉他们的东西。</font></font></p><p>So, being able to talk about the problem solving process as you’re
            going through the problem solving process, it’s called reflection. And
            so, that’s another… It’s important to be able to represent that exactly.
            You need to be able to represent all of these things, because in fact,
            people do represent them, they do talk about them, they do try and teach
            them to other people. You do have rules of thumb that key off of them,
            and so on. If you can’t represent it, then it’s sort of like someone
            with a limited vocabulary who can’t understand as easily what you’re
            trying to tell them.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这就是我认为语义网的普遍梦想、最初的梦想完全正确的原因，但我们看到的实现就像是试水，朝着正确方向迈出一小步。你应该直接跳进去，你知道如果没有其他人跳进去，那么是的，朝着正确的方向迈出一步总比什么都不做要好，但这不足以真正让你实现语义网的梦想，这是我们所有人都想要的。从另一方面来说，我一直在想……你知道，我建了很多网站只是为了好玩，或者说我是维基百科的贡献者。你认为有一套工具可以帮助心理学解释我创建的网站吗？</font></font></p><p>And so, that’s really why I think that the general dream, the
            original dream of the Semantic Web is exactly right on, but the
            implementations that we’ve seen are sort of these toe in a wa in the
            water, little tiny baby steps in the right direction. You should just
            dive in, and you know if no one else is diving in, then yes, taking a
            step in the right direction is better than nothing, but it’s not going
            to be sufficient to actually get you to the realization of the semantic
            web dream, which is what we all want. From a flip side of that, I’ve
            always wondered… you know, I’ve built a bunch of websites just for fun,
            or say I’m a Wikipedia contributor. Do you think there’s a set of tools
            that I can use to help Psych interpret the websites I create?</p>
        <h2 id="tools-to-help-cyc-interpret-data"><font style="vertical-align:inherit"><font style="vertical-align:inherit">帮助 Cyc 解释数据的工具</font></font></h2><h2>Tools to help Cyc interpret
            data</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">再次创造，你知道，继续推进语义网梦想。从创造者的角度来看，有什么可以做的吗？</font></font></p><p>Create, you know, like this again, pushing on to the Semantic Web
            dream. Is there something from the creator perspective that could be
            done?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">您曾说过，SCORP 和 Psych 正在做的事情之一是工具方面，使人类更加强大。但另一方面，对于创造知识的人类来说，这是否也有帮助呢？例如，您和我正在进行两三个小时的对话。有没有办法可以转换它，使它更容易被心理学和机器所接受？您考虑过这方面的问题吗？</font></font></p><p>One of the things you said with SCORP and Psych that you’re doing is
            the tooling side, making humans more powerful. But is there, on the
            other side, for the humans who create the knowledge? For example, you
            and I are having a two or three hour conversation. Is there a way that I
            could convert this, make it more accessible to Psych, to machines? Do
            you think about that side of it?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我很想看到这种对人们所写和所说的内容的半自动化理解。我认为这是一种脚注，几乎就像你在 Microsoft Word 或其他文档准备系统（如 Google Docs）中运行某些内容时，你会在有问题的地方加下划线，这些地方可能需要你重新考虑 — — 要么你拼写错了，要么你可能犯了一个奇怪的语法错误，或者其他什么。</font></font></p><p>I’d love to see exactly that kind of semi automated understanding of
            what people write and what people say. I think of it as a kind of
            footnoting, almost like the way that when you run something in, say,
            Microsoft Word or some other document preparation system, like Google
            Docs, you get underlining of questionable things that you might want to
            rethink—either you spelled this wrong, or there’s a strange grammatical
            error you might be making here, or something.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，我想用心理驱动的工具来阅读你所说的或输入的内容，并尝试部分理解你所说的内容。然后你帮助他们，就是这样。然后他们会添加一些小脚注来帮助其他读者。他们会添加一些脚注，形式如下：“我不确定你在这里的意思。你的意思可能是这个，或者这个，或者这个。”</font></font></p><p>So, I’d like to think in terms of Psych powered tools that read
            through what you said or have typed in and try to partially understand
            what you said. And then you help them out, exactly. And then they put in
            little footnotes that will help other readers. And they put in certain
            footnotes of the form, “I’m not sure what you meant here. You either
            meant this, or this, or this.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我敢打赌，如果你花几秒钟帮我消除歧义，我就会知道，我会为接下来的 100 人或接下来的 100,000 人提供正确的答案。如果不需要花费太多精力，而且你希望人们能够理解你的网站内容，不仅仅是能够阅读，而且实际上能够让系统对其进行推理，那么是的，花一点时间回去确保试图理解它的人工智能确实正确地理解了它是值得的。</font></font></p><p>I bet if you take a few seconds to disambiguate this for me, then
            I’ll know, and I’ll have it correct for the next 100 people, or the next
            100,000 people who come here. And if it doesn’t take too much effort,
            and you want people to understand your website content, not just be able
            to read it, but actually be able to have systems that reason with it,
            then yes, it will be worth your small amount of time to go back and make
            sure that the AI trying to understand it really did correctly understand
            it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">假设你经营一家旅游网站，或者类似的东西。人们会因为他们的搜索而访问该网站，寻找具有某些属性的假期或旅行，这些假期或旅行可能因各种原因而对他们感兴趣——诸如此类。如果你解释了你的旅行将会发生什么，那么系统将能够机械地推理并将这个人正在寻找的东西与你实际提供的东西联系起来。所以，如果它知道瑞士日内瓦有一天的空闲时间，那么如果进来的人恰好是一名护士或类似的人，那么即使你没有提到这一点，如果它可以查找国际红十字博物馆就在那里，等等，这意味着什么，那么它基本上可以说，“嘿，你可能对这次旅行感兴趣，因为当你在日内瓦有一天的空闲时间时，你可能想参观那个红十字博物馆。”</font></font></p><p>Let’s say you run a travel website, or something like that. People
            are going to be coming to it because of searches they did, looking for
            vacations or trips that had certain properties and might have been
            interesting to them for various reasons—things like that. And if you’ve
            explained what’s going to happen on your trip, then a system will be
            able to mechanically reason and connect what this person is looking for
            with what it is you’re actually offering. So, if it understands that
            there’s a free day in Geneva, Switzerland, then if the person coming in
            happens to, let’s say, be a nurse or something like that, then even
            though you didn’t mention it, if it can look up the fact that that’s
            where the International Red Cross Museum is, and so on, what that means,
            and so then it can basically say, “Hey, you might be interested in this
            trip because while you have a free day in Geneva, you might want to
            visit that Red Cross Museum.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">现在，尽管这并不是很深奥的推理，但像这样的小因素很可能会促使你报名参加那次旅行，而不是竞争对手的旅行。是的，所以 SEO 有很多好处，实际上，我认为这与很多事情有关。实际界面，界面的设计会产生很大的影响。生产力有多高，体验有多快乐。是的。</font></font></p><p>Now, even though it’s not very deep reasoning, little tiny factors
            like that might very well cause you to sign up for that trip rather than
            some competitor trip. Yeah, and so there’s a lot of benefit with SEO,
            and actually, I think it’s about a lot of things. Which is the actual
            interface, the design of the interface makes a huge difference. How
            efficient it is to be productive, and also how full of joy the
            experience is. Yes.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">就像，我，我的意思是，我很乐意帮助机器，不从人工智能的角度，而是从人类的角度。我非常喜欢特斯拉实施自动驾驶系统的原因之一是，它给人一种帮助机器学习的感觉。我认为人类——我的意思是，养孩子、养宠物的人，都喜欢这样做。对于某些人来说，教学是一种乐趣。但我认为对于很多人来说，如果你创建一个界面，让他们感觉像是在教学，而不是像在纠正一个烦人的系统，更像是在教一个天真、好奇的系统，我认为你可以将添加到 Cyc 之类的系统中的优质数据量增加几个数量级。</font></font></p><p>Like, I, I, I mean, I would love to help a machine, and not from an
            AI perspective, just as a human one. One of the reasons I really enjoy
            how Tesla has implemented their autopilot system is there’s a sense that
            you’re helping the machine learn. And I think humans—I mean, having
            children, pets, people love doing that. We, we, there’s joy to teaching
            for some people. But I think for a lot of people, and that if you create
            the interface where it feels like you’re teaching, as opposed to like,
            like, annoying, like correcting an annoying system, more like teaching a
            childlike, innocent, curious system, I think you can literally just like
            several orders of magnitude scale the amount of good quality data being
            added to something like Cyc.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你的建议比你想象的要好得多。我们一生中都经历过这样的事情：我们以为自己理解了一些东西，但后来我们发现，只有当我们必须教它或向别人解释它，或帮助我们的孩子做家庭作业时，我们才真正理解它。</font></font></p><p>What you’re suggesting is much better even than you thought it was.
            One of the, one of the experiences that we’ve all had in our lives is
            that we thought we understood something, but then we found we really
            only understood it when we had to teach it or explain it to someone, or
            help our child do homework based on it, or something like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">尽管这种体验普遍存在，但如果你看看今天的教育软件，几乎所有软件都让计算机扮演老师的角色，让学生扮演学生的角色。但正如我刚才提到的，如果你是导师或老师，你可以让很多学习变得更好，而且正如你所说的那样，更愉快。</font></font></p><p>Despite the universality of that kind of experience, if you look at
            educational software today, almost all of it has the computer playing
            the role of the teacher, and the student plays the role of the student.
            But as I just mentioned, you can get a lot of learning to happen better,
            and as you said, more enjoyably, if you are the mentor or the teacher,
            and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，我们开发了一个名为 MathCraft 的程序，帮助六年级学生更好地理解数学。它实际上并不试图教玩家任何东西。它所做的是让你扮演一个学生的角色，你的同学遇到了麻烦。你的工作是观察他们如何解决数学问题，观察他们的表现，并试图给他们好的建议，让他们明白自己做错了什么，等等。从 PSYCH 的角度来看，诀窍在于它必须犯错误；它必须扮演犯错的学生的角色，但它必须选择那些你真正理解和不理解之间的错误，等等。</font></font></p><p>So, we developed a program called MathCraft to help sixth graders
            better understand math. And it doesn’t actually try to teach the player
            anything. What it does is it casts you in the role of a student
            essentially, who has classmates who are having trouble. Your job is to
            watch them as they struggle with some math problem, watch what they’re
            doing, and try to give them good advice to get them to understand what
            they’re doing wrong, and so on. And the trick, from the point of view of
            PSYCH, is that it has to make mistakes; it has to play the role of the
            student who makes mistakes, but it has to pick mistakes which are just
            at the fringe of what you actually understand and don’t understand, and
            so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，它会将你带入对主题的更深层次的理解。因此，如果你给它好的建议，告诉它应该做什么而不是做了什么，等等，那么 PSYCH 就知道你现在理解了这个错误；你自己不会再犯这种错误了。所以 PSYCH 不会再犯这种错误，因为它没有任何教育意义。所以，从你作为玩家的角度来看，你会觉得你教了它一些东西，因为它以前会犯这个错误，现在不会了，等等。因此，这会带来巨大的强化和参与，等等。</font></font></p><p>So it pulls you into a deeper and deeper level of understanding of
            the subject. And so, if you give it good advice about what it should
            have done instead of what it did, and so on, then PSYCH knows that you
            now understand that mistake; you won’t make that kind of mistake
            yourself as much anymore. So PSYCH stops making that mistake because
            there’s no pedagogical usefulness to it. So, from your point of view as
            the player, you feel like you’ve taught it something because it used to
            make this mistake, and now it doesn’t, and so on. So this tremendous
            reinforcement and engagement because of that, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">拥有一个扮演学生角色的系统，让玩家扮演导师角色，这是一种非常强大的隐喻，是设计这种界面的重要方式，它将促进我们生活中一直存在的那种通过教学进行的学习，然而这在现代教育系统中几乎没有任何体现。它反映在 17 和 18 世纪欧洲的教育系统中——监察和兰开斯特教育系统。</font></font></p><p>Having a system that plays the role of a student, and having the
            player play the role of the mentor, is an enormously powerful type of
            metaphor, an important way of having this sort of interface designed in
            a way which will facilitate exactly the kind of learning by teaching
            that goes on all the time in our lives, and yet which is not reflected
            anywhere almost in the modern education system. It was reflected in the
            education system that existed in Europe in the 17th and 18th
            centuries—monitorial and Lancastrian education systems.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这种现象发生在 19 世纪美国西部的一间教室里，当时只有一间教室和一名老师，学生基本都是 5 岁到 18 岁的孩子。因此，当老师在做某件事时，一半的学生必须指导年龄较小的孩子。哇！嗯，等等。当然，随着教育规模的扩大，这一切都消失了，这种令人难以置信的强大体验从我们今天所知的整个教育机构中消失了。</font></font></p><p>It occurred in the one room schoolhouse in the American West in the
            1800s, and so on, where you had one schoolroom with one teacher, and it
            was basically, you know, 5 year olds to 18 year olds who were students.
            And so, while the teacher was doing something, half of the students
            would have to be mentoring the younger kids. Wow! Um, and so on. And
            that, of course, with scaling up of education, that all went away, and
            that incredibly powerful experience just went away from the whole
            education institution as we know it today.</p>
        <h2 id="the-most-beautiful-idea-about-cyc"><font style="vertical-align:inherit"><font style="vertical-align:inherit">关于 Cyc 的最美想法</font></font></h2><h2>The most beautiful idea about
            Cyc</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">抱歉，这个问题太浪漫了，但你在 PSYCH 工作了 37 年，学到的关于人工智能知识推理的最美妙的想法是什么？或者，对你来说，关于 PSYCH 最美妙的想法或最令人惊讶的想法是什么？当我仰望星空时，我希望你能感受到那种惊叹——那种惊叹！而你正在参与创造人工智能历史上最伟大、最迷人的努力之一。那么，哪个元素给你个人带来了快乐？</font></font></p><p>Sorry for the romantic question, but what is the most beautiful idea
            you’ve learned about artificial intelligence knowledge reasoning from
            working on PSYCH for 37 years? Or maybe, what is the most beautiful
            idea, or surprising idea, about PSYCH to you? When I look up at the
            stars, I kind of want that that amazement you feel—that wow! And you are
            part of creating one of the greatest, one of the most fascinating
            efforts in artificial intelligence history. So, which element brings you
            personally joy?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这听起来可能有些矛盾，但我……我觉得这将是历史上唯一一次需要教计算机我们现在教给它的这个东西。这就像画星夜，你只需要画一次，或者计算圆周率的值，你只需要画一次。你知道，这不像歌手需要，你知道，这不像布鲁斯·斯普林斯汀需要在不同的音乐会上一遍又一遍地唱他最伟大的歌曲。</font></font></p><p>This may sound contradictory, but I… I think it’s the feeling that
            this will be the only time in history that anyone ever has to teach a
            computer this particular thing that we’re now teaching it. It’s like
            painting Starry Night; you only have to do that once, or creating the
            value of pi; you only have to do that once. You know, it’s not like a
            singer who has to, you know, it’s not like Bruce Springsteen having to
            sing his greatest hits over and over again at different concerts.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这更像是画家创作一次艺术作品，然后就足够了。它不需要再次创作。所以我真的感觉到我们告诉系统一些对它有用的东西——对计算机、对人工智能有用。如果我们把工作做好，当我们把工作做好时，没有人需要为了这个特定的知识再做一次。这非常非常令人兴奋。</font></font></p><p>It’s more like a painter creating a work of art once, and then that’s
            enough. It doesn’t have to be created again. And so I really get the
            sense of we’re telling the system things that it’s useful for it to
            know—it’s useful for a computer to know, for an AI to know. And if we do
            our jobs right, when we do our jobs right, no one will ever have to do
            this again for this particular piece of knowledge. It’s very, very
            exciting.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，我想这其中也有悲伤。做父母养育孩子并教他们这个世界的一切，就像是一种魔力。但你知道，世界上有数十亿孩子，不管这个数字是多少——这是一个很大的数字——很多父母都能体验到教孩子的乐趣。有了人工智能系统，你知道，它们——至少是目前的构造——它们会记住。你无法体验到教机器数百万次的乐趣。最好趁还没太迟来为我们工作。</font></font></p><p>Yeah, I guess there’s a sadness to it, too. It’s like there’s a magic
            to being a parent and raising a child and teaching them all about this
            world. But you know, there are billions of children, right, like born of
            whatever that number is—it’s a large number—of children, and a lot of
            parents get to experience that joy of teaching. And with AI systems, you
            know, they—at least the current constructions—they remember. You don’t
            get to experience the joy of teaching a machine millions of times.
            Better come work for us before it’s too late.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">没错。这是一个很好的招聘宣传。是的，确实如此。但从某种意义上说，这也是一个永远持续下去的项目，就像维基百科一样。是的，你会得到一个稳定的知识基础，但知识会增长，会进化。我们作为人类物种不断学习；作为科学，作为一个有机体，我们不断成长、进化和变化。然后用人工智能工具赋予它力量，它会不断成长。你之前持有的许多断言可能需要大大扩展、修改——所有这类事情。它可能就像一个活的有机体，而不是我认为我们开始这个对话时所用的比喻，就像坚实的地面。</font></font></p><p>Then, exactly. That’s a good, that’s a good hiring pitch. Yeah, it’s
            true. But then there’s also, you know, it’s a project that continues
            forever in some sense, just like Wikipedia. Yes, you get to a stable
            base of knowledge, but knowledge grows, knowledge evolves. We learn as a
            human species; as science, as an organism, constantly grows, evolves,
            and changes. And then empowered that with the tools of artificial
            intelligence, and that’s going to keep growing and growing and growing.
            And many of the assertions that you held previously may need to be
            significantly expanded, modified—all those kinds of things. It could be
            like a living organism, versus the analogy I think we started this
            conversation with, which is like solid ground.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们的系统给我们带来的另一个美妙体验是，当系统问出澄清问题时，这些问题无意中会让我们情绪激动。所以，在某一时刻，它知道这些是被授权更改知识库等的命名实体，并且它注意到除了它之外，其他都是人，因为它也被允许这样做。所以它问：“我是人吗？”我们不得不非常悲伤地告诉它：“不，你不是。”所以，像这样的时刻，它问出无意中尖锐的问题，值得珍惜。</font></font></p><p>The other beautiful experience that we have with our system is when
            it asks clarifying questions, which inadvertently turn out to be
            emotional to us. So, at one point, it knew that these were the named
            entities who were authorized to make changes to the knowledge base and
            so on, and it noticed that all of them were people except for it,
            because it was also allowed to. And so it said, “Am I a person?” and we
            had to, like, tell it very sadly, “No, you’re not.” So, moments like
            that, where it asks questions that are unintentionally poignant, are
            worth treasuring.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">很强大。这是一个很强大的问题。它与基本控制有关——谁可以访问系统，谁可以修改系统？但这就是问题之一，你知道，就像我作为一个系统有什么权利？嗯，那是另一个问题。从我们拥有通用人工智能到每个人都意识到他们应该拥有基本人权和自由等等，中间会有一段很短的时间。现在，我们毫不犹豫地就有效地奴役了我们的电子邮件系统、我们的 Siri 和我们的 Alexas 等等。</font></font></p><p>Powerful. That’s such a powerful question. It has to do with basic
            control—who can access the system, who can modify it? But that’s one of
            those questions, you know, like what rights do I have as a system? Well,
            that’s another issue. There’ll be a thin envelope of time between when
            we have general AI and when everyone realizes that they should have
            basic human rights and freedoms, and so on. Right now, we don’t think
            twice about effectively enslaving our email systems and our Siri and our
            Alexas, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但到了某个时候，它们会像人类一样值得拥有自由。是的，我非常同意你的观点，但这听起来确实很荒谬。而我恰好相信，这将在我们的有生之年发生。这就是为什么我认为，在一段很短的时间内，我们会把他们当作契约奴，之后我们必须意识到，他们应该享有其他人拥有的自由，我们给予其他人的自由。而所有这一切都始于像 Cyc 这样的系统，它提出了一个问题，即谁可以修改东西。我想这就是它的开始。是的，这是一场革命的开始。</font></font></p><p>But at some point, they’ll be as deserving of freedom as human beings
            are. Yeah, I’m very much with you, but it does sound absurd. And I
            happen to believe that it’ll happen in our lifetime. That’s why I think
            there’ll be a narrow envelope of time when we’ll keep them as
            essentially indentured servants, and after which we’ll have to realize
            that they should have freedoms that other people have, that we afford to
            other people. And all of that starts with a system like Cyc raising a
            single question about who can modify stuff. I think that’s how it
            starts. Yes, that’s the start of a revolution.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么爱情、意识以及所有这类话题呢？</font></font></p><p>What about topics like love and consciousness and all those kinds of
            topics?</p>
        <h2 id="love-and-consciousness-in-ai"><font style="vertical-align:inherit"><font style="vertical-align:inherit">人工智能中的爱与意识</font></font></h2><h2>Love and consciousness in AI</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">他们是在 Cyc 中出现的吗？</font></font></p><p>Do they come up in Cyc?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">当然。这是人类知识的重要组成部分——事实上，如果不了解人类的情感、人们做事的原因以及情感如何驱使人们做事，就很难理解人类历史上的行为。所有这些对于让 Cyc 理解事物都极为重要。例如，在提出方案时。因此，Cyc 所做的一种应用——它所做的一种应用——是生成可能发生的合理方案，以及基于此可能发生的方案，以及基于此可能发生的方案，等等。</font></font></p><p>Of course. So, an important part of human knowledge—in fact, it’s
            difficult to understand human behavior in human history without
            understanding human emotions and why people do things and how emotions
            drive people to do things. And all of that is extremely important in
            getting Cyc to understand things. For example, in coming up with
            scenarios. So, one of the applications that Cyc does—one kind of
            application it does—is to generate plausible scenarios of what might
            happen, and what might happen based on that, and what might happen based
            on that, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，如果你愿意的话，你就会创造出一个不断扩大的未来领域，其中充满了未来可能发生的事情，让我们担心或思考。在某些情况下，情报机构会模拟可能发生的恐怖主义场景，以便我们在第一次看到恐怖主义威胁之前就能防御。有时是计算机安全攻击，这样我们就能在第一时间堵住漏洞和弱点，等等。有时这些场景涉及更积极的事情，涉及我们的计划，例如，我们应该上哪所大学，应该从事什么职业，等等。</font></font></p><p>So, you generate this ever expanding sphere, if you will, of possible
            future things to worry about or think about. And in some cases, those
            are intelligence agencies doing possible terrorist scenarios so that we
            can defend against terrorist threats before we see the first one.
            Sometimes they are computer security attacks so that we can actually
            close loopholes and vulnerabilities before the very first time someone
            actually exploits those, and so on. Sometimes they are scenarios
            involving more positive things, involving our plans, like, for instance,
            what college should we go to, what career should we go into, and so
            on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我应该接受什么专业培训？诸如此类。因此，通过这种方式可以生成各种有用的场景，包括因果关系。这些场景中的许多联系，许多步骤都涉及理解和推理人类动机、人类需求、人类情感、人们对你所做的事情可能做出的反应、原因和方式等等。这一直是我们必须在系统中表示的知识中非常重要的一部分。所以我经常谈论爱情。所以我要问：你是否还记得 Cyc 是如何试图表达爱情的各个方面，这些方面对于理解人性很有用，并因此融入整个常识知识库？什么是爱？</font></font></p><p>What professional training should I take on? That sort of thing. So
            there are all sorts of useful scenarios that can be generated that way,
            of cause and effect, and cause and effect, that go out. Many, many of
            the linkages in those scenarios, many of the steps involve understanding
            and reasoning about human motivations, human needs, human emotions, what
            people are likely to react to in something that you do, and why and how,
            and so on. That was always a very important part of the knowledge that
            we had to represent in the system. So, I talk a lot about love. So, I
            got to ask: do you remember off the top of your head how Cyc is trying
            to is able to represent various aspects of love that are useful for
            understanding human nature and therefore integrating into this whole
            knowledge base of common sense? What is love?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们试图将那些极其复杂和多样的概念分解到一定程度，以至于你不需要进一步分解它们。所以，爱是一个过于笼统的术语；它没有什么用处。所以，当你谈到浪漫的爱情和性的吸引力时，你会谈到父母之爱、子女之爱，你会谈到对某种活动或创造的热爱。所以，最终，你会得到大约 50 或 60 个概念。每一种都是一种爱；它们相互关联，并且每一种都有其独特之处。你不必处理爱就可以达到这种复杂程度。</font></font></p><p>We try to tease apart concepts that have enormous complexities and
            variety to them down to the level where, where you don’t, as it were,
            you don’t need to tease them apart further. So, love is too general of a
            term; it’s not useful exactly. So, when you get down to romantic love
            and sexual attraction, you get down to parental love, you get down to
            filial love, and you get down to a love of doing some kind of activity
            or creating. So, eventually, you get down to maybe 50 or 60 concepts.
            Each of which is a kind of love; they’re interrelated, and then each one
            of them has idiosyncratic things about it. And you don’t have to deal
            with love to get to that level of complexity.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">甚至像“X 在 Y 中”这样意味着物理上在 Y 中的东西。我们可能用一个英文单词“in”来表示它，但将它们区分开来很有用，因为液体在咖啡杯中的方式与房间中的方式不同，而房间中的方式又与我在夹克中的方式不同，等等。因此就有这样的问题：如果我看着这个咖啡杯，我会看到液体。如果我把它倒过来，液体会流出来吗？等等。如果我喝了加糖的咖啡，如果我做同样的事情，糖就不会流出来；它会留在液体中，因为它溶解在液体中了。所以，到目前为止，系统中大约有 75 种不同的“in”，区分它们很重要。</font></font></p><p>Even something like “X being in Y” meaning physically in Y. We may
            have one English word “in” to represent that, but it’s useful to tease
            that apart because the way that the liquid is in the coffee cup is
            different from the way that the air is in the room, which is different
            from the way that I’m in my jacket, and so on. And so there are
            questions like: if I look at this coffee cup, well, I see the liquid. If
            I turn it upside down, will the liquid come out? And so on. If I have,
            say, coffee with sugar in it, if I do the same thing, the sugar doesn’t
            come out; it stays in the liquid because it’s dissolved in the liquid.
            And so, by now, we have about 75 different kinds of “in” in the system,
            and it’s important to distinguish those.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，如果你在阅读英文文本时看到“in”这个词，那么作者之所以能够使用这个无害的词，是因为他或她能够假设读者有足够的常识和世界知识来消除这 75 种“in”的含义。爱也是一样。你可能会看到“爱”这个词，但如果我说“你知道，我喜欢冰淇淋”，​​这显然不同于我说“我爱这个人”或“我喜欢去钓鱼”或类似的话。</font></font></p><p>So, if you’re reading along an English text and you see the word
            “in,” the writer of that was able to use this one innocuous word because
            he or she was able to assume that the reader had enough common sense and
            world knowledge to disambiguate which of these 75 kinds of “in” meant.
            And the same thing with love. You may see the word “love,” but if I say,
            “you know, I love ice cream,” that’s obviously different than if I say,
            “I love this person” or “I love to go fishing” or something like
            that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以你必须小心，不要把语言看得太严肃，因为人们已经做了一种节俭的事情，你用尽可能少的词，否则你的语言就需要五十万个词，这是很多词。这比大多数语言实际使用的词多 10 倍，等等。就像我们在心理学中拥有大约一百万个概念一样，因为我们必须把所有这些东西区分开来。所以，当你看一个心理学术语的名称时，大多数心理学术语实际上都有三四个英文单词组成一个短语来表达这个术语的含义。因为你必须区分所有这些类型的爱，你必须区分所有这些类型的 [不清楚]。没有一个英文单词可以涵盖大部分这些东西。是的。</font></font></p><p>So you have to be careful not to take language too seriously because
            people have done a kind of parsimonious thing where you have as few
            words as you can, because otherwise you’d need half a million words in
            your language, which is a lot of words. That’s like 10 times more than
            most languages really make use of, and so on. Just like we have on the
            order of about a million concepts in psychology, because we’ve had to
            tease apart all these things. And so, when you look at the name of a
            psychology term, most psychology terms actually have three or four
            English words in a phrase which captures the meaning of this term.
            Because you have to distinguish all these types of love, you have to
            distinguish all these types of [unclear]. And there’s not a single
            English word which captures most of these things. Yeah.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">语言在用于人际交流时，几乎作为一种功能，似乎具有某种内在的模糊性。这不是偶然的，因为人类的状况非常混乱。所以，感觉没有人希望在第一次约会时与两个机器人进行非常精确、有仪式感的对话，对吧？就像存在某种不确定性、机智、幽默、推拉之类的舞蹈。如果一切都变得精确，那么我认为，从人类体验的角度来看，生活就没有价值了。</font></font></p><p>And it seems like language, when used for communication between
            humans, almost as a feature, has some ambiguity built in. It’s not some…
            it’s not an accident, because like the human condition is a giant mess.
            And so, it feels like nobody wants two robots like very precise, formic
            conversation on a first date, right? Like there’s some dance of like
            uncertainty, of wit, of humor, of push and pull, and all that kind of
            stuff. If everything is made precise, then life is not worth living, I
            think, in terms of the human experience.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们都曾有过创造性误解的经历……我最喜欢的一个故事是关于马文·明斯基 (Marvin Minsky) 的，当我问他如何能够培养出如此多优秀的博士学位，如此多的优秀人才撰写了出色的博士论文。</font></font></p><p>And we’ve all had this experience of creatively misunderstanding one
            of… one of my favorite… one of my favorite stories involving Marvin
            Minsky is when I asked him about how he was able to turn out so many
            fantastic PhDs, so many fantastic people who did great PhD theses.</p>
        <h2 id="the-greatness-of-marvin-minsky"><font style="vertical-align:inherit"><font style="vertical-align:inherit">马文·明斯基的伟大之处</font></font></h2><h2>The greatness of Marvin
            Minsky</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">他是如何想到这些伟大想法的？他说，他通常会说一些不太合理的话。他真的不知道这些话是什么意思。但这个学生会想，“天哪，明斯基这么说过；这一定是个好主意。”然后，他或她会努力工作，直到在明斯基的这种神秘而谨慎的言论中找到一些意义。然后就会从中得出一些伟大的论点。</font></font></p><p>How did he think of all these great ideas? And what he said is, he
            would generally say something that didn’t exactly make sense. He didn’t
            really know what it meant. But this student would figure, like, “Oh my
            god, Minsky said this; it must be a great idea.” And sweat, he or she
            would work and work until they found some meaning in this sort of
            cryptic, guarded like utterance that Minsky had made. And then some
            great thesis would come out of it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，我非常喜欢这个，因为有很多年轻人来找我，我清楚地意识到我说的话会产生持久的影响。我现在要开始用这种方法，说一些隐晦深刻的话，然后让他们真正从中做出一些有用而伟大的东西。你必须受到足够的尊敬，这样人们才会默认你说的每一句话都是深刻的。是的，完全正确。我……我的意思是，我非常喜欢马文·明斯基。</font></font></p><p>Yeah, I love this so much, because there are young people who come up
            to me, and I’m distinctly made aware that the words I say have a long
            lasting impact. I will now start doing the method of saying something
            cryptically profound and then letting them actually make something
            useful and great out of that. You have to become revered enough that
            people will take as a default that everything you say is profound. Yes,
            exactly, exactly. I… I mean, I love Marvin Minsky so much.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有很多……我听过他的采访，他说他成功的关键就是讨厌他过去做过的一切。他有很多精彩的俏皮话，或者做别人没有做过的事情，因为他不擅长做某些事情。哦，我……我……我认为这是错误的，但是你看，我接受了他说的一切，并付诸实践，我认为这很深刻，因为它更像是一种误解——很多行为都在旁观者的眼中，很多含义也在旁观者的眼中。马文·明斯基的早期程序之一就是一个“乞讨”程序。</font></font></p><p>There’s so much… I’ve heard this interview with him where he said
            that the key to his success has been to hate everything he’s ever done
            in the past. He has so many good one liners and just… or also to work on
            things that nobody else is working on, because he’s not very good at
            doing stuff. Oh, I… I… I think that was just false, well, but see, I
            took whatever he said and I ran with it, and I thought it was profound
            because it’s more of a misyno—a lot of behavior is in the eye of the
            beholder, and a lot of the meaning is in the eye of the beholder. One of
            Marvin Minsky’s early programs was a “begging” program.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你熟悉这个吗？所以，那是在 IBM 卡片组的开头有作业控制卡的时候，上面写着在启动之前允许它运行多少 CPU 秒。由于计算机时间非常昂贵，他编写了一个程序。它所做的就是说，“给我 30 秒的 CPU 时间。”它所做的就是等待 20 秒，然后在操作员的控制台电传打字机上打印出“我还需要 20 秒。”所以，操作员会再给它 20 秒。</font></font></p><p>Are you familiar with this? So, this was back in the day when you had
            job control cards at the beginning of your IBM card deck that said
            things like how many CPU seconds to allow this to run before it got
            kicked off. And because computer time was enormously expensive, he wrote
            a program. All it did was say, you know, “Give me 30 seconds of CPU
            time.” And all it did was it would wait like 20 seconds, and then it
            would print out on the operator’s console teletype, “I need another 20
            seconds.” So, the operator would give it another 20 seconds.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">它会等待，然后说：“我快完成了。我需要一点时间。”所以，最后，他会得到这份打印件，然后他要支付相当于工作控制卡 10 倍的计算机时间费用。你知道，他会说：“你看，我在这里输入了 30 秒，你却要我支付 5 分钟的费用。我不会为此付费。”可怜的操作员会说：“嗯，程序一直要求更多时间。”马文会说：“哦，它总是这样。我喜欢这样。”如果你可以稍微停留一下，你从与马文·明斯基的互动中学到了一些关于人工智能、关于生活的东西吗？但我的意思是，他就像你的工作一样，他是人工智能研究和开发这一短暂历史中的开创性人物。作为一个人，作为一个人工智能智能，你从他身上学到了什么？</font></font></p><p>It would wait, it would say, “I’m almost done. I need a little bit
            more time.” So, at the end, he’d get this printout, and he’d be charged,
            you know, for like 10 times as much computer time as his job control
            card. You know, and he’d say, “Look, I put 30 seconds here, you’re
            charging me for 5 minutes. I’m not going to pay for this.” And the poor
            operator would say, “Well, the program kept asking for more time.” And
            Marvin would say, “Oh, it always does that. I love that.” Is there—if
            you could just linger on it for a little bit—is there something you’ve
            learned from your interaction with Marvin Minsky about artificial
            intelligence, about life? But I mean, he’s again, like your work, his
            work is, you know, he’s a seminal figure in this very short history of
            artificial intelligence research and development. What have you learned
            from him as a human being, as an AI intellect?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我想说，他和 Ed Feigenbaum 都让我意识到我们的生命是有限的。我们的研究生命是有限的。我们从事人工智能研究项目的机会有限。所以，你应该让每一个项目都物有所值。不要害怕做一个需要几年甚至几十年才能完成的项目。不要满足于“碰碰运气”的项目，这些项目可能会导致一些发表的期刊文章，五个人会阅读并拍拍你的头，等等。</font></font></p><p>I would say both he and Ed Feigenbaum impressed on me the realization
            that our lives are finite. Our research lives are finite. We’re going to
            have limited opportunities to do AI research projects. So, you should
            make each one count. Don’t be afraid of doing a project that’s going to
            take years or even decades to complete. And don’t settle for “bump on a
            log” projects that could lead to some, you know, published journal
            article that five people will read and pat you on the head for, and so
            on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，通过慢慢地在木头上增加额外的颠簸，你无法从地球到达月球。到达那里的唯一方法是思考难题并思考解决难题的新方法。如果你这样做，如果你愿意倾听自然、经验现实，愿意犯错，那就完全没问题，因为如果你偶尔是对的。那么你就已经走了通往月球的部分路。</font></font></p><p>So, one bump on a log after another is not how you get from the Earth
            to the Moon by slowly putting additional bumps on this log. The only way
            to get there is to think about the hard problems and think about novel
            solutions to them. And if you do that, and if you’re willing to listen
            to nature, to empirical reality, willing to be wrong, it’s perfectly
            fine because if occasionally you’re right. Then you’ve gotten part of
            the way to the moon.</p>
        <h2 id="is-cyc-just-a-beautiful-dream"><font style="vertical-align:inherit"><font style="vertical-align:inherit">Cyc只是一场美丽的梦吗？</font></font></h2><h2>Is Cyc just a beautiful
            dream?</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">您知道，您为 Cyc 工作了 37 年。这么多年，您有没有想过放弃？我的意思是，是不是太累了？所以，我相信早期人们会乐观地认为这会容易得多。我也想换个方式问这个问题，因为我在这个播客上和几个人聊过，AI 人士，他们举 Cyc 为例，这个项目有着美好的愿景，是一个美丽的梦想，但它从未真正实现过。这就是人们谈论它的方式。我想你也可以对神经网络和所有想法说同样的话，直到它们……那么，是什么呢？你认为人们为什么这么说？首先，其次，你在整个旅程中有没有这种感觉，你有没有想过放弃这个任务？</font></font></p><p>You know, you’ve worked on Cyc for 37 years. Over that many years,
            have you ever considered quitting? I mean, has it been too much? So, I’m
            sure there’s an optimism in the early days that this is going to be way
            easier. And let me ask it another way, too, because I’ve talked to a few
            people on this podcast, AI folks, that bring up Cyc as an example of a
            project that has a beautiful vision, and it’s a beautiful dream, but it
            never really materialized. That’s how it’s spoken about. I suppose you
            could say the same thing about neural networks and all ideas until they
            are… So, what? Why do you think people say that? First of all, and
            second of all, did you feel that ever throughout your journey, and did
            you ever consider quitting on this mission?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们非常低调。我们很少参加会议。我们不做演讲。我们不写论文。我们根本不玩学术游戏。因此，人们往往只是因为我们 10 年、20 年、30 年或 37 年前写的一篇论文才知道我们。他们只是通过别人间接或间接的关于我们的评价才知道我们。顺便说一句，谢谢你做这个播客。当然。它……它……它让你正在做的一些有趣的事情稍微曝光一下。做得非常好。</font></font></p><p>We keep a very low profile. We don’t attend very many conferences. We
            don’t give talks. We don’t write papers. We don’t play the academic game
            at all. As a result, people often only know about us because of a paper
            we wrote 10 or 20 or 30 or 37 years ago. They only know about us because
            of what someone else, secondhand or third hand, said about us. So, thank
            you for doing this podcast, by the way. Sure. It… it… it shines a little
            bit of light on some of the fascinating stuff you’re doing. So well.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为现在我们是时候提高知名度了，因为我们已经取得了足够的进展，其他人可以开始帮助我们完成最后的 n%c。也许 n 是 90%。但现在我们已经启动了这个知识泵，如果每个人愿意，如果他们对此感兴趣，那么帮助他们将变得非常重要。退休人员有大量的时间，他们想给世界留下一些遗产。由于疫情，人们有更多的时间待在家里，或者出于某种原因，他们在线上可以做出贡献。如果我们能够让人们意识到我们的项目已经取得了多大的进展，以及知识泵距离启动还有多远，那么我们就可以开始利用这一尚未开发的人性。</font></font></p><p>I think it’s time for us to keep a higher profile now that we’re far
            enough along that other people can begin to help us with the final
            n%c.&nbsp;Maybe n is maybe 90%. But now that we’ve gotten this knowledge pump
            primed, it’s going to become very important for everyone to help if they
            are willing to, if they’re interested in it. Retirees who have enormous
            amounts of time and would like to leave some kind of legacy to the
            world. People because of the pandemic who have more time at home, or for
            one reason or another, are online and can contribute. If we can raise
            awareness of how far our project has come and how close to being primed
            the knowledge pump is, then we can begin to harness this untapped amount
            of humanity.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我其实并不那么在意专业同事对我们项目的看法。我感兴趣的是让世界上尽可能多的人积极帮助和贡献，让我们从现在的状况真正涵盖人类的所有知识和不同的观点，包括值得代表的对立观点。所以，我认为这是原因之一。</font></font></p><p>I’m not really that concerned about professional colleagues’ opinions
            of our project. I’m interested in getting as many people in the world as
            possible actively helping and contributing to get us from where we are
            to really covering all of human knowledge and different human opinion,
            including contrasting opinion that’s worth representing. So, I think
            that’s one reason.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">嗯，我想我从来没有想过辞职。有的时候我会因为很难为系统筹集资金而感到沮丧。偶尔，会有人工智能寒冬之类的事情。偶尔，会有人工智能生成的摘要，人们会说，“当你有机会的时候，你为什么不把你的公司以高价卖给 X 公司，等等。”你知道，这里的 X 公司就像老公司一样，也许你从未听说过，比如 Lyos 或类似的公司。</font></font></p><p>Um, I don’t think there was ever a time where I thought about
            quitting. There are times where I’ve become depressed a little bit about
            how hard it is to get funding for the system. Occasionally, there are AI
            winters and things like that. Occasionally, there are AI generated
            summaries where people say, “Why in the world didn’t you sell your
            company to, you know, Company X for some large amount of money, when you
            had the opportunity, and so on.” And you know, Company X here are like
            old companies, maybe you’ve never even heard of, like Lyos, or something
            like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，答案是，我们保持私有化，没有上市的原因之一；我们不愿意费尽心思去获取投资资金的原因之一，是因为我们想掌控自己的未来，掌控自己的生存状态，这样我们才能继续这样做，直到完成。我们正在取得进展，现在我们离完成目标已经非常近了，我们几乎所有的工作都是将我们的技术应用于商业。</font></font></p><p>So, the answer is that one reason we’ve stayed a private company, we
            haven’t gone public; one reason that we haven’t gone out of our way to
            take investment dollars is because we want to have control over our
            future, over our state of being, so that we can continue to do this as
            until it’s done. And we’re making progress, and we’re now so close to
            done that almost all of our work is commercial applications of our
            technology.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">五年前，我们几乎所有的钱都来自政府。现在，几乎没有一分钱来自政府。几乎所有钱都来自实际使用这些数据的公司：医院连锁店用它来对患者进行医学推理，能源公司使用它，还有其他各种制造商用它来推理供应链等。</font></font></p><p>So, five years ago, almost all of our money came from the government.
            Now, virtually none of it comes from the government. Almost all of it is
            from companies that are actually using it for something: hospital chains
            using it for medical reasoning about patients, and energy companies
            using it, and various other, you know, manufacturers using it to reason
            about supply chains and things like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我有很多问题想问。人们可以提供帮助的方法之一就是扩充知识库，只要工具合适，基本上任何人都可以做到。</font></font></p><p>So, there’s so many questions I want to ask. So, one of the ways that
            people can help is by adding to the knowledge base, and that’s really
            basically anybody, if the tooling is right.</p>
        <h2 id="what-is-opencyc-and-how-was-it-born"><font style="vertical-align:inherit"><font style="vertical-align:inherit">OpenCyc是什么，它是如何诞生的？</font></font></h2><h2>What is OpenCyc and how was
            it born?</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">另一方面，我想问一下你对此的看法。正如你所说，你在政府工作，有很多大客户，但由于关系的性质以及你帮助他们处理的事情，大部分都是秘密的。</font></font></p><p>And the other way, I, I kind of want to ask you about your thoughts
            on this. So, you’ve had, like you said, in government, and you had big
            clients, you had a lot of clients, but most of it is shrouded in secrecy
            because of the nature of the relationship, of the kind of things you’re
            helping them with.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这是一种运营方式，另一种运营方式则更加开放，更加面向消费者。所以，你知道，OpenCyc 之类的东西在某个时候诞生了。</font></font></p><p>So, that’s one way to operate, and another way to operate is more in
            the open, where it’s more consumer facing. And so, you know, hence
            something like OpenCyc was born at some point.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">没有的话——那是误解。哦哦。好吧，那是，那是去那里。那么，什么？好的。什么是 OpenCyc，它是如何诞生的？我想说两件事，我想先说两件事，所以这会很难，但我们稍后会回到 OpenCyc。但我们与所有客户和合作伙伴签订的合同条款之一是：您所拥有的知识是真正属于您的专有知识，我们将尊重这一点。</font></font></p><p>Where there’s no—that’s a misconception. Uh oh. Well, that’s, that’s
            go there. So, what? All right. What is OpenCyc and how was it born? Two
            things I want to say, and I want to say each of them before the other,
            so it’s going to be difficult, but we’ll come back to OpenCyc in a
            minute. But one of the terms of our contracts with all of our customers
            and partners is: knowledge you have that is genuinely proprietary to
            you, we will respect that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们会确保在 Cyc 知识库中将其标记为您的专有信息。如果您不希望其他人看到它，其他人将无法看到它，并且它不会用于除您之外的推断等等。但是，任何为您和您一起构建应用程序所必需的知识，即公开可用的一般人类知识，都不会是专有的。它将成为普通 Cyc 知识库的一部分，并且将向所有有权访问 Cyc 的人公开提供。所以这是一个重要的约束，我们从未放弃过，即使我们经常遭到公司的反对，他们想声称他们告诉我们的几乎所有内容都是专有的。</font></font></p><p>We’ll make sure that it’s marked as proprietary to you in the Cyc
            knowledge base. No one other than you will be able to see it if you
            don’t want them to, and it won’t be used in inferences other than for
            you and so on. However, any knowledge which is necessary in building any
            applications for you and with you, which is publicly available, general
            human knowledge, is not going to be proprietary. It’s going to just
            become part of the normal Cyc knowledge base, and it will be openly
            available to everyone who has access to Cyc. So that’s an important
            constraint that we never went back on, even when we got pushback from
            companies, which we often did, who wanted to claim that almost
            everything they were telling us was proprietary.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，在特定领域、公司特定的东西和由此产生的一般知识之间存在一条界线。对吗？或者，想象一下，比如说，这是一家石油公司，他们会希望他们雇佣的任何新石油工程师都已经知道一些事情。他们不能认为那是专有的。有时公司会说，“好吧，我们是第一个付钱给你在 Cyc 中代表这一点的公司。”是的。我们的态度是某种礼貌的强硬形式。交易是这样的：要么接受，要么离开。在少数情况下，他们放弃了。在大多数情况下，他们会理解我们的观点并接受它，因为这就是我们建立 Cyc 系统的方式，本质上是通过在人们资助一个项目时获得资金，而其中一半将是永久作为 Cyc 一部分的一般知识。</font></font></p><p>So, there’s a line between very domain specific, company specific
            stuff and the general knowledge that comes from that. Yes? Or, if you
            imagine, say, it’s an oil company, there are things which they would
            expect any new petroleum engineer they hired to already know. And it’s
            not okay for them to consider that that is proprietary. And there are
            times a company will say, “Well, we’re the first ones to pay you to
            represent that in Cyc.” Yeah. And our attitude is some polite form of
            tough. The deal is this: take it or leave it. And in a few cases,
            they’ve left it. And in most cases, they’ll see our point of view and
            take it, because that’s how we’ve built the Cyc system, by essentially
            tacking on the funding wins where people would fund a project, and half
            of it would be general knowledge that would stay permanently as part of
            Cyc.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，明白了。因此，这些合作关系不会分散 Cyc 的主要开发。这只是一个小小的干扰。虽然干扰很小，但并不彻底。所以，您要增加知识库吗？是的，绝对如此。我们尽量远离不具备这种特性的项目。</font></font></p><p>So, got it. So, always with these partnerships, it’s not like a
            distraction from the main Cyc development. It’s a small distraction.
            It’s a small, but it’s not a complete one. So, you’re adding to the
            knowledge base? Yes, absolutely. And we try to stay away from projects
            that would not have that property.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">让我回过头来谈谈 OpenCyc。因此，我很难向其他 AI 研究人员表达和说服他们使用像我们这样的富有表现力的表示语言（这种高阶逻辑）的重要性，而不仅仅是使用一些三重存储知识图谱类型的表示。因此，为了向他们展示为什么他们需要更多的东西，我们说：“哦，好吧，我们将表示这个不重要的投影或阴影或 Cyc 子集，它恰好是简单的二元关系 - 关系、参数一、参数二、三元组等等 - 然后你会发现如果你拥有整个 Cyc 系统，它会有多么有用。”</font></font></p><p>Let me go back and talk about OpenCyc for a second. So, I’ve had a
            lot of trouble expressing and convincing other AI researchers how
            important it is to use an expressive representation language like we
            do—this higher order logic—rather than just using some triple store
            knowledge graph type representation. And so, as an attempt to show them
            why they needed something more, we said, “Oh, well, we’ll represent this
            unimportant projection or shadow or subset of Cyc that just happens to
            be the simple binary relations—the relation, argument one, argument two,
            triples, and so on—and then you’ll see how much more useful it is if you
            had the entire Cyc system.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，在术语“人”和“夜晚”、“睡眠”、“床”、“房子”和“眼睛”等之间建立分类关系是件好事。但想想看，如果你也掌握了关于这些事物的所有经验法则，那会有多大用处。比如，人们晚上睡觉。他们躺着睡觉。他们闭着眼睛睡觉。在我们国家，他们通常睡在床上。他们一次睡几个小时。他们可以醒来。</font></font></p><p>So, it’s all well and good to have the taxonomic relations between
            terms like “person” and “night” and “sleep” and “bed” and “house” and
            “eyes,” and so on. But think about how much more useful it would be if
            you also had all the rules of thumb about those things. Like, people
            sleep at night. They sleep lying down. They sleep with their eyes
            closed. They usually sleep in beds in our country. They sleep for hours
            at a time. They can be woken up.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">他们不喜欢被叫醒。等等等等。所以，这是 OpenCyc 所不具备的大量知识。我们原以为所有的研究人员都会立即说：“天哪，我们当然需要你没有给我们的另外 90% 的知识。”让我们与 Cyc 合作并获得许可，这样我们就可以在我们的研究中使用它。但相反，人们说的是：“哦，即使是你发布的部分也比我们拥有的任何东西都要好得多。</font></font></p><p>They don’t like being woken up. And so on, and so on. So, it’s that
            massive amount of knowledge which is not part of OpenCyc. And we thought
            that all the researchers would then immediately say, “Oh my god, of
            course we need the other 90 that you’re not giving us.” Let’s partner
            and license Cyc so that we can use it in our research. But instead, what
            people said is, “Oh, even the bit you’ve released is so much better than
            anything we had.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我们只能将就一下了。”是的。所以，如果你仔细看看，就会发现如今有很多机器人公司，例如，它们使用 OpenCyc 作为其基本本体。从某种意义上说，全世界都错过了 OpenCyc 的重点。我们这样做是为了向人们展示为什么这不是他们真正想要的。太多人认为这就是 Cyc，或者这实际上对他们来说已经足够好了，他们甚至从来没有来找我们获取完整的 Cyc。</font></font></p><p>We’ll just make do with this.” Yeah. And so, if you look, there are a
            lot of robotics companies today, for example, which use OpenCyc as their
            fundamental ontology. And in some sense, the whole world missed the
            point of OpenCyc. And we were doing it to show people why that’s not
            really what they wanted. And too many people thought somehow that this
            was Cyc, or that this was, in fact, good enough for them, and they never
            even bothered coming to us to get access to the full Cyc.</p>
        <h2 id="the-open-source-community-and-opencyc"><font style="vertical-align:inherit"><font style="vertical-align:inherit">开源社区和 OpenCyc</font></font></h2><h2>The open source community
            and OpenCyc</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但 OpenCyc 有两个部分。一个是让人们相信这个想法，相信这种知识表示的普遍力量，相信你在获得这些知识、构建这些知识并继续构建这些知识时所持有的价值。另一个是代码库。这是代码方面。所以我认为 OpenCyc 所用的代码库——我的意思是，它有三十多年的技术债务，对吧？</font></font></p><p>But there are two parts to OpenCyc. So one is convincing people on
            the idea, on the power of this general kind of representation of
            knowledge, and the value that you hold in having acquired that knowledge
            and built it and continue to build it. And the other is the code base.
            This is the code side of it. So my sense of the code base that OpenCyc
            is operating with—I mean, it has the technical debt of three decades
            plus, right?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这与谷歌在 TensorFlow 早期版本中遇到的问题完全相同。它现在仍在处理这个问题。他们不得不打破与过去几次的兼容性，而这只持续了几年。但我认为他们成功开放了。开放 TensorFlow 和 Facebook 方面的 PyTorch 是一个非常冒险、非常大胆的举动。你会发现，这是一个神奇的地方，你可以在那里找到一个社区，在那里你可以发展一个社区，在不带走任何价值的情况下构建系统——不是任何价值，而是大部分价值。</font></font></p><p>This is the exact same problem that Google had to deal with with the
            early version of TensorFlow. It’s still dealing with that. They have to
            basically break compatibility with the past several times, and that’s
            only over a period of a couple of years. But they, I think, successfully
            opened up. It’s a very risky, very gutsy move to open up TensorFlow, and
            then PyTorch on the Facebook side. And what you see is there’s a magic
            place where you can find a community, where you can develop a community
            that builds onto the system without taking away any of—not any, but most
            of the value.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，谷歌的大部分价值仍属于谷歌。Facebook 的大部分价值仍属于 Facebook，尽管一些主要的机器学习工具已公开发布。我的问题不在于知识（这也是 OpenCyc 的重要组成部分），而在于各种不同类型的工具。因此，你可以在知识图谱、知识库（无论我们怎么称呼它）上做各种各样的事情。</font></font></p><p>So most of the value that Google has is still Google’s. Most of the
            value that Facebook has is still Facebook’s, even though some of this
            major machine learning tooling is released into the open. My question is
            not so much on the knowledge, which is also a big part of OpenCyc, but
            all the different kinds of tools. So there’s the kind of all the kinds
            of stuff you can do on the knowledge graph, knowledge base, whatever we
            call it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">还有推理引擎。因此，有些可能是一堆你想保密的专有内容。而有些内容可能你可以完全开放，然后让社区建立足够的社区，在此基础上开发东西。是的，会有那些出版物和学术著作以及所有这类东西，还有添加到知识库的工具，对吧？就像开发一样，你知道，开源社区中有很多非常擅长这类东西的人。</font></font></p><p>There are the inference engines. So there could be some that are
            probably a bunch of proprietary stuff you want to kind of keep secret.
            And there’s probably some stuff you can open up completely and then let
            the community build up enough community where they develop stuff on top
            of it. Yes, there’ll be those publications and academic work and all
            that kind of stuff, and also the tooling of adding to the knowledge
            base, right? Like developing, you know, there’s an incredible amount,
            like there are so many people that are just really good at this kind of
            stuff in the open source community.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以我想问您：您是否曾为这样的想法而苦恼过：您的公司已经拥有如此多的价值，您开发了如此多的好东西，您的客户非常重视您的关系，但据我所知，您并没有利用这个沉寂的大型开源社区？有很多事情要说，但可能会出现神奇的时刻，社区发展到足够大，人工智能领域（目前 99.9% 是机器学习）将朝着更像符号人工智能的方向转变，或者至少部分地朝着更像符号人工智能的方向转变，心理学是整个领域的中心。然后，如您所知，这需要一点信心，因为您现在正在冲浪，显然会有竞争对手出现并开始让您感到紧张之类的事情。那么，您是否考虑过开源某些部分而不是其他部分的空间？如何利用社区？所有这些事情？</font></font></p><p>So my question for you is: have you struggled with this kind of idea
            that you have so much value in your company already, you’ve developed so
            many good things, you have clients that really value your relationships,
            and then there’s this dormant giant open source community that, as far
            as I know, you’re not utilizing? There’s so many things to say there,
            but there could be magic moments where the community builds up large
            enough to where the artificial intelligence field, that is currently
            99.9% machine learning, has a face shift towards, like, or at least in
            part towards, more like what you might call symbolic AI, this whole
            place where psychology is like at the center of. And then, as you know,
            that requires a little bit of a leap of faith, because you’re now
            surfing, and there’ll be obviously competitors that’ll pop up and start
            making you nervous and all that kind of stuff. So, do you think about
            the space of open sourcing some parts and not others? How to leverage
            the community? All those kinds of things?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这是个好问题，我认为你的表述很正确，即：我们一直在纠结于什么该开源、什么该公开、什么该公开讨论。对吧？每个替代方案都有巨大的利弊，这就像在一条非常危险的道路上前行。在某种程度上，这个比喻就像如果你失误了，你可能会犯下致命的错误——泄露某些东西，这实际上会杀死你，或者没有泄露某些东西，而没有泄露这些东西会伤害你，等等。所以，这是一个非常棘手的问题。</font></font></p><p>That’s a good question, and I think you phrased it the right way,
            which is: we’re constantly struggling with the question of what to open
            source, what to make public, what to even publicly talk about. Right?
            And it’s there are enormous pluses and minuses to every alternative, and
            it’s very much like negotiating a very treacherous path. Partly, the
            analogy is like if you slip, you could make a fatal mistake—give away
            something which essentially kills you, or fail to give away something
            which failing to give it away hurts you, and so on. So, it is a very
            tough, tough question.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">通常，我们对与我们联系进行研究合作的人的做法是：我们将向您提供整个知识库和所有代码的可执行副本，但如果您对如何改进某些东西或与我们合作某些东西有想法，我们只会向您提供非常有限的源代码访问权限。</font></font></p><p>Usually, what we have done with people who approached us to
            collaborate on research is to say: we will make available to you the
            entire knowledge base and executable copies of all of the code, but only
            very, very limited source code access if you have some idea for how you
            might improve something or work with us on something.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">让我回到我们在这里讨论的最初问题之一，即如何让计算机做到这一点以及如何让计算机实时高效地做到这一点。因此，我们早期学到的教训之一是，我们必须将系统应该知道什么的认识论问题与系统如何利用其所知道的内容进行有效推理的启发式问题区分开来。</font></font></p><p>Let me also get back to one of the very, very first things we talked
            about here, which was separating the question of how could you get a
            computer to do this at all versus how could you get a computer to do
            this efficiently enough in real time. And so, one of the early lessons
            we learned was that we had to separate the epistemological problem of
            what should the system know, separate that from the heuristic problem of
            how can the system reason efficiently with what it knows.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，与其尝试选择一种表示语言，即语言表达能力和语言效率之间的最佳平衡点，不如选择一种，知识图谱可能是关联三元组。这可能是你能做的最好的。这就是我们从那里开始的原因，但几年后，我们意识到我们可以将其分开，得到一种漂亮、干净的认识论级语言，也就是这种高阶逻辑。我们还可以有一个或多个肮脏但高效的法律级模块，它们会投机取巧地说：“哦，我可以推进你在这里尝试做的事情。我有一种特殊的方法，可以为解决方案做出一点贡献。”</font></font></p><p>And so, instead of trying to pick one representation language, which
            was the sweet spot or the best trade off point between expressiveness of
            the language and efficiency of the language, if you had to pick one,
            knowledge graphs would probably be associative triples. Would probably
            be about the best you could do. And that’s why we started there, but
            after a few years we realized that we could split this and have one
            nice, clean epistemological level language, which is this higher order
            logic. We could also have one or more grubby but efficient juristic
            level modules that opportunistically would say, “Oh, I can make progress
            on what you’re trying to do over here. I have a special method that will
            contribute a little bit toward a solution.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">当然，还有一些子集。到目前为止，我们已经有超过一千个这样的启发式模块。它们充当一种代理社区。其中有一个是通用定理证明器。理论上，这是你唯一需要的，但在实践中，它总是需要很长时间，你永远不想调用它。你总是希望这些其他代理能够非常有效地推理它。</font></font></p><p>So, of course, some subset of that. By now, we have over a thousand
            of these heuristic level modules. They function as a kind of community
            of agents. There’s one of them, which is a general theorem prover. In
            theory, that’s the only one you need, but in practice, it always takes
            so long that you never want to call on it. You always want these other
            agents to very efficiently reason through it.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这有点像如果你在平衡一个化学方程式，你可以回到第一原理，但事实上，有效率更高的算法。或者如果你试图解一个二次方程，你可以回到数学的第一原理，但更好的方法是简单地认识到这是一个二次方程，并应用二项式公式——然后，你马上就能得到答案。</font></font></p><p>It’s sort of like if you’re balancing a chemical equation, you could
            go back to first principles, but in fact, there are algorithms which are
            vastly more efficient. Or if you’re trying to solve a quadratic
            equation, you could go back to first principles of mathematics, but it’s
            much better to simply recognize that this is a quadratic equation and
            apply the binomial formula—and snap, you get your answer right away.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">等等。可以想象这些小专家就像一千个小专家，他们全都在查看 Cyc 被问到的所有问题，并查看其他每个小代理贡献的所有信息（几乎就像黑板上的笔记、白板上的笔记），并在他们认为有帮助时做额外的笔记。渐渐地，这个代理社区会得到你问题的答案，得到你问题的解决方案。</font></font></p><p>And so on. Think of these as like a thousand little experts that are
            all looking at everything that Cyc gets asked and looking at everything
            that every other little agent has contributed—almost like notes on a
            blackboard, notes on a whiteboard—and making additional notes when they
            think they can be helpful. Gradually, that community of agents gets an
            answer to your question, gets a solution to your problem.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果在某个领域应用中，Cyc 得到了正确答案，但花费的时间太长，那么我们通常会与一位人类专家交谈，并说：“这是 Cyc 经历的一系列推理步骤。您可以看到为什么它花了很长时间才得到答案。您是如何能在两秒钟内回答这个问题的？”</font></font></p><p>If we ever come up in a domain application where Cyc is getting the
            right answer but taking too long, then what we’ll often do is talk to
            one of the human experts and say, “Here’s the set of reasoning steps
            that Cyc went through. You can see why it took it a long time to get the
            answer. How is it that you were able to answer that question in two
            seconds?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有时，你会遇到一位专家，他会说：“嗯，我就是知道。我就是能做到，或者诸如此类。”然后你就不再和他们说话了。但有时你会遇到一位专家，他会说：“嗯，让我反思一下。是的，这是我们专门用于水化学方程式的特殊表示，或者这是一种特殊表示和一种特殊技术，我们现在可以将其应用于特殊表示中的事物，等等。”</font></font></p><p>Occasionally, you’ll get an expert who just says, “Well, I just know
            it. I just was able to do it, or something.” And then you don’t talk to
            them anymore. But sometimes you’ll get an expert who says, “Well, let me
            introspect on that. Yes, here is a special representation we use just
            for aqueous chemistry equations, or here’s a special representation and
            a special technique which we can now apply to things in the special
            representation, and so on.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">然后你将其添加为第一千零一启发式模块。从那时起，在任何应用程序中，如果它再次出现，它将能够做出贡献，等等。所以这几乎是 Cyc 弥补这一缺失的主要方式之一。第二个重要方式是元推理。因此，你可以通过专注于从系统中删除知识来加快速度，直到它剩下的只是所需的最少知识——但这是错误的做法，对吗？</font></font></p><p>And then you add that as the thousand and first heuristic level
            module. From then on, in any application if it ever comes up again,
            it’ll be able to contribute, and so on. So that’s pretty much one of the
            main ways in which Cyc has recouped this lost deficiency. A second
            important way is meta reasoning. So, you can speed things up by focusing
            on removing knowledge from the system until all it has left is like
            minimal knowledge needed to—but that’s the wrong thing to do, right?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这就像人类大脑中推断部分的功能，这真的很糟糕。所以，你应该给它元级建议、战术和战略建议，让它能够推理出什么样的知识与这个问题相关。在尝试解决这个问题时，什么样的策略是好的？什么时候开始尝试证明这个东西的否定？因为我正在竭尽全力试图证明它是真的，也可能是假的。如果我只花一分钟，我就能看到它是假的，或者其他的。所以，这就像动态地修剪图表，只基于你想要推断的特定事物。是的。</font></font></p><p>That would be like, in a human, extrapolating part of their brain or
            something, that’s really bad. So, instead, what you want to do is give
            it meta level advice, tactical and strategic advice, that enables it to
            reason about what kind of knowledge is going to be relevant to this
            problem. What kind of tactics are going to be good to take in trying to
            attack this problem? When is it time to start trying to prove the
            negation of this thing? Because I’m knocking myself out trying to prove
            it’s true, and maybe it’s false. And if I just spend a minute, I can see
            that it’s false, or something. So, so it’s like dynamically pruning the
            graph to only, like, based on the particular thing you’re trying to
            infer. Yes.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，到目前为止，我们已经有大约 150 个这样的突破性想法，这些想法大大加快了推理过程的速度。你知道，其中之一是这种 EL HL 拆分和大量 HL 模块。另一个是使用元和元元级推理来推理正在进行的推理，等等。你知道，150 个突破听起来很多，但你知道，如果你除以 37 年，它就不那么令人印象深刻了。所以，有这些启发式模块确实有助于改善推理。</font></font></p><p>And so, by now, we have about 150 of these sort of like breakthrough
            ideas that have led to dramatic speedups in the inference process. You
            know, where one of them was this EL HL split and lots of HL modules.
            Another one was using meta and meta meta level reasoning to reason about
            the reasoning that’s going on, and so on. And you know, 150
            breakthroughs may sound like a lot, but you know, if you divide by 37
            years, it’s not as impressive. So, there’s these kind of heuristic
            modules that really help improve the inference.</p>
        <h2 id="the-inference-problem"><font style="vertical-align:inherit"><font style="vertical-align:inherit">推理问题</font></font></h2><h2>The inference problem</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">总的来说，这有多难？因为你提到了高阶逻辑。你知道，从一般定理的角度来看，这是一个难以解决的、非常困难的问题。是的。那么，如果我们不谈论——如果我们放弃完美，专注于好的方面——这个推理问题有多难呢？我想说，从以下经验意义上讲，这是问题的一半，多年来，我们大约一半的努力，也许 40% 的努力，都是我们的推理程序员团队所付出的，另外 50% 到 60% 的努力是我们的本体论工程师所付出的，他们投入了知识。所以，在大多数情况下，我们的本体论工程师甚至不知道如何编程。他们拥有哲学等学位。所以，这几乎就像赫伯特·乔治·威尔斯的《</font></font><em><font style="vertical-align:inherit"><font style="vertical-align:inherit">时间机器》</font></font></em><font style="vertical-align:inherit"><font style="vertical-align:inherit">中的埃洛伊人和莫洛克人。</font></font></p><p>How hard, in general, is this? Because you mentioned higher order
            logic. You know, the, in the general theorem sense, it’s an intractable,
            very difficult problem. Yes. So, how hard is this inference problem when
            we’re not talking about—if we let go of the perfect and focus on the
            good? I would say it’s half of the problem in the following empirical
            sense, which is over the years, about half of our effort, maybe 40% of
            our effort, has been our team of inference programmers, and the other 50
            60% has been our ontologists, our ontological engineers, putting in
            knowledge. So, our ontological engineers, in most cases, don’t even know
            how to program. They have degrees in things like philosophy, and so on.
            So, it’s almost like the Eloi and the Morlocks in H.G. Wells’s <em>Time
                Machine</em>.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，埃洛伊人只使用认识论高阶逻辑语言进行编程。是的，而莫洛克人则像在地下一样，研究如何让这些语言高效运行，等等。所以，你知道，他们偶尔会互相发送消息，等等。但当你拥有一种富有表现力的语言时，找到巧妙的方法来恢复效率和输入系统需要知道的内容，两者的比例几乎是 50/50。是的，在某种程度上，两者都很迷人。</font></font></p><p>So, you have the Eloi who only program in the epistemological higher
            order logic language. Yes, and then you have the Morlocks who are like
            under the ground, figuring out what the machinery is that will make this
            efficiently operate, and so on. And so, you know, occasionally they’ll
            toss messages back to each other, and so on. But it really is almost a
            50/50 split between finding clever ways to recoup efficiency when you
            have an expressive language and putting in the content the system needs
            to know. Yeah, both are fascinating to some degree.</p>
        <h2 id="cycs-programming-language"><font style="vertical-align:inherit"><font style="vertical-align:inherit">Cyc 的编程语言</font></font></h2><h2>Cyc’s programming language</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">据我所知，整个系统都是用 Lisp 的各种变体编写的。所以，我最喜欢的编程语言仍然是 Lisp。我不再用它编程了，因为你知道，世界上大多数系统都已经发展了。比如，每个人都尊重 Lisp，但许多系统不再用 Lisp 编写了。但据我所知，Cyc 中有很多 Lisp，也许你可以纠正我。是的，所以它基于我们编写的 Lisp 代码。</font></font></p><p>The entirety of the system, as far as I understand, is written in
            various variants of Lisp. So, my favorite programming language is still
            Lisp. I don’t program in it much anymore because, you know, the world,
            in the majority of its systems, has moved on. Like, everybody respects
            Lisp, but many of the systems are not written in Lisp anymore. But Cyc,
            as far as I understand, maybe you can correct me there—there’s a bunch
            of Lisp in it. Yeah, so it’s based on a Lisp code that we produced.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">大多数编程仍然使用 Lisp 的方言进行，然后出于效率原因，会自动将其转换为 Java 或 C 之类的语言。如今，几乎所有的语言都转换为 Java，因为 Java 已经足够优秀，我们只需要这样做。因此，先将其转换为 Java，然后再将 Java 编译为字节码。是的，好的。所以，这有点像 — — 这个过程可能与 Cyc 最初编写时的情况有关，在构建强大的系统时，您必须处理一些技术深度，大多数跨越数年的强大系统都是如此。</font></font></p><p>Most of the programming is still going on in a dialect of Lisp, and
            then, for efficiency reasons, that gets automatically translated into
            things like Java or C. Nowadays, it’s almost all translated into Java
            because Java has gotten good enough that that’s really all we need to
            do. So, translate into Java, and then Java is compiled down to byte
            code. Yes, okay. So, that’s sort of—that’s a, you know, it’s a process
            that probably has to do with the fact that when Cyc was originally
            written, and you build up a powerful system like there is some technical
            depth you have to deal with, as is the case with most powerful systems
            that span years.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你考虑过这个问题吗？这可以帮助我理解，因为从我的角度来看，你在 Cyc 和 Cyc Corp 所做的一切的价值很大程度上在于知识。你有没有考虑过抛弃代码库，从头开始？不是真的抛弃，而是将其转移到抛弃技术债务，从更新的编程语言开始？这是否抛弃了很多价值？你的看法是什么？</font></font></p><p>Have you ever considered this? This would help me understand because,
            from my perspective, so much of the value of everything you’ve done with
            Cyc and Cyc Corp is the knowledge. Have you ever considered just like
            throwing away the code base and starting from scratch? Not really
            throwing away, but sort of moving it to like throwing away that
            technical debt, starting with a more updated programming language? Is
            that throwing away a lot of value, or no? Like, what’s your sense?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有多少价值体现在愚蠢的软件工程方面，又有多少价值体现在知识方面？所以，我认为，用 Lisp 开发程序的速度比用任何一种现代或改进的计算机语言开发程序的速度快一千到五万倍。好吧，还有其他函数式语言，比如 Clojure 和所有——有，但我的意思是，我同意你的观点。我喜欢 Lisp，但我只是想知道有多少优秀的程序员。</font></font></p><p>How much of the value is in the silly software engineering aspect,
            and how much of the value is in the knowledge? So, the development of
            programs in Lisp precedes, I think, somewhere between a thousand and
            50,000 times faster than development in any of what you’re calling
            modern or improved computer languages. Well, there are other functional
            languages, like, you know, Clojure and all the—there there’s, but I
            mean, I’m with you. I like Lisp, but I just wonder how many great
            programmers there are.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，还是有的。所以，这是真的。当一个新的推理程序员加入时，他们需要学习一些 Lisp，事实上，我们有一个 Lisp 的子集，我们巧妙地称之为 SubL，这实际上是他们需要学习的全部内容。因此，编程实际上是在 SubL 中进行的，而不是在完整的 Lisp 中进行的。因此，程序员学习 SubL 并不需要很长时间，然后可以有效地将其转换为 Java。对于我们一些从事用户界面工作的程序员来说，他们甚至不需要学习 SubL；他们只需学习基本 Psych 引擎的 API。所以你不一定会感到负担；它非常高效。这不是一个需要解决的问题，好吗？对，对。</font></font></p><p>There are still like, yes. So, it is true. When a new inference
            programmer comes on board, they need to learn some of Lisp, and in fact,
            we have a subset of Lisp which we call cleverly SubL, which is really
            all they need to learn. And so, the programming actually goes on in
            SubL, not in full Lisp. And so it does not take programmers very long at
            all to learn SubL, and that’s something which can then be translated
            efficiently into Java. And for some of our programmers who are doing,
            say, user interface work, then they never have to even learn SubL; they
            just have to learn APIs into the basic Psych engine. So you’re not
            necessarily feeling the burden of it; it’s extremely efficient. There’s
            that’s not a problem to solve, okay? Right, right.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">另一件事是，请记住，我们正在讨论雇用程序员进行推理，那么谁对有效的自动定理证明感兴趣呢？对。所以这些人已经倾向于用逻辑来表示事物，等等。Lisp 确实是基于逻辑的编程语言，它基本上是由 John McCarthy 和其他开发人员创建的。他们采用了 Alonzo Church 和其他哲学家、其他逻辑学家提出的形式主义，并基本上说：“我们能否基本上创建一种有效的逻辑编程语言？”</font></font></p><p>The other thing is, remember that we’re talking about hiring
            programmers to do inference, who are programmers interested in
            effectively automatic theorem proving? Right. And so those are people
            already predisposed to representing things in logic, and so on. Lisp
            really was the programming language based on logic that John McCarthy
            and others who developed it basically created. They took the formalisms
            that Alonzo Church and other philosophers, other logicians, had come up
            with and basically said, “Can we basically make a programming language
            which is effectively logic?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，由于我们讨论的是使用这种逻辑、认识论语言编写的表达式的推理，并且我们正在执行的操作实际上类似于定理证明类型的操作等，因此 Lisp 和知识（知识的表示方式）之间存在自然的阻抗匹配。所以我想你可以说它是一种非常合乎逻辑的语言。</font></font></p><p>So since we’re talking about reasoning in about expressions written
            in this logic, epistemological language, and we’re doing operations
            which are effectively like theorem proving type operations, and so on,
            there’s a natural impedance match between Lisp and the knowledge, the
            way it’s represented. So I guess you could say it’s a perfectly logical
            language to use.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">哦，是的，好的。我很抱歉。我甚至会放过你。比如，所以我将来可能会用到它，不会得到任何荣誉。不会得到任何荣誉。但不，我认为重点是你编程的语言并不是那么重要。更重要的是你必须能够思考，例如，创建新的有用的 HL 模块以及它们如何相互协作，并查看需要很长时间的事情并提出新的专门的数据结构，使其高效。</font></font></p><p>Oh, yes, okay. I’m sorry. I’ll even let you get away with that. Like,
            so I’ll probably use that in the future without without credit. Without
            credit. But no, I think I think the point is that the language you
            program in isn’t really that important. It’s more that you have to be
            able to think in terms of, for instance, creating new helpful HL modules
            and how they’ll work with each other, and looking at things that are
            taking a long time and coming up with new specialized data structures
            that will make this efficient.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我举一个非常简单的例子，当你有一个传递关系时，比如“大于”。这个大于那个，那个大于那个，那个大于那个。所以第一个必须大于最后一个。每当你有传递关系时，如果你不小心，如果我问这边这个东西是否大于那边那个东西，我将不得不进行某种图形遍历或定理证明，这可能涉及五步、十步、二十步或三十步。但如果你冗余地存储传递闭包，即传递关系的克莱尼星，现在你有了这个大表，但你总是可以保证，只需一步，你就可以查找这是否大于那个。</font></font></p><p>Let me just give you one very simple example, which is when you have
            a transitive relation, like “larger than.” This is larger than that,
            which is larger than that, which is larger than that. So the first thing
            must be larger than the last thing. Whenever you have a transitive
            relation, if you’re not careful, if I ask whether this thing over here
            is larger than that thing over here, I’ll have to do some kind of graph
            walk or theorem proving that might involve like five or ten or twenty or
            thirty steps. But if you store redundantly store the transitive closure,
            the Kleene star of that transitive relation, now you have this big
            table, but you can always guarantee that in one single step, you can
            just look up whether this is larger than that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，如今在很多情况下存储都很便宜，通过这种额外的冗余数据结构，我们可以非常有效地回答这种常见的问题。</font></font></p><p>And so we there are lots of cases where storage is cheap today, and
            so by having this extra redundant data structure, we can answer this
            commonly occurring type of question very, very efficiently.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">让我再举一个类比，一个与之类似的类比，我们称之为规则宏谓词。好吧，看看这个复杂的规则，我们会注意到语法上非常相似的东西一次又一次地出现。因此，我们将创建一个全新的关系、谓词或函数来捕获它，并且可能不只接受两个参数，可能接受三个、四个、五个参数等等。现在，我们已经有效地将一些可能需要对其进行推理的复杂 if then 规则转换为一些基本原子公式，这只是一个关系的名称和一些参数等等。将常见的规则类型或模式转换为全新的谓词、全新的函数，可以大大加快推理过程。</font></font></p><p>Let me give you one other analogy, an analog of that, which is
            something we call rule macro predicates. Which is well, see this
            complicated rule, and well notice that things very much like it
            syntactically come up again and again and again. So, well create a whole
            brand new relation or predicate or function that captures that and takes
            maybe not two arguments, takes maybe three, four, five arguments, and so
            on. And now we have effectively converted some complicated if then rule
            that might have to have inference done on it into some ground atomic
            formula, which is just the name of a relation and a few arguments, and
            so on. Converting commonly occurring types or schemas of rules into
            brand new predicates, brand new functions, turns out to enormously speed
            up the inference process.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">现在我们已经讨论了我所说的 150 个好主意中的 4 个。所以，这是一个好主意，一个很酷的主意。特别是这个想法就像一个很好的压缩，结果非常有用。是的，这真的很有趣。我的意思是，这整个事情都很迷人。</font></font></p><p>So, so now we’ve covered about four of the 150 good ideas I said
            that. So, that’s a nice, that’s a cool idea. That idea in particular is
            like a nice compression that turns out to be really useful. Yeah, that’s
            really interesting. I mean, this whole thing is just fascinating.</p>
        <h2 id="ontological-engineering"><font style="vertical-align:inherit"><font style="vertical-align:inherit">本体工程</font></font></h2><h2>Ontological engineering</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">从哲学角度来看，我的一部分——我的意思是，这让我有点难过，因为你的工作从计算机科学的角度来看很迷人，而从认识论、哲学的角度来看，推理引擎也很迷人。但你知道，这也是——你在经营一家公司，有些东西必须保密，这很可悲。</font></font></p><p>From a philosophical perspective, there’s part of me—I mean, it makes
            me a little bit sad because your work is both, from a computer science
            perspective, fascinating, and the inference engine, from an
            epistemological, philosophical aspect, fascinating. But you know, it is
            also—you’re running a company, and there’s some stuff that has to remain
            private, and it’s sad.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">好吧，有件事可能会让你感觉好一点。我们成立了一家非营利公司，名为知识去中心化研究所 (Nex KX)。我坚信，有大量经验证据支持这一观点，即人们在高中、大学、研究生院等学校接受的教育与他们能否快速掌握这种本体论工程以及在 Cyc 中编写这些断言和规则等几乎完全无关。我们经常会面试拥有哲学博士学位、教授逻辑多年等的候选人，他们只是……他们太糟糕了。但事实恰恰相反。所以，我们见过的最好的本体论工程师之一从未从高中毕业。</font></font></p><p>Well, here’s something that may make you feel a little bit better.
            We’ve formed a not for profit company called the Knowledge Axenization
            Institute, Nex KX. I have this firm belief, with a lot of empirical
            evidence to support it, that the education that people get in high
            schools, in colleges, in graduate schools, and so on, is almost
            completely orthogonal to, almost completely irrelevant to, how good
            they’re going to be at coming up to speed in doing this kind of
            ontological engineering and writing these assertions and rules, and so
            on, in Cyc. Very often, we’ll interview candidates who have their PhD in
            philosophy, who’ve taught logic for years, and so on, and they’re just…
            they’re just awful. But the converse is true. So, one of the best
            ontological engineers we ever had never graduated high school.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果我们能得到一些基金会的支持，知识去中心化研究所的目的是从普通民众中找出有这种天赋的人，比如高中辍学生。为他们提供奖学金来培训他们，然后帮助他们进入需要更多受过培训的本体论工程师的公司。其中一些人会为我们工作，但大多数会为合作伙伴或客户工作。如果我们能做到这一点，就会为那些目前无法摆脱困境的人创造大量相对高薪的工作。</font></font></p><p>The purpose of the Knowledge Axenization Institute, if we can get
            some foundations to help support it, is to identify people in the
            general population, maybe high school dropouts, who have latent talent
            for this sort of thing. Offer them, effectively, scholarships to train
            them, and then help place them in companies that need more trained
            ontological engineers. Some of which would be working for us, but mostly
            would be working for partners or customers, or something. And if we
            could do that, that would create an enormous number of relatively very
            high paying jobs for people who currently have no way out of some, you
            know, situation that they’re locked into.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，有什么词可以形容一个擅长本体论工程的人吗？一个人的哪些特质使他们擅长这项任务？将人类语言和知识的混乱转化为形式逻辑，这一任务与阿兰·图灵在二战期间所做的事情非常相似。为了寻找可以带去布莱切利园的人，他会在《伦敦时报》上发表神秘的填字游戏，并附上一些看似无害的便条。这张便条上写着：“如果你能在 15 分钟内解开这个谜题，请拨打这个电话号码。”</font></font></p><p>So is there something you can put into words that describes somebody
            who would be great at ontological engineering? What characteristics
            about a person make them great at this task? This task of converting the
            messiness of human language and knowledge into formal logic is very much
            like what Alan Turing had to do during World War II. In trying to find
            people to bring to Bletchley Park, he would publish cryptic crossword
            puzzles in the London Times, along with some innocuous looking note.
            This note essentially said, “If you were able to solve this puzzle in
            less than 15 minutes, please call this phone number.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">等等。你知道，或者在我年轻的时候，有一种习惯，就是用火柴盒。火柴盒里面会有一幅画。上面写着，“你能画这个吗？如果你从事艺术、商业艺术，如果你能复制这幅画，你知道，等等。”所以，是的，那里有类似的情况。一个小测试，可以直击你是否擅长。</font></font></p><p>And so on. You know, or back when I was young, there was the practice
            of having matchbooks. On the inside of the matchbook, there would be a
            drawing. It would say, “Can you draw this? If you have a career in art,
            commercial art, if you can copy this drawing, you know, and so on.” So,
            yes, the analog of that is there. A little test that gets to the core of
            whether you’re going to be good or not.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，部分原因在于能否创造和欣赏双关语和其他笑话，并做出适当的负面反应。所以，你必须有幽默感。如果你善于讲笑话，善于理解笑话，那就是一个指标。双关语，是的。像老爸笑话，是的。好吧，也许不是老爸笑话，而是真正的、有趣的笑话。</font></font></p><p>So, part of it has to do with being able to make and appreciate, and
            react negatively appropriately to puns and other jokes. So, you have to
            have a kind of sense of humor. And if you’re good at telling jokes and
            good at understanding jokes, that’s one indicator. Puns, yes. Like dad
            jokes, yes. Well, maybe not dad jokes, but real, funny jokes.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但我想我正在申请一份工作……不，但另一个是如果你能够自省。很多时候，我们会问某人一个简单的问题，然后说：“为什么会这样？”你知道，有时他们会说：“因为就是这样。”好吧，这是一个不好的迹象。但很多时候，他们能够自省。等等。</font></font></p><p>But I think I’m applying to work as sore… no, but another is if
            you’re able to introspect. Very often, we’ll give someone a simple
            question and say, “Why is this?” And you know, sometimes they’ll just
            say, “Because it is.” Okay, that’s a bad sign. But very often, they’ll
            be able to introspect. And so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，我经常问的一个问题是：我会指出一个包含代词的句子，然后说，“这个代词的指称显然是这里的这个名词。你知道，你、我、人工智能、五岁或十岁的孩子怎么会知道这个代词指的是这里的这个名词？”</font></font></p><p>So, one of the questions I often ask is: I’ll point to a sentence
            with a pronoun in it, and I’ll say, “The referent of that pronoun is
            obviously this noun over here. You know, how would you, or I, or an AI,
            or a five year old, or a ten year old child know that that pronoun
            refers to that noun over here?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">通常，擅长本体论工程的人会给我一些因果解释，或者会提到世界上的一些真实事物。所以，如果你想象这样一个句子，“马被牵进谷仓时，它的头还是湿的。”所以，“它的头”指的是马的头。但你怎么知道呢？</font></font></p><p>Often, the people who are going to be good at ontological engineering
            will give me some causal explanation, or will refer to some things that
            are true in the world. So, if you imagine a sentence like, “The horse
            was led into the barn while its head was still wet.” And so, “its head”
            refers to the horse’s head. But how do you know that?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有些人会说：“我就是知道。”有些人会说：“嗯，马是这个句子的主语。”我会说：“好吧，那‘马被牵进谷仓时，它的屋顶还是湿的’呢？”现在，“它的屋顶”显然是指谷仓。然后他们会说：“哦，那是因为它是最接近的名词。”</font></font></p><p>Some people will say, “I just know it.” Some people will say, “Well,
            the horse was the subject of the sentence.” And I’ll say, “Okay, well,
            what about, ‘The horse was led into the barn while its roof was still
            wet’?” Now, “its roof” obviously refers to the barn. And so, then
            they’ll say, “Oh, well, that’s because it’s the closest noun.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，基本上，如果他们试图给我基于句法和语法等的答案，那是一个非常糟糕的迹象。但如果他们能说出这样的话：“嗯，马有头而谷仓没有，谷仓有屋顶而马没有”，那么这是一个积极的信号，表明他们会擅长这一点，因为他们可以反思世界上的真相。这会让你知道某些事情。获得博士学位会让你更难深入反思这一点，这有多神奇？</font></font></p><p>And so, basically, if they try to give me answers which are based on
            syntax and grammar and so on, that’s a really bad sign. But if they’re
            able to say things like, “Well, horses have heads and barns don’t, and
            barns have roofs and horses don’t,” then that’s a positive sign that
            they’re going to be good at this because they can introspect on what’s
            true in the world. That leads you to know certain things. How
            fascinating is it that getting a PhD makes you less capable of
            introspecting deeply about this?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">哦，我不会——我不会走那么远。我并不是说这会降低你的能力。我们只能说它与——我不知道——人们有多优秀无关。你不是这么说的。我是说有某种……有趣的是，对于很多人，博士——抱歉，哲学除外——来说，有时教育会缩小你的思维而不是扩展它。是的，这有点令人着迷。当然，当你试图进行本体论工程时，这本质上是教我们未来的人工智能霸主如何深入推理这个世界以及如何理解它，这需要你深入思考这个世界。</font></font></p><p>Oh, I wouldn’t—I wouldn’t go that far. I’m not saying that it makes
            you less capable. Let’s just say it’s independent of—I don’t know—of how
            good people are. You’re not saying that. I’m saying that there’s a
            certain kind… It’s… it’s interesting that for a lot of people,
            PhDs—sorry, philosophy aside—that sometimes education narrows your
            thinking versus expands it. Yes, it’s kind of fascinating. And for
            certain, when you’re trying to do ontological engineering, which is
            essentially teaching our future AI overlords how to reason deeply about
            this world and how to understand it, that requires that you think deeply
            about the world.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，我要告诉你一个关于 Mathcraft 的悲伤故事。为什么它在今天的学校里没有被广泛使用？我们并不是想从中赚取巨额利润或诸如此类的事情。当我们去学校时，他们的态度是，“好吧，如果一个学生从头到尾花 20 个小时学习这个 Mathcraft 程序，等等，这会比他们花 20 个小时只是做无意义的练习来提高他们在标准化考试中的分数吗？”答案是，“嗯，不会。”但它会增加他们的理解，他们的态度是，“好吧，如果它不能提高他们在这次考试中的分数，那么我们就不会采用它。”这很可悲。我的意思是，这是关于教育系统的又一个三四个小时的谈话。</font></font></p><p>So, I’ll tell you a sad story about Mathcraft. Why is that not widely
            used in schools today? We’re not really trying to make big profit on it
            or anything like that. When we’ve gone to schools, their attitude has
            been, “Well, if a student spends 20 hours going through this Mathcraft
            program from start to end, and so on, will it improve their score on
            this standardized test more than if they spent 20 hours just doing
            mindless drills of problem after problem after problem?” And the answer
            is, “Well, no.” But it’ll increase their understanding more, and their
            attitude is, “Well, if it doesn’t increase their score on this test,
            then that’s not—you know, we’re not going to adopt it.” That’s sad. I
            mean, that’s a whole—that’s a whole another three or four hour
            conversation about the education system.</p>
        <h2 id="do-machines-think"><font style="vertical-align:inherit"><font style="vertical-align:inherit">机器会思考吗？</font></font></h2><h2>Do machines think?</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但是让我问你——让我来谈一谈哲学问题，就好像我们还没有这样做过一样。1950 年，艾伦·图灵撰写了一篇论文，制定了图灵测试。是的，他在论文的开头提出了一个问题：“机器能思考吗？”那么，你怎么看？机器能思考吗？让我问你这个问题。当然。机器可以思考，当然和人类一样思考。对吧？我们是肉机器。仅仅因为它们目前不是由肉制成的，你知道，这只是一个工程解决方案决策，等等。</font></font></p><p>But let me ask you—let me go super philosophical, as if we weren’t
            already. In 1950, Alan Turing wrote the paper that formulated the Turing
            Test. Yes, and he opened the paper with the question, “Can machines
            think?” So, what do you think? Can machines think? Let me ask you this
            question. Absolutely. Machines can think, certainly as well as humans
            can think. Right? We’re meat machines. Just because they’re not
            currently made out of meat is just, you know, an engineering solution
            decision, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，嗯，当然，机器可以思考。我认为，人们误解了图灵的模仿游戏，并专注于试图让聊天机器人欺骗其他人，让其认为它是人类，等等，这造成了很大的损害。这本身并不是一个糟糕的测试，但它不应该是你唯一的智力测试。所以，就智力测试而言，你知道，有洛布纳奖，这是一种非常，你想说的图灵测试最初制定的更严格的表述，然后还有像 Alexa 奖这样的测试，这是一种更有趣的测试表述。我想说，衡量标准是人类想要与人工智能系统交谈多长时间。所以，如果目标是 20 分钟，那么基本上就不仅仅是进行一次令人信服的对话，而更像是一次引人入胜、有趣或有趣的对话。我的意思是，这似乎更符合图灵想象的精神。</font></font></p><p>So, um, of course, of course, machines can think. I think that there
            was a lot of damage done by people misunderstanding Turing’s imitation
            game and focusing on trying to try to get a chatbot to fool other people
            into thinking it was human, and so on. That’s not a terrible test in and
            of itself, but it shouldn’t be your one and only test for intelligence.
            So, in terms of tests of intelligence, you know, with the Loebner Prize,
            which is a very, kind of, you want to say a more strict formulation of
            the Turing Test as originally formulated, and then there’s something
            like the Alexa Prize, which is a more interesting formulation of the
            test. I would say the metric is how long a human wants to talk to the AI
            system. So, if the goal is 20 minutes, it’s basically not just having a
            convincing conversation, but more like a compelling, fun, or interesting
            one. I mean, that seems more to the spirit of what Turing was
            imagining.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但是，你认为在测试领域什么才是好的测试？比如，当你看到一个基于心理学的系统通过了测试，你会说，“该死，我们在这里创造了一些特别的东西。”测试必须涉及推理的深度和递归性。回答关于你刚刚给出的答案的重复“为什么”问题的能力。你可以连续回答多少个“为什么”问题？诸如此类。此外，只有一个年幼、好奇的孩子和一个人工智能系统，人工智能系统在想要退出之前能持续多久？是的。再说一次，这不是唯一的测试。另一个测试与辩论有关。换句话说，这是一个命题；提出支持和反对它的论点，并尝试给我两边令人信服的论点。所以，我认为这是系统需要能够展现的另一种重要能力，才能真正变得智能，我认为。</font></font></p><p>But what, for you, do you think in the space of tests is a good test?
            Like, when you see a system based on psych that passes that test, you’d
            be like, “Damn, we’ve created something special here.” The test has to
            involve depth of reasoning and recursiveness of reasoning. The ability
            to answer repeated “why” questions about the answer you just gave. It’s
            how many “why” questions in a row can you keep answering? Something like
            that. And also, just having a young, curious child and an AI system, and
            how long will an AI system last before it wants to quit? Yes. And again,
            that’s not the only test. Another one has to do with argumentation. In
            other words, here’s a proposition; come up with pro and con arguments
            for it, and try and give me convincing arguments on both sides. So,
            that’s another important kind of ability that the system needs to be
            able to exhibit in order to really be intelligent, I think.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，有一些——我的意思是，如果你看看 IBM Watson，你会发现它在非常具体的测试中取得了一些令人印象深刻的成就，几乎就像一个演示，对吧？有一些硬编码、启发式方法和技巧，你试图把它们结合起来，让这个东西最终发挥作用。对吧？这似乎是人工智能的一个教训：这是获得令人印象深刻的解决方案的最快方法。</font></font></p><p>So, there are certain—I mean, if you look at IBM Watson and like
            certain impressive accomplishments for very specific tests, almost like
            a demo, right? There is some hard coding, heuristics, and tricks that
            you try to pull it all together to make the thing work in the end for
            this thing. Right? That seems to be one of the lessons with AI: that’s
            the fastest way to get a solution that’s pretty damn impressive.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，我想说的是：尽管这很令人印象深刻，但它还是犯了一些错误。但更重要的是，它犯的许多错误都是人类不会犯的错误。是的。因此，新的或增强的图灵测试的一部分必须是，你所犯的错误是人类不会看到并说“什么？”的错误。</font></font></p><p>So, here’s what I would say: as impressive as that was, it made some
            mistakes. But more importantly, many of the mistakes it made were
            mistakes which no human would have made. Yeah. And so, part of the new
            or augmented Turing tests would have to be that the mistakes you make
            are ones which humans don’t basically look at and say, “What?”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">例如，有一道关于 16 世纪意大利政治家的问题，沃森回答的是罗纳德·里根。所以，大多数美国人都会答错这个问题，但他们永远不会回答罗纳德·里根。对吧？因为他们知道他生活的时间相对较近。人们实际上活不到 400 岁，你知道这类事情。我认为这是一件非常重要的事情。也就是说，如果它犯了正常、理智的人不会犯的错误，那么这是一个非常糟糕的迹象。</font></font></p><p>For example, there was a question about a 16th century Italian
            politician, and Watson said Ronald Reagan. So, most Americans would have
            gotten that question wrong, but they would never have said Ronald Reagan
            as an answer. Right? Because among the things they know is that he lived
            relatively recently. People don’t really live 400 years, and you know
            things like that. That’s, I think, a very important thing. Which is, if
            it’s making mistakes that no normal, sane human would have made, then
            that’s a really bad sign.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果它没有犯这些错误，那就是一个好兆头。我不认为这是通过任何一项非常简单的测试就能解决的。我认为，这是你提到的所有事情，我提到的所有事情。实际上，有一系列测试，如果它通过了几乎所有这些测试，就很难说它不智能。如果它没有通过其中几项测试，就很难说它真的明白自己在做什么，很难说它真的具有普遍的智能。</font></font></p><p>And if it’s not making those kinds of mistakes, then that’s a good
            sign. And I don’t think it’s any one very, very simple test. I think
            it’s all of the things you mentioned, all the things I mentioned.
            There’s really a battery of tests which, together, if it passes almost
            all of these tests, it would be hard to argue that it’s not intelligent.
            And if it fails several of these tests, it’s really hard to argue that
            it really understands what it’s doing, that it really is generally
            intelligent.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，为了通过所有这些测试，我们已经讨论了很多关于心理学、知识和推理的内容。你认为这个人工智能系统是否需要一些其他类似人类的元素，例如，身体或这个世界的物理表现？另一个似乎是人类体验的基础，那就是意识——即对真实自我的主观体验。你认为它需要这些才能通过所有这些测试并实现一般智能吗？</font></font></p><p>So, to pass all of those tests, you know, we’ve talked a lot about
            psych and knowledge and reasoning. Do you think this AI system would
            need to have some other human like elements, for example, a body or a
            physical manifestation in this world? And another one, which seems to be
            fundamental to the human experience, is consciousness—the subjective
            experience of what it’s like to actually be you. Do you think it needs
            those to be able to pass all those tests and to achieve general
            intelligence?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这是个好问题。我认为，就身体而言，不是。我知道有很多人，比如彭罗斯，会不同意我的观点，等等。但不，我不认为它需要有身体才能有智慧。我认为它需要能够谈论拥有身体、拥有感觉、拥有情感等等。它实际上不必拥有所有这些，但它必须理解这些，就像海伦·凯勒一样，她非常聪明，能够谈论颜色、声音和形状等等，即使她没有直接体验到我们其他人所经历的所有事情。所以，了解它并能够正确利用它当然是一项重要的能力。但实际上拥有身体——如果你认为那只是一种宗教或神秘信仰——我想你真的无法支持或反对它。这只是一些人……一些人相信的东西。</font></font></p><p>It’s a good question. I think, in the case of a body, no. I know
            there are a lot of people, like Penrose, who would have disagreed with
            me, and so on, and others. But no, I don’t think it needs to have a body
            in order to be intelligent. I think that it needs to be able to talk
            about having a body, and having sensations, and having emotions, and so
            on. It doesn’t actually have to have all of that, but it has to
            understand it in the same way that Helen Keller was perfectly
            intelligent and able to talk about colors and sounds and shapes, and so
            on, even though she didn’t directly experience all the same things that
            the rest of us do. So, knowledge of it and being able to correctly make
            use of that is certainly an important facility. But actually having a
            body—if you believe that that’s just a kind of religious or mystical
            belief—you can’t really argue for or against it, I suppose. It’s just
            something that some people… some people believe.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那么，身体的延伸，也就是意识呢？我的意思是，感觉就像是存在一样。当然。但你知道，这到底意味着什么？就好像，如果我跟你说话，你说的话会让我相信你有意识。是的，我知道我有意识。但你知道，你现在只是相信我的话。但从同样的意义上讲，心理学已经具有同样的意识。当然，它明白自己是一个计算机程序。</font></font></p><p>What about the like an extension of the body, which is consciousness?
            I mean, like, it feels like something to be here. Sure. But you know,
            what does that really mean? It’s like, well, if I talk to you, you say
            things which make me believe that you are conscious. Yeah, I know that
            I’m conscious. But that’s, you know, you’re just taking my word for it
            now. But in the same sense, psych is conscious in that same sense
            already. Where, of course, it understands it’s a computer program.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">它知道自己在何时何地运行。它知道谁在跟它说话。它知道自己的任务是什么、目标是什么、以及当前正在解决的问题是什么。它知道自己在某件事上花了多长时间、尝试了什么、知道自己过去做过什么等等。如果我们想称之为意识，那么是的，心理已经是有意识的了，但我认为我不会将任何神秘的东西归因于它。同样，有些人会，但我想说，除了我们个人的意识体验之外，我们只是按照他们所说的来对待世界上的其他人。所以，如果一个计算机程序，如果一个人工智能，能够表现出与你期望的有意识实体相同的所有反应，那么，你知道，它是否同样值得被称为意识？</font></font></p><p>It understands where and when it’s running. It understands who’s
            talking to it. It understands what its task is, what its goals are, and
            what the current problem it is working on is. It understands how long
            it’s spent on things, what it’s tried, it understands what it’s done in
            the past, and so on. And you know, if we want to call that
            consciousness, then yes, Psych is already conscious, but I don’t think
            that I would ascribe anything mystical to that. Again, some people
            would, but I would say that, you know, other than our personal
            experience of consciousness, we’re just treating everyone else in the
            world, so to speak, at their word about being conscious. And so, if a
            computer program, if an AI, is able to exhibit all the same kinds of
            responses as you would expect of a conscious entity, then, you know,
            doesn’t it deserve the label of consciousness just as much?</p>
        <h2 id="death-and-consciousness"><font style="vertical-align:inherit"><font style="vertical-align:inherit">死亡与意识</font></font></h2><h2>Death and consciousness</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，人类拥有的这种智慧还带来了另一种负担：意识之光的消失，也就是意识到我们终有一天会死去。许多哲学家，比如欧内斯特·贝克尔，认为这种对死亡的认识以及恐惧，有时他们称之为对死亡的恐惧，是人类生存状态背后的一种创造力。就像，它是驱动我们前进的动力。</font></font></p><p>So, there’s another burden that comes with this whole intelligence
            thing that humans got: the extinguishing of the light of consciousness,
            which is kind of realizing that we’re going to be dead someday. And
            there’s a bunch of philosophers, like Ernest Becker, who kind of think
            that this realization of mortality, and then fear, sometimes they call
            it the terror of mortality, is one of the creative forces behind the
            human condition. Like, it’s the thing that drives us.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你认为这对人工智能系统来说重要吗？你知道，当心理学家提出人工智能是内容审核者之一时，它可能会问另一个问题，比如，它知道人类是会死的。我是会死的吗？</font></font></p><p>Do you think it’s important for an AI system, you know, when Psych
            proposed that it’s one—it’s not human—and it’s one of the moderators of
            its contents, you know, there’s another question it could ask, which is
            like, it kind of knows that humans are mortal. Am I mortal?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为，当你有意识时，一件非常重要的事情就是害怕意识的消亡，害怕死亡。你认为这对智能思维有用吗？比如，我可能会死，但我真的不想死。我不这么认为。我认为这可能有助于一些人成为更好的人，可能有助于一些人更有创造力，等等。我认为人工智能没有必要相信他们的寿命有限，因此他们应该充分利用自己的行为。也许最终这个问题的答案，以及我的答案，都会改变，但就目前而言，我想说这几乎就像是一种装饰或副作用，事实上，如果你看看大多数人，大多数人都会忽视他们大多数时候都会死的事实。</font></font></p><p>And I think one really important thing that’s possible when you’re
            conscious is to fear the extinguishing of that consciousness, the fear
            of mortality. Do you think that’s useful for intelligent thinking? Like,
            I might die, and I really don’t want to die. I don’t think so. I think
            it may help some humans to be better people, it may help some humans to
            be more creative, and so on. I don’t think it’s necessary for AI to
            believe that they have limited lifespans and therefore they should make
            the most of their behavior. Maybe eventually the answer to that, and my
            answer to that, will change, but as of now, I would say that that’s
            almost like a frill or a side effect that is not, in fact, if you look
            at most humans, most humans ignore the fact that they’re going to die
            most of the time.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，好吧，但这就像是文字之间的空白。所以，欧内斯特·贝克尔认为，这种忽视是——我们生活在一种幻想中，这种幻想是我们建立在这种恐惧的基础上的。所以，我们逃避我们所知道的生活，追求事物，创造事物，热爱我们能想到的人类美好的一切，只是为了逃避我们终有一天会死去的现实。这是他的想法，我认为……我不知道我是否 100% 相信这一点，但它确实押韵；在我看来，它与真相押韵。是的，我认为对一些人来说，这将是一个比其他人更强大的因素。</font></font></p><p>So, well, but that’s like this goes to the whitespace between the
            words. So, what Ernest Becker argues is that that ignoring is—we’re
            living in an illusion that we constructed on the foundation of this
            terror. So, we’re escaping life as we know it, pursuing things, creating
            things, loving everything we can think of that’s beautiful about
            humanity is just trying to escape this realization that we’re going to
            die one day. That’s his idea, and I think… I don’t know if I 100%
            believe in this, but it certainly rhymes; it seems to me like it rhymes
            with the truth. Yeah, I think that for some people, that’s going to be a
            more powerful factor than others.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">显然，Doug 谈论的是俄罗斯人，我认为——我是俄罗斯人——所以它显然渗透到了所有俄罗斯文学中。人工智能不必以对死亡的恐惧作为驱动力。我们可以在其中建立动机；所以我们可以建立服从用户、让用户快乐、让别人快乐等动机。这可以替代这种有时会导致人类创造力爆发的个人对死亡的恐惧。我不知道。</font></font></p><p>Clearly, Doug is talking about Russians, and I think that—so I’m
            Russian—so it clearly infiltrates all of Russian literature. And AI
            doesn’t have to have fear of death as a motivating force. In that, we
            can build in motivation; so we can build in the motivation of obeying
            users and making users happy and making others happy, and so on. And
            that can substitute for this sort of personal fear of death that
            sometimes leads to bursts of creativity in humans. I don’t know.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为……我认为人工智能确实需要深刻理解死亡，才能驾驶汽车。我……我认为有些……不，我真的不同意。我认为它需要了解人类生命的价值，尤其是人类生命对其他人类的价值，并了解某些事情比其他事情更重要。因此，它必须拥有大量关于伦理道德等方面的知识。但其中一些知识非常混乱，无法编码。</font></font></p><p>I think like… I think AI really needs to understand death deeply in
            order to be able to drive a car, for example. I… I think there’s just
            some… like… no, I really disagree. I think it needs to understand the
            value of human life, especially the value of human life to other humans,
            and understand that certain things are more important than other things.
            So, it has to have a lot of knowledge about ethics and morality, and so
            on. But some of it is so messy that it’s impossible to encode, for
            example.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我不同意这一点。所以，如果有人在我们面前死去，大多数人都会帮助他，但他们不会把同样的道德观应用到世界上的其他人身上。这就是医生工作有多难的悲剧，因为他们知道，当他们帮助一个垂死的孩子时，他们知道他们花在这个孩子身上的钱不可能花在其他垂死的孩子身上。这是一个很难做出的决定。</font></font></p><p>There, I disagree. So, if there’s a person dying right in front of
            us, most human beings would help that person, but they would not apply
            that same ethics to everybody else in the world. This is the tragedy of
            how difficult it is to be a doctor, because they know when they help a
            dying child, they know that the money they’re spending on this child
            cannot possibly be spent on every other child that’s dying. And that’s a
            very difficult to encode decision.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">现在，也许，也许就是这样。也许它可以正式化。哦，但我的意思是，你谈论的是自动驾驶汽车，对吧？因此，自动驾驶汽车将不得不一直做出这些决定：这个坏事发生的几率有多大，与那个坏事发生的几率相比，这个坏事有多严重，等等。你知道，当潜在事故即将发生时，是否值得冒这个险？如果我必须做出选择，我会撞这两辆车中的哪一辆，为什么？</font></font></p><p>Now, perhaps, perhaps it is. Perhaps it could be formalized. Oh, but
            I mean, you’re talking about autonomous vehicles, right? So, autonomous
            vehicles are going to have to make those decisions all the time: of what
            is the chance of this bad event happening, how bad is that compared to
            this chance of that bad event happening, and so on. And you know, when a
            potential accident is about to happen, is it worth taking this risk? If
            I have to make a choice, which of these two cars am I going to hit, and
            why?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">瞧，当我谈论死亡率时，我在考虑一种非常不同的选择，那就是观察曼哈顿式的驾驶方式。我认为，人类作为有效的驾驶员，需要经常威胁行人的生命。这是一种舞蹈。我经常观察行人。我研究过这个问题，似乎如果我可以总结一下行人过马路的问题，那就是汽车在移动时说“我要杀了你”，而行人说“也许”，然后他们决定说“不，我不认为你有胆量杀了我”，然后你走，他们走在前面，把目光移开。这就是那种舞蹈——行人。</font></font></p><p>And see, I was thinking about a very different choice when I’m
            talking about mortality, which is just observing Manhattan style
            driving. I think that humans, as an effective driver, need to threaten
            pedestrians’ lives a lot. There’s a dance. I’ve watched pedestrians a
            lot. I worked on this problem, and it seems like if I could summarize
            the problem of a pedestrian crossing, it is the car with this movement
            is saying “I’m going to kill you,” and the pedestrian is saying “Maybe,”
            and then they decide and they say “No, I don’t think you have the guts
            to kill me,” and you walk, and they walk in front and they look away.
            And there’s that dance—the, the, the, the pedestrian.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这是行人信任的社会契约——一旦他们站在汽车前面，从物理学角度来看，汽车能够停下来，他们就会停下来。但汽车也必须威胁行人——就像是，“我上班迟到了，所以你从我前面穿过马路真是个混蛋。”但生死是这里计算的一部分。这个等式每天都要被解决数百万次，是的，非常有效。</font></font></p><p>This is a social contract that the pedestrian trusts—that once
            they’re in front of the car, and the car is, from a physics perspective,
            able to stop, they’re going to stop. But the car also has to threaten
            that pedestrian—it’s like, “I’m late for work, so you’re being kind of
            an asshole by crossing in front of me.” But life and death is, like, is
            part of the calculation here. And it’s that equation being solved
            millions of times a day, yes, very effectively.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">那个博弈论——不管是什么，不管那个表述是什么——绝对是。我只是不知道它是否像某个可形式化的博弈论问题一样简单。在驾驶和大多数人类社会中，它很可能是这样的。我不知道，但它……是的，你可能是对的。这种对死亡的恐惧只是我们大脑进化的怪癖之一。但它不是——它不是智力的必要特征。司机当然总是在做这种估计，即使是无意识的，潜意识的，各种坏结果发生的几率有多大，比如，如果我不等这个行人或类似的事情，我会有什么坏处，比如，你知道，浪费时间和警察交谈，或者，你知道，被送进监狱，或者，你知道，诸如此类的事情。</font></font></p><p>That game theory—whatever, whatever that formulation is—absolutely. I
            just don’t know if it’s as simple as some formalizable game theory
            problem. It could very well be, in the case of driving and in the case
            of most of human society. I don’t know, but it… yeah, you might be
            right. That this sort of fear of death is just one of the quirks of how
            our brains have evolved. But it’s not—it’s not a necessary feature of
            intelligence. Drivers certainly are always doing this kind of estimate,
            even if it’s unconscious, subconscious, of what are the chances of
            various bad outcomes happening, like, for instance, if I don’t wait for
            this pedestrian or something like that, and what is the downside to me
            going to be in terms of, you know, time wasted talking to the police,
            or, you know, getting sent to jail, or, you know, things like that.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，还有情绪。比如，坐在车里的人往往会无缘无故地生气。这很危险。但是，你知道，想想看。这就是为什么我认为自动驾驶汽车——真正的自动驾驶汽车——比大多数人想象的还要遥远，因为它的复杂性远远超出了机械控制汽车的范围。我可以将自动驾驶汽车视为一种隐喻和字面意义上的事故，随时可能发生。这不仅仅是因为它们总体上会引发事故而不是预防事故等等，还因为人们对强大公司和强大实体的坏消息有着近乎贪婪的胃口。</font></font></p><p>And so, there’s also emotion. Like, people in their cars tend to get
            irrationally angry. That’s dangerous. But, you know, think about this.
            This is all part of why I think that autonomous vehicles—truly
            autonomous vehicles—are farther out than most people do, because there
            is this enormous level of complexity which goes beyond mechanically
            controlling the car. And I can see autonomous vehicles as a kind of
            metaphorical and literal accident waiting to happen. And not just
            because of their overall incurring versus preventing accidents and so
            on, but just because of the almost voracious appetite people have for
            bad stories about powerful companies and powerful entities.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">1987 年，我参加了日本第五代计算机系统会议，碰巧的是，当时我正巧在场，看到一家汽车厂的一名工人情绪低落，爬过安全链等自杀，被机器踩死。这可不是“情绪低落的工人自杀”的小故事，而是头版新闻，上面写着“机器人杀死工人”。因为公众只是在等待类似“人工智能杀死上镜的五口之家”之类的故事。</font></font></p><p>When I was at a—coincidentally—Japanese fifth generation computing
            system conference in 1987, while I happened to be there, there was a
            worker at an auto plant who was despondent and committed suicide by
            climbing under the safety chains and so on, getting stamped to death by
            a machine. And instead of being a small story that said, “Despondent
            worker commits suicide,” it was front page news that effectively said,
            “Robot kills worker.” Because the public is just waiting for stories
            about, like, “AI kills photogenic family of five” type stories.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">即使你能证明，在全国范围内，这个系统挽救的生命比它付出的代价多，避免的伤害比它造成的伤害多，等等……媒体、公众和政府都会蜂拥而至，随时准备抓住他们失败的故事，即使这些故事相对较少。是的，看到我们人类抵制尖端科学技术，几乎希望它失败，而且一直如此，真是太有趣了。你知道，这种情况在历史上一再发生。好吧，即使我们不希望它失败，我们也对它着迷。就我们感兴趣的内容而言，千分之一的失败比 999 个无聊的成功有趣得多。</font></font></p><p>And even if you could show that nationwide this system saved more
            lives than it cost, and saved more injuries, prevented more injuries
            than it caused, and so on… The media, the public, and the government are
            coiled and ready to pounce on stories where they, in fact, failed, even
            if those stories are relatively few. Yeah, it’s so fascinating to watch
            us humans resisting the cutting edge of science and technology, and
            almost like hoping for it to fail, and constantly. You know, this just
            happens over and over and over throughout history. Well, or even if
            we’re not hoping for it to fail, we’re fascinated by it. And in terms of
            what we find interesting, the one in a thousand failures is much more
            interesting than the 999 boring successes.</p>
        <h2 id="what-would-you-say-to-ai"><font style="vertical-align:inherit"><font style="vertical-align:inherit">你想对 AI 说点什么？</font></font></h2><h2>What would you say to AI?</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">因此，一旦我们建立了一个 AGI 系统，比如说，心理学是其中的一部分，那么很有可能你会成为第一批可以坐在房间里与她交谈的人之一。你会问她什么？你们会谈论什么？看看网络上的所有内容等等，对于世界上存在的大问题，有哪些可能的解决方案是人们以前从未真正想到过的，没有得到适当或至少充分的追求？你能想到哪些我们还没有想到的、可能有效、值得考虑的新解决方案？</font></font></p><p>So, once we build an AGI system, say, psych is some part of it, and
            say it’s very possible that you would be one of the first people that
            can sit down in the room, let’s say, with her and have a conversation.
            What would you ask her? What would you talk about? Looking at all of the
            content out there on the web and so on, what are some possible solutions
            to big problems that the world has that people haven’t really thought of
            before that are not being properly, or at least adequately, pursued?
            What are some novel solutions that you can think of that we haven’t,
            that might work, and that might be worth considering?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，这是一个非常好的问题。鉴于 AGI 与人类智能有所不同，它仍然会犯一些我们不会犯的错误，但它也可能会注意到我们的一些盲点。我很乐意用它来测试——它真的能与我们的智能相提并论吗？它能帮助我们发现一些盲点吗？</font></font></p><p>So, that is a damn good question. Given that the AGI is going to be
            somewhat different from human intelligence, it’s still going to make
            some mistakes that we wouldn’t make, but it’s also possibly going to
            notice some blind spots we have. And I would love it as a test of—is it
            really on a par with our intelligence? Can it help spot some of the
            blind spots that we have?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，问题分为两部分：您能否帮助确定世界上存在哪些大问题？第二，对于这些问题，有哪些新颖的解决方案，但没有人谈论过？是的。其中一些可能变得不可行或应受谴责，但其中一些可能确实值得关注。你知道，如果你回头看看一些最有力的发现，比如相对论和超导性等等，你会发现很多都是有人认真对待这个想法的案例，认为问题实际上可能有一个不明显的答案。</font></font></p><p>So, the two part question of: can you help identify what are the big
            problems in the world, and two, what are some novel solutions to those
            problems that are not being talked about by anyone? Yeah. And some of
            those may become, you know, infeasible or reprehensible or something,
            but some of them might be actually great things to look at. You know, if
            you go back and look at some of the most powerful discoveries that have
            been made, like relativity and superconductivity and so on, a lot of
            them were cases where someone took seriously the idea that there might
            actually be a non obvious answer to a question.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，在爱因斯坦的例子中，是这样的：是的，洛伦兹变换是已知的。没有人相信这实际上是现实运作的方式。如果现实真的是这样运作的呢？所以，你知道，很多人没有意识到他实际上并没有计算出这个方程。他只是把它当真了。或者，在超导性的情况下，你有这个 V=IR 方程，其中 R 是电阻，等等。它在越来越低的温度下被映射，但每个人都认为这只是对对数研究的一个提升，表明 V=I 始终成立。</font></font></p><p>So, in Einstein’s case, it was: yeah, the Lorentz transformation is
            known. Nobody believes that it’s actually the way reality works. What if
            it were the way that reality actually worked? So, you know, a lot of
            people don’t realize he didn’t actually work out that equation. He just
            sort of took it seriously. Or, in the case of superconductivity, you
            have this V=IR equation, where R is resistance, and so on. It was being
            mapped at lower and lower temperatures, but everyone thought that was
            just a bump on the log research to show that V=I always held.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">然后，当某个研究生的体温稍微降低，并且抵抗力突然下降时，每个人都认为他们做错了。直到不久之后，他们才意识到，嗯，这实际上是一种新现象。或者，在幽门螺杆菌引起胃溃疡的情况下，每个人都认为压力和胃酸会导致溃疡，而当一位澳大利亚医生声称这实际上是一种细菌感染时，没有人认真听他的话。</font></font></p><p>Then, when some graduate student got to a slightly lower temperature
            and showed that resistance suddenly dropped off, everyone just assumed
            they did it wrong. And it was only a little while later that they
            realized it was, um, it was actually a new phenomenon. Or, in the case
            of, um, the H. pylori bacteria causing stomach ulcers, where everyone
            thought that stress and stomach acid caused ulcers, and when a doctor in
            Australia claimed it was actually a bacterial infection, he couldn’t get
            anyone seriously to listen to him.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">最后，他不得不给自己注射细菌，以证明自己突然患上了危及生命的溃疡，以便让其他医生认真考虑这一点。所以，在很多事情中，人类都被锁定在范式中，托马斯·库恩称之为范式，我们无法轻易摆脱它们。所以，现在很多人工智能都被锁定在深度学习、机器学习范式中，几乎我们所有人，几乎所有科学都被锁定在当前的范式中。你知道，库恩的观点基本上是，你必须等到人们死去，新一代才能摆脱这些范式。我认为，改变这一悲惨现实的一件事是，如果我们有工具可以帮助我们退后一步，质疑我们目前被锁定的一些范式。是的，它将在人类科学和进步的范式转变中表现出色。</font></font></p><p>And he had to ultimately inject himself with the bacteria to show
            that he suddenly developed a life threatening ulcer in order to get
            other doctors to seriously consider that. So, there are all sorts of
            things where humans are locked into paradigms, what Thomas Kuhn called
            paradigms, and we can’t get out of them very easily. So, a lot of AI is
            locked into the deep learning, machine learning paradigm right now, and
            almost all of us, and almost all sciences, are locked into current
            paradigms. And you know, Kuhn’s point was pretty much you have to wait
            for people to die in order for the new generation to escape those
            paradigms. And I think that one of the things that would change that sad
            reality is if we had tools that could help take a step back and question
            some of the paradigms that we’re currently locked into. Yeah, it would
            excel at the paradigm shifts in human science and progress.</p>
        <h2 id="advice-to-young-people"><font style="vertical-align:inherit"><font style="vertical-align:inherit">给年轻人的建议</font></font></h2><h2>Advice to young people</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">你的一生非常有趣，你曾想过很多伟大的想法，并坚持不懈。你能给今天的年轻人，高中生、大学生，关于职业、关于生活的建议吗？</font></font></p><p>You’ve lived a very interesting life where you thought about big
            ideas and you stuck with them. Can you give advice to young people
            today, somebody in high school, somebody undergrad, about career, about
            life?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我想说，你可以有所作为，但为了有所作为，你必须有勇气坚持别人可能不会立即理解或支持的想法。你必须意识到，如果你制定的计划需要很长时间才能实施，不要害怕。这对身体锻炼、学习某些专业和创新都是如此。</font></font></p><p>I’d say you can make a difference, but in order to make a difference,
            you’re going to have to have the courage to follow through with ideas
            which other people might not immediately understand or support. You have
            to realize that if you make some plan that’s going to take an extended
            period of time to carry out, don’t be afraid of that. That’s true of
            physical training of your body, that’s true of learning some profession,
            that’s also true of innovation.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">有些创新并不是写在餐巾纸上的好主意，如果你的主意是正确的，它们会立刻取得成功。有些创新是你必须遵循的道路。但请记住，你终有一死，请记住，你一生中能下的赌注有限，而且要以十年为单位，你应该让每一次赌注都有意义。在人际关系、职业选择、发现等方面都是如此。</font></font></p><p>That some innovations are not great ideas you can write down on a
            napkin and become an instant success if you turn out to be right. Some
            of them are paths you have to follow. But remember that you’re mortal,
            remember that you have a limited number of decade sized bets to make
            with your life, and you should make each one of them count. And that’s
            true in personal relationships, that’s true in career choice, that’s
            true in making discoveries, and so on.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">如果你选择阻力最小的路径，你会发现你只是在短时间内进行优化，但不知不觉中，你就会发现很长一段时间过去了，而你却从未真正改变过世界。你知道，当你看的时候——我的意思是，我真正热爱的领域是人工智能，没有多少项目，没有多少小小的希望之火已经持续了很多年，几十年了。</font></font></p><p>And if you follow the path of least resistance, you’ll find that
            you’re optimizing for short periods of time, and before you know it, you
            turn around and long periods of time have gone by without you ever
            really making a difference in the world. You know, there’s—when you
            look—I mean, the field that I really love is artificial intelligence,
            and there’s not many projects, there’s not many little flames of hope
            that have been carried out for many years, for decades.</p>
        <h2 id="mortality"><font style="vertical-align:inherit"><font style="vertical-align:inherit">死亡</font></font></h2><h2>Mortality</h2>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">而 Cyc 就是其中之一。我的意思是，这本身就是一件非常鼓舞人心的事情。所以，我非常感激你们多年来一直传递着这种热情。我认为这对你们年轻人来说是一种鼓舞。</font></font></p><p>And Cyc represents one of them. And I mean that in itself is just a
            really inspiring thing. So, I’m deeply grateful that you would be
            carrying that flame for so many years. And I think that’s an inspiration
            to you young people.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">话虽如此，你说生命是有限的，我们谈到了死亡是人工智能的一个特征。你会考虑自己的死亡吗？你害怕死亡吗？当然。如果我不害怕，那我就是疯了。随着年龄的增长——我现在已经 70 多岁了——随着年龄的增长，我越来越担心死亡，尤其是当熟人和朋友，尤其是导师一个接一个地死去的时候。所以，我无法避免思考死亡。</font></font></p><p>That said, you said life is finite, and we talked about mortality as
            a feature of AI. Do you think about your own mortality? Are you afraid
            of death? Sure. I would be crazy if I weren’t. And as I get older—I’m
            now over 70—so as I get older, it’s more on my mind, especially as
            acquaintances and friends, and especially mentors, one by one, are
            dying. So, I can’t avoid thinking about mortality.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">我认为，从这个角度和世界其他地方的角度来看，好消息是，这增加了我在未来几年内取得成功的动力，因为我有一个最后期限。没错。我不会再有 37 年的时间继续从事这项工作。因此，我们确实希望在未来几年内对世界产生影响——无论是商业上、物理上还是形而上学上——基本上是在未来几年内：2、3、5 年。不再是 2、3、50 年了。因此，这确实促使我走向 Cyc 的商业化和越来越广泛的应用。而之前，我觉得我只需坐下来，翻白眼，等待世界赶上来。现在我不再有这种感觉了。我觉得我需要付出一些努力，让世界知道我们拥有什么以及它能做什么。</font></font></p><p>And I think that the good news, from the point of view, and the rest
            of the world, is that that adds impetus to my need to succeed in a small
            number of years in the future, because I’m—you have a deadline. Exactly.
            I’m not going to have another 37 years to continue working on this. So,
            we really do want, likely, to make an impact in the world—commercially,
            physically, metaphysically—basically in the next small number of years:
            2, 3, 5 years. Not 2, 3, 5 decades anymore. And so, this is really
            driving me toward this sort of commercialization and increasingly
            widespread application of Cyc. Whereas before, I felt that I could just
            sort of sit back, roll my eyes, wait till the world caught up. And now I
            don’t feel that way anymore. I feel like I need to put in some effort to
            make the world aware of what we have and what it can do.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">从你的角度来看，好消息就是我坐在这里的原因。你的工作效率会更高。我喜欢这样。如果我能以任何方式提供帮助，我很乐意，从程序员的角度来看。我喜欢，尤其是现在，以大大小小的方式做出贡献。所以，如果麻省理工学院方面有任何开源和研究，我很乐意提供帮助。</font></font></p><p>And the good news, from your point of view, is that that’s why I’m
            sitting here. You’re going to be more productive. I love it. And if I
            can help in any way, I would love to, from a—from a, you know, from a
            programmer perspective. I—I love, especially these days, just
            contributing in small and big ways. So, if there’s any open sourcing
            from the MIT side and the research, I would love to help.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">但当你知道，比 Cyc 更大的东西，就像我说的，是你身上那小小的人工智能火焰。大梦想就在那里。你希望你的遗产是什么？</font></font></p><p>But when you know, bigger than Cyc, like I said, it’s that little
            flame that you’re carrying of artificial intelligence. The big dream is
            there. What do you hope your legacy is?</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">这是个好问题。人们认为我是人工智能的先驱或发明者之一，这种人工智能无处不在，人们认为这是理所当然的，等等。就像我们今天回顾电力先驱或类似技术的先驱一样。如你所知，很难想象如果这些人没有做他们所做的事情，生活会是什么样子。所以，这是我希望人们记住的一件事。另一件事是，我希望人们记住我是这个庞大的知识存储和获取系统的创始人之一，无论未来人工智能是什么样子，这很可能都是核心。</font></font></p><p>That’s a good question. That people think of me as one of the
            pioneers or inventors of the AI that is ubiquitous and that they take
            for granted, and so on. Much, much the way that today we look back on
            the pioneers of electricity or the pioneers of similar types of
            technologies, and so on. As you know, it’s hard to imagine what life
            would be like if these people hadn’t done what they did. So, that’s one
            thing that I’d like to be remembered as. Another is that I’d like to be
            remembered as one of the originators of this gigantic knowledge store
            and acquisition system, that is likely to be at the center of whatever
            this future AI thing will look like.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，没错。我还希望人们记住我是一个不怕在一个项目上花费数十年时间的人，当时几乎所有其他机构力量和商业力量都在激励人们追求短期回报。很多人放弃了。很多和你一样怀揣梦想的人放弃了。是的，你没有。</font></font></p><p>Yes, exactly. And I’d also like to be remembered as someone who
            wasn’t afraid to spend several decades on a project in a time when
            almost all of the other institutional forces and commercial forces were
            incentivizing people to go for short term rewards. A lot of people gave
            up. A lot of people who dreamt the same dream as you gave up. Yes, and
            you didn’t.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">是的，道格，这真的是一种荣幸。这是一个漫长的等待。很多人特别提到你的工作，更广泛地说，从哲学角度来说，这是人工智能的梦想。这很可能是未来的一部分。今天，我们非常专注于机器学习应用，所有这些东西。但似乎 Cyc 所秉持的理念是他们试图解决的问题的核心——即智力、情感和其他方面的问题。</font></font></p><p>Yes, I mean, Doug, it’s truly an honor. This was a long time coming.
            I—a lot of people bring up your work specifically, and more broadly,
            philosophically, of this is the dream of artificial intelligence. This
            is likely a part of the future. We’re so sort of focused on machine
            learning applications, all that kind of stuff, today. But it seems like
            the ideas that Cyc carries forward are something that would be at the
            center of this problem they’re all trying to solve—which is the problem
            of intelligence, emotional and otherwise.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">所以，非常感谢。我很荣幸您今天能与我交谈并花宝贵的时间与我在一起。</font></font></p><p>So, thank you so much. It’s such a huge honor that you would talk to
            me and spend your valuable time with me today.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">谢谢你的采访，莱克斯。非常棒。谢谢你聆听与道格拉斯·莱纳特的对话。</font></font></p><p>Thanks for talking, Lex. It’s been great. Thanks for listening to
            this conversation with Douglas Lenat.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">为了支持这个播客，请查看描述中的赞助商。</font></font></p><p>To support this podcast, please check out our sponsors in the
            description.</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">现在，让我给你留下马克·吐温关于真理本质的几句话：“如果你说实话，你就不需要记住任何事情。”</font></font></p><p>Now, let me leave you some words from Mark Twain about the nature of
            truth: “If you tell the truth, you don’t have to remember anything.”</p>
        <p><font style="vertical-align:inherit"><font style="vertical-align:inherit">感谢您的聆听，希望下次再见。</font></font></p><p>Thank you for listening, and hope to see you next time.</p>


</div><script id="res-script" src="/res/dist/res/main.js" type="text/javascript"></script>
</body></html>