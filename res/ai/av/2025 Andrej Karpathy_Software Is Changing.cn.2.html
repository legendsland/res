<!DOCTYPE html><html lang="en"><head>
<meta name="dc.identifier" content="res/5f3b4194a6d45a1e7117e7319779301ad300130b">

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Andrej Karpathy: Software Is Changing (Again) | Andrej Karpathy：软件正在（再次）改变</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0 auto;
        }
        .en {
            color: #555;
            font-style: italic;
        }
        .cn {
            margin-bottom: 0.5em;
        }
        h1, h2, h3 {
            border-bottom: 1px solid #eaeaea;
            padding-bottom: 0.3em;
            margin-top: 1.5em;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1em 0;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
<link id="res-style" rel="stylesheet" href="/res/dist/res/style.css" type="text/css">
</head>
<body>
<div id="book-container">
<h1 class="cn">Andrej Karpathy：软件正在（再次）改变</h1>
<h1 class="en">Andrej Karpathy: Software Is Changing (Again)</h1>

<img src="https://img.youtube.com/vi/LCEmiRjPEtQ/hqdefault.jpg" alt="Youtube video thumbnail">

<p class="cn">4周前 (2025年6月19日) — 39:31</p>
<p class="en">4 weeks ago (Jun 19, 2025) — 39:31</p>

<p><a href="https://youtube.com/watch?v=LCEmiRjPEtQ">https://youtube.com/watch?v=LCEmiRjPEtQ</a></p>

<h2 class="cn">摘要</h2>
<h2 class="en">Summary</h2>

<p class="cn">特斯拉前人工智能总监 Andrej Karpathy 讨论了人工智能时代软件不断变化的本质。他认为，软件正在经历一场根本性的转变，从软件 1.0（传统代码）转向软件 2.0（神经网络权重），现在又转向软件 3.0（用英语提示编程的 LLM）。LLM 类似于操作系统，目前通过云中的分时共享进行访问。他强调了带有 GUI 的部分自治应用程序的需求，以及让 LLM 更容易访问软件（包括调整文档）的重要性。演讲者还强调了在使用 LLM 时进行人工监督的重要性，以及“vibe coding”在软件开发民主化方面的潜力。</p>
<p class="en">Andrej Karpathy, former director of AI at Tesla, discussed the evolving nature of software in the age of AI.  He argues that software is undergoing a fundamental shift, moving from Software 1.0 (traditional code) to Software 2.0 (neural network weights) and now Software 3.0 (LLMs programmed with prompts in English).  LLMs are analogous to operating systems, currently accessed via time-sharing in the cloud.  He emphasizes the need for partial autonomy apps with GUIs and the importance of making software more accessible to LLMs, including adapting documentation.  The speaker also highlighted the importance of human oversight in the use of LLMs and the potential for "vibe coding" to democratize software development.</p>

<h2 class="cn">我认为可以公平地说，软件正在再次发生根本性的变化。LLM 是一种新型计算机，而你用<em>英语</em>对它们进行编程。因此，我认为它们完全配得上软件方面的一次主版本升级。</h2>
<h2 class="en">Imo fair to say that software is changing quite fundamentally again. LLMs are a new kind of computer, and you program them <em>in English</em>. Hence I think they are well deserving of a major version upgrade in terms of software.</h2>

<p class="cn">请欢迎特斯拉前人工智能总监 Andrej Karpathy。大家好。哇，这里有好多人。大家好。嗯，好的。是的。所以，我今天很高兴能在这里和大家谈论人工智能时代的软件。我听说你们中的许多人是学生——本科生、硕士生、博士生等等——而且你们即将进入这个行业。我认为现在进入这个行业确实是一个极其独特且非常有趣的时期。我认为其根本原因在于，软件正在再次发生变化。</p>
<p class="en">Please welcome former director of AI at Tesla, Andrej Karpathy. Hello. Wow, a lot of people here. Hello. Um, okay. Yeah. So, I'm excited to be here today to talk to you about software in the era of AI. And I'm told that many of you are students—bachelors, masters, PhDs, and so on—and you're about to enter the industry. And I think it's actually like an extremely unique and very interesting time to enter the industry right now. And I think fundamentally the reason for that is that software is changing again.</p>

<p class="cn">我之所以说“再次”，是因为我其实已经给过这个演讲了。嗯，但问题是软件在不断变化。所以我其实有很多材料可以用来创作新的演讲，而且我认为它正在发生非常根本性的变化。我认为，粗略地讲，软件在如此根本的层面上已经有70年没有太大变化了。然后，在过去的几年里，我认为它迅速地改变了大约两次。因此，有大量的工作要做，有大量的软件需要编写和重写。</p>
<p class="en">And I say again because I actually gave this talk already. Um, but the problem is that software keeps changing. So I actually have a lot of material to create new talks, and I think it's changing quite fundamentally. I think, roughly speaking, software has not changed much on such a fundamental level for 70 years. And then it's changed, I think, about twice quite rapidly in the last few years. And so there's just a huge amount of work to do, a huge amount of software to write and rewrite.</p>

<p class="cn">那么，让我们来看看软件的领域。所以，如果我们把这个看作是软件的地图——这是一个非常酷的工具，叫做GitHub地图。嗯，这有点像所有编写的软件。这些是给计算机的指令，用于在数字空间中执行任务。所以，如果你放大这里，这些都是不同种类的代码仓库，这就是所有已经编写的代码。</p>
<p class="en">So, let's take a look at maybe the realm of software. So, if we kind of think of this as like the map of software—this is a really cool tool called the map of GitHub. Um, this is kind of like all the software that's written. These are instructions to the computer for carrying out tasks in the digital space. So, if you zoom in here, these are all different kinds of repositories, and this is all the code that has been written.</p>

<p class="cn">几年前，我观察到软件正在发生变化，出现了一种新型的软件。当时我称之为软件2.0。这里的想法是，软件1.0是你为计算机编写的代码。而软件2.0现在基本上是神经网络，特别是神经网络的权重。你不是直接编写这些代码；你更像是在调整数据集，然后运行一个优化器来创建这个神经网络的参数。</p>
<p class="en">A few years ago, I kind of observed that software was kind of changing, and there was kind of like a new type of software around. And I called this Software 2.0 at the time. The idea here was that Software 1.0 is the code you write for the computer. Software 2.0 now are basically neural networks, and in particular, the weights of a neural network. And you're not writing this code directly; you are more kind of like tuning the datasets, and then you're running an optimizer to create the parameters of this neural net.</p>

<p class="cn">我认为，在当时，神经网络被看作只是一种不同类型的分类器，就像决策树之类的东西。所以，我认为这种框架要恰当得多。而现在，实际上，我们拥有了在软件2.0领域中与GitHub等价的东西。我认为Hugging Face基本上等同于软件2.0中的GitHub。还有Model Atlas，你可以在那里可视化所有编写的代码。</p>
<p class="en">I think, like, at the time, neural nets were kind of seen as just a different kind of classifier, like a decision tree or something like that. And so, I think it was kind of like—I think this framing was a lot more appropriate. And now, actually, what we have is kind of like an equivalent of GitHub in the realm of Software 2.0. And I think Hugging Face is basically equivalent to GitHub in Software 2.0. And there's also Model Atlas, and you can visualize all the code written there.</p>

<p class="cn">顺便说一下，如果你好奇的话，中间的那个大圆圈，那个点，是Flux图像生成器的参数。所以，每当有人在Flux模型之上调整一个模型时，你基本上就在这个空间里创建了一个Git提交，并且你创建了一个不同类型的图像生成器。所以，基本上，我们有：软件1.0是编程计算机的计算机代码。软件2.0是编程神经网络的权重。嗯，这里有一个AlexNet的例子，一个图像识别神经网络。</p>
<p class="en">In case you're curious, by the way, the giant circle, the point in the middle, these are the parameters of a Flux image generator. And so, anytime someone tunes a model on top of a flux model, you basically create a Git commit in this space, and you create a different kind of image generator. So, basically, what we have is: Software 1.0 is the computer code that programs a computer. Software 2.0 are the weights which program neural networks. Uh, and here's an example of AlexNet, an image recognizer neural network.</p>

<p class="cn">现在，到目前为止，我们直到最近才熟悉的所有神经网络都有点像固定功能的计算机——比如图像到类别，或者类似的东西。我认为已经改变的，而且我认为是一个相当根本性的改变是，神经网络通过大型语言模型变得可编程。所以，我认为这是相当新颖、独特的。它是一种新型的计算机，因此，在我看来，值得给它一个新的称号——软件3.0。基本上，你的提示现在是编程LLM的程序。</p>
<p class="en">Now, so far, all of the neural networks that we've been familiar with until recently were kind of like fixed function computers—image to categories, or something like that. And I think what's changed, and I think is a quite fundamental change, is that neural networks became programmable with large language models. And so, I see this as quite new, unique. It's a new kind of computer, and so, in my mind, it's worth giving it a new designation of Software 3.0. And basically, your prompts are now programs that program the LLM.</p>

<p class="cn">而且值得注意的是，这些提示是用英语写的。所以，这是一种非常有趣的编程语言。嗯，所以也许为了总结一下区别，如果你在做情感分类，例如，你可以想象编写一些Python来进行情感分类，或者你可以训练一个神经网络，或者你可以提示一个大型语言模型。嗯，所以这里，这是一个简短的提示，你可以想象改变它并以稍微不同的方式对计算机进行编程。</p>
<p class="en">And remarkably, these prompts are written in English. So, it's kind of a very interesting programming language. Um, so maybe to summarize the difference, if you're doing sentiment classification, for example, you can imagine writing some amount of Python to basically do sentiment classification, or you can train a neural net, or you can prompt a large language model. Uh, so here, this is a few short prompts, and you can imagine changing it and programming the computer in a slightly different way.</p>

<p class="cn">所以，基本上，我们有软件1.0，软件2.0，而且我认为我们正在看到——也许你已经看到很多GitHub代码不再仅仅是代码了。有很多像英语和代码夹杂在一起的东西，所以我认为有一类新的代码正在增长。所以，它不仅是一种新的编程范式，而且令我惊奇的是，它使用的是我们的母语英语。所以，当几年前这让我大吃一惊时，我发了这条推文，我想它吸引了很多人的注意。这是我目前置顶的推文：值得注意的是，我们现在正在用英语对计算机进行编程。</p>
<p class="en">So, basically, we have Software 1.0, Software 2.0, and I think we're seeing—maybe you've seen a lot of GitHub code is not just like code anymore. There's a bunch of like English interspersed with code, and so I think kind of there's a growing category of new kinds of code. So, not only is it a new programming paradigm, it's also remarkable to me that it's in our native language of English. And so, when this blew my mind a few, I guess, years ago now, I tweeted this, and I think it captured the attention of a lot of people. And this is my currently pinned tweet: that remarkably, we're now programming computers in English.</p>

<p class="cn">现在，当我在特斯拉的时候，我们正在研究自动驾驶，我们试图让汽车能够驾驶。我当时展示了这张幻灯片，你可以想象汽车的输入在底部，它们通过一个软件堆栈来产生转向和加速。我当时观察到，在自动驾驶系统中有很多C++代码，也就是软件1.0的代码，然后里面有一些神经网络在做图像识别。</p>
<p class="en">Now, when I was at Tesla, we were working on the autopilot, and we were trying to get the car to drive. And I sort of showed this slide at the time where you can imagine that the inputs to the car are on the bottom, and they're going through a software stack to produce the steering and acceleration. And I made the observation at the time that there was a ton of C++ code around in the autopilot, which was the Software 1.0 code, and then there was some neural nets in there doing image recognition.</p>

<p class="cn">我观察到，随着时间的推移，当我们让自动驾驶变得更好时，神经网络的能力和规模基本上都在增长，除此之外，所有的C++代码都被删除了，很多最初用1.0编写的功能和能力都被迁移到了2.0。举个例子，很多将来自不同摄像头的图像和跨时间的信息拼接起来的工作都是由一个神经网络完成的，我们因此能够删除大量的代码。所以，软件2.0堆栈可以说完全吞噬了自动驾驶的软件堆栈。</p>
<p class="en">And I kind of observed that over time, as we made the autopilot better, basically the neural network grew in capability and size, and in addition to that, all the C++ code was being deleted, and kind of like was, and a lot of the kind of capabilities and functionality that was originally written in 1.0 was migrated to 2.0. So, as an example, a lot of the stitching up of information across images from the different cameras and across time was done by a neural network, and we were able to delete a lot of code. So, the Software 2.0 stack quite literally ate through the software stack of the autopilot.</p>

<p class="cn">我当时觉得这非常了不起，而且我认为我们正在再次看到同样的事情，基本上我们有了一种新的软件，它正在吞噬整个技术栈。我们有三种完全不同的编程范式，我认为如果你要进入这个行业，精通所有这些范式是一个非常好的主意，因为它们各有优缺点，你可能想用1.0、2.0或3.0来编程某些功能。你是要训练一个神经网络？还是仅仅提示一个LLM？这应该是一段明确的代码，等等？所以，我们都必须做出这些决定，并且实际上可能在这些范式之间流畅地转换。</p>
<p class="en">I thought this was really remarkable at the time, and I think we're seeing the same thing again, where basically we have a new kind of software, and it's eating through the stack. We have three completely different programming paradigms, and I think if you're entering the industry, it's a very good idea to be fluent in all of them, because they all have slight pros and cons, and you may want to program some functionality in 1.0 or 2.0 or 3.0. Are you going to train a neural network? Are you going to just prompt an LLM? Should this be a piece of code that's explicit, etc.? So, we all have to make these decisions and actually potentially fluidly transition between these paradigms.</p>

<h2 class="cn">LLM 具有公用事业、晶圆厂和操作系统的特性 → 新的 LLM 操作系统，由实验室制造，并像公用事业一样分发（目前）。许多历史类比都适用——我认为我们正处于大约 1960 年代的计算时代。</h2>
<h2 class="en">LLMs have properties of utilities, of fabs, and of operating systems → New LLM OS, fabbed by labs, and distributed like utilities (for now). Many historical analogies apply - imo we are computing circa ~1960s.</h2>

<p class="cn">所以，我现在想谈的是，首先，在第一部分，谈谈LLM以及如何看待这个新的范式和生态系统，以及它是什么样子的。嗯，比如，这个新计算机是什么？它看起来像什么，生态系统又是什么样子的？</p>
<p class="en">So, what I wanted to get into now is, first, in the first part, to talk about LLMs and how to kind of think of this new paradigm and the ecosystem and what that looks like. Uh, like, what is this new computer? What does it look like, and what does the ecosystem look like?</p>

<p class="cn">我被Andrej Karpathy多年前的一句话所打动，我想，Andrej将在我之后发言。但他当时说，“人工智能是新的电力”，我确实认为它捕捉到了一些非常有趣的东西，即LLM现在当然感觉像是具有公用事业的属性。</p>
<p class="en">Um, I was struck by this quote from Andrej Karpathy, actually many years ago now, I think, and I think Andrej is going to be speaking right after me. Uh, but he said at the time, "AI is the new electricity," and I do think that it kind of captures something very interesting, in that LLMs certainly feel like they have properties of utilities right now.</p>

<p class="cn">所以，像OpenAI、Gemini、Anthropic等LLM实验室，他们花费资本支出训练LLM，这有点像建设电网。然后是运营支出，通过API向我们所有人提供这种智能。这是通过计量访问完成的，我们按百万个令牌或其他方式付费。我们对这个API有很多非常类似公用事业的需求——我们要求低延迟、高正常运行时间、一致的质量等等。</p>
<p class="en">So, LLM labs like OpenAI, Gemini, Anthropic, etc., they spend capital expenditure to train the LLMs, and this is kind of equivalent to building out a grid. And then there's operational expenditure to serve that intelligence over APIs to all of us. This is done through metered access, where we pay per million tokens or something like that. And we have a lot of demands that are very utility like demands out of this API—we demand low latency, high uptime, consistent quality, etc.</p>

<p class="cn">在电力系统中，你会有一个转换开关。所以，你可以把你的电力来源从电网、太阳能、电池或发电机之间转换。在LLM中，我们可能有一个开放的路由器，可以轻松地在现有的不同类型的LLM之间切换。因为LLM是软件，它们不争夺物理空间。所以，基本上有六个电力供应商是可以的，你可以在它们之间切换，对吧？因为它们不是以如此直接的方式竞争。</p>
<p class="en">In electricity, you would have a transfer switch. So, you can transfer your electricity source from, like, grid and solar or battery or generator. In LLMs, we have maybe an open router and easily switch between the different types of LLMs that exist. Because LLMs are software, they don't compete for physical space. So, it's okay to have basically like six electricity providers, and you can switch between them, right? Because they don't compete in such a direct way.</p>

<p class="cn">而且我认为有点迷人的是，实际上在过去几天我们看到了，很多LLM都宕机了，人们有点像卡住了一样，无法工作。我觉得这有点迷人，当最先进的LLM宕机时，这实际上有点像世界范围内的智能中断、电力不足。这有点像电网电压不稳定的时候，我们对这些模型的依赖越大，地球就变得越笨，这已经非常戏剧化了，而且我认为会继续增长。</p>
<p class="en">And I think what's also a little fascinating, and we saw this in the last few days, actually, a lot of the LLMs went down, and people were kind of like stuck and unable to work. And I think it's kind of fascinating to me that when state of the art LLMs go down, it's actually kind of like an intelligence outage, brownouts in the world. It's kind of like when the voltage is unreliable in the grid, and the planet just gets dumber the more reliance we have on these models, which already is like really dramatic, and I think will continue to grow.</p>

<p class="cn">但是LLM不仅具有公用事业的属性。我认为也可以公平地说，它们具有一些晶圆厂的属性。</p>
<p class="en">But LLMs don't only have properties of utilities. I think it's also fair to say that they have some properties of fabs.</p>

<p class="cn">原因在于，构建LLM所需的资本支出（CAPEX）实际上相当大。嗯，这不仅仅是像建个发电站之类的，对吧？你投入了巨额资金，而且我认为技术树正在迅速发展。</p>
<p class="en">The reason for this is that the capital expenditure (CAPEX) required for building LLMs is actually quite large. Uh, it's not just like building some power station or something like that, right? You're investing a huge amount of money, and I think the technology tree is growing quite rapidly.</p>

<p class="cn">所以我们处在一个拥有深度技术树、研发秘密集中在LLM实验室的世界里。</p>
<p class="en">So we're in a world where we have sort of deep tech trees, research and development secrets that are centralizing inside the LLM labs.</p>

<p class="cn">嗯，但是我认为这个类比也有点模糊，因为正如我提到的，这是软件，而软件的可防御性稍差，因为它非常具有可塑性。所以我认为这是一个值得思考的有趣的事情。</p>
<p class="en">Um, and but I think the analogy muddies a little bit also because, as I mentioned, this is software, and software is a bit less defensible because it is so malleable. And so I think it's just an interesting kind of thing to think about potentially.</p>

<p class="cn">你可以做很多类比，比如4纳米工艺节点可能有点像一个具有特定最大FLOPS的集群。你可以想象，当你使用NVIDIA GPU并且只做软件而不做硬件时。这有点像无晶圆厂模式。但如果你实际上也在构建自己的硬件并且在TPU上进行训练，如果你是谷歌，那有点像英特尔模式，你拥有自己的晶圆厂。</p>
<p class="en">There are many analogies you can make, like a 4 nanometer process node maybe is something like a cluster with certain max FLOPS. You can think about when you're using NVIDIA GPUs and you're only doing the software and you're not doing the hardware. That's kind of like the fabless model. But if you're actually also building your own hardware and you're training on TPUs, if you're Google, that's kind of like the Intel model where you own your fab.</p>

<p class="cn">所以我认为这里有一些有意义的类比。但实际上，我认为最有意义的类比或许是，在我看来，LLM与操作系统有着非常强烈的类比关系。</p>
<p class="en">So I think there are some analogies here that make sense. But actually, I think the analogy that makes the most sense, perhaps, is that in my mind, LLMs have very strong kind of analogies to operating systems.</p>

<p class="cn">嗯，因为这不仅仅是电力或水。它不是像自来水一样作为商品出来的东西。这些现在是日益复杂的软件生态系统，对吧？所以它们不仅仅是像电力这样的简单商品。</p>
<p class="en">Uh, in that this is not just electricity or water. It's not something that comes out of the tap as a commodity. These are now increasingly complex software ecosystems, right? So they're not just like simple commodities like electricity.</p>

<p class="cn">而且我觉得有趣的是，生态系统的形成方式非常相似，你有几个闭源提供商，比如Windows或macOS，然后你有一个开源替代品，比如Linux。</p>
<p class="en">And it's kind of interesting to me that the ecosystem is shaping in a very similar kind of way, where you have a few closed source providers like Windows or macOS, and then you have an open source alternative like Linux.</p>

<p class="cn">而且我认为对于LLM也是如此，我们有几个相互竞争的闭源提供商，然后也许Llama生态系统目前可能是一个接近于可能发展成类似Linux的东西的近似物。同样，我认为现在还为时过早，因为这些只是简单的LLM，但我们开始看到这些将会变得更加复杂。</p>
<p class="en">And I think for LLMs as well, we have a kind of a few competing closed source providers, and then maybe the Llama ecosystem is currently like maybe a close approximation to something that may grow into something like Linux. Again, I think it's still very early because these are just simple LLMs, but we're starting to see that these are going to get a lot more complicated.</p>

<p class="cn">这不仅仅是关于LLM本身。这是关于所有工具的使用和模态以及所有这些如何工作。所以当我前段时间意识到这一点时，我试着把它画出来，在我看来，LLM有点像一个新的操作系统，对吧？所以LLM是一种新型的计算机。它坐落在那里；它有点像CPU的等价物。上下文窗口有点像内存，然后LLM使用所有这些功能来协调内存和计算以解决问题。所以，如果你从这个角度看，它确实非常像一个操作系统。</p>
<p class="en">It's not just about the LLM itself. It's about all the tool use and the modalities and how all of that works. And so when I sort of had this realization a while back, I tried to sketch it out, and it kind of seemed to me like LLMs are kind of like a new operating system, right? So the LLM is a new kind of computer. It's sitting; it's kind of like the CPU equivalent. The context windows are kind of like the memory, and then the LLM is orchestrating memory and compute for problem solving using all of these capabilities here. And so, definitely, if you look at it, it looks very much like an operating system from that perspective.</p>

<p class="cn">嗯，还有一些类比。例如，如果你想下载一个应用程序，比如说我去VS Code然后去下载，你可以下载VS Code，你可以在Windows、Linux或macOS上运行它，就像你可以拿一个像Cursor这样的LLM应用程序，你可以在GPT、Cloud或Gemini系列上运行它一样，对吧？它只是一个下拉菜单。所以，在这方面它有点类似。</p>
<p class="en">Um, a few more analogies. For example, if you want to download an app, say I go to VS Code and I go to download, you can download VS Code and you can run it on Windows, Linux, or macOS in the same way as you can take an LLM app like Cursor and you can run it on GPT, or Cloud, or Gemini series, right? It's just a dropdown. So, it's kind of like similar in that way as well.</p>

<p class="cn">更多让我印象深刻的类比是，我们有点像处在1960年代的时代，对于这种新型计算机来说，LLM计算仍然非常昂贵，这迫使LLM集中在云端。我们都只是通过网络与之交互的客户端，我们没有人能充分利用这些计算机。因此，使用分时共享是有意义的，我们都只是，你知道，当他们在云端运行计算机时，我们只是批处理的一个维度。这与当时计算机的样子非常相似。操作系统在云端。所有东西都是流式传输的，并且有批处理。所以，个人计算革命还没有发生，因为它只是不经济。这没有意义。但我认为有些人正在尝试。</p>
<p class="en">More analogies that I think strike me is that we're kind of like in this 1960s ish era where LLM compute is still very expensive for this new kind of computer, and that forces the LLMs to be centralized in the cloud. And we're all just sort of client things that interact with it over the network, and none of us have full utilization of these computers. And therefore, it makes sense to use time sharing where we're all just, you know, a dimension of the batch when they're running the computer in the cloud. And this is very much what computers used to look like during this time. The operating systems were in the cloud. Everything was streamed around, and there was batching. And so, the personal computing revolution hasn't happened yet because it's just not economical. It doesn't make sense. But I think some people are trying.</p>

<p class="cn">事实证明，Mac Mini，例如，非常适合某些LLM，因为如果你进行批处理一的推理，这一切都非常受内存限制。所以，这实际上是可行的。我认为这些可能是个人计算的一些早期迹象。但这还没有真正发生。它会是什么样子还不清楚。也许你们中的一些人会发明这是什么，或者它是如何工作的，或者这应该——这应该是什么。</p>
<p class="en">And it turns out that Mac Minis, for example, are a very good fit for some of the LLMs because it's all—if you're doing batch one inference, this is all super memory bound. So, this actually works. And I think these are some early indications, maybe, of personal computing. But this hasn't really happened yet. It's not clear what this looks like. Maybe some of you get to invent what this is, or how it works, or what this should—what this should be.</p>

<p class="cn">也许我还要提到的一个类比是，每当我在文本中直接与ChatGPT或某个LLM交谈时，我都感觉像是在通过终端与操作系统交谈。就像它只是——它是文本。它是对操作系统的直接访问。而且我认为GUI还没有以一种通用的方式真正被发明出来，比如ChatGPT是否应该有一个不同于纯文本气泡的GUI？嗯，当然，我们稍后会谈到的一些应用程序有GUI，但没有像跨所有任务的GUI，如果这说得通的话。</p>
<p class="en">Maybe one more analogy that I'll mention is whenever I talk to ChatGPT or some LLM directly in text, I feel like I'm talking to an operating system through the terminal. Like it's just—it's text. It's direct access to the operating system. And I think a GUI hasn't yet really been invented in a general way, like should ChatGPT have a GUI different than just a text bubble? Uh, certainly some of the apps that we're going to go into in a bit have GUIs, but there's no like GUI across all the tasks, if that makes sense.</p>

<p class="cn">嗯，在某些方面，LLM与操作系统在一些相当独特的方面是不同的，也与早期计算不同。我写过关于这个特别的属性，它让我觉得这次非常不同。那就是LLM，像是，颠覆了通常存在于技术中的技术扩散方向。所以，例如，对于电力、密码学、计算、飞行、互联网、GPS——许多以前没有的新的变革性技术——通常，政府和公司是第一批用户，因为它新颖、昂贵等等。它只是后来才扩散到消费者。</p>
<p class="en">Um, there are some ways in which LLMs are different from operating systems in some fairly unique ways and from early computing. I wrote about this one particular property that strikes me as very different this time around. It's that LLMs, like, flip the direction of technology diffusion that is usually present in technology. So, for example, with electricity, cryptography, computing, flight, the internet, GPS—lots of new transformative technologies that have not been around—typically, it is the government and corporations that are the first users because it's new and expensive, etc. And it only later diffuses to consumers.</p>

<p class="cn">嗯，但我觉得LLM有点像是反过来了。所以，也许早期的计算机都是关于弹道学和军事用途，但对于LLM，它都是关于如何煮鸡蛋之类的事情。这当然很像我的很多用法。所以我觉得非常有趣的是，我们有了一台新的神奇的计算机，它在帮我煮鸡蛋。它不是在帮助政府做一些非常疯狂的事情，比如一些军事弹道学或一些特殊技术。事实上，公司和政府在采用所有这些技术方面都落后于我们所有人。所以，这只是倒过来了，我认为它为我们想要如何使用这项技术或者一些最初的应用在哪里提供了一些信息，等等。</p>
<p class="en">Uh, but I feel like LLMs are kind of like flipped around. So, maybe with early computers, it was all about ballistics and military use, but with LLMs, it's all about how do you boil an egg or something like that. This is certainly like a lot of my use. And so it's really fascinating to me that we have a new magical computer, and it's like helping me boil an egg. It's not helping the government do something really crazy like some military ballistics or some special technology. Indeed, corporations and governments are lagging behind the adoption of all of us, of all these technologies. So, it's just backwards, and I think it informs maybe some of the uses of how we want to use this technology or like where are some of the first apps, and so on.</p>

<p class="cn">总而言之，到目前为止，LLM实验室——LLM。我认为使用这种语言是准确的，但LLM是复杂的操作系统。它们大约是1960年代的计算水平，我们正在重新进行计算。它们目前通过分时共享提供，并像公用事业一样分发。新颖和前所未有的是，它们不在少数政府和公司的手中。它们在我们所有人的手中，因为我们都有一台电脑，而且它都只是软件。而且，chaship被传送到我们的电脑上——像数十亿人一样——几乎是瞬间和一夜之间。这太疯狂了。嗯，我觉得这是事实，这有点疯狂，现在是我们进入这个行业并为这些电脑编程的时候了。这太疯狂了。所以，我认为这非常了不起。</p>
<p class="en">In summary, so far, LLM labs—LLMs. I think it's accurate language to use, but LLMs are complicated operating systems. They're circa 1960s in computing, and we're redoing computing all over again. And they're currently available via time sharing and distributed like a utility. What is new and unprecedented is that they're not in the hands of a few governments and corporations. They're in the hands of all of us because we all have a computer, and it's all just software. And, chaship was beamed down to our computers—like billions of people—like instantly and overnight. And this is insane. Uh, and it's kind of insane to me that this is the case, and now it is our time to enter the industry and program these computers. This is crazy. So, I think this is quite remarkable.</p>

<h2 class="cn">LLM心理学：LLM = “人类精神”，人的随机模拟，其中模拟器是自回归Transformer。由于它们是在人类数据上训练的，它们具有一种涌现的心理，并且在某些方面是超人的，但在许多其他方面也容易犯错。鉴于此，我们如何与它们富有成效地携手合作？</h2>
<h2 class="en">LLM psychology: LLMs = "people spirits", stochastic simulations of people, where the simulator is an autoregressive Transformer. Since they are trained on human data, they have a kind of emergent psychology, and are simultaneously superhuman in some ways, but also fallible in many others. Given this, how do we productively work with them hand in hand?</h2>

<p class="cn">在我们对LLM进行编程之前，我们必须花一些时间思考这些东西是什么。我特别喜欢谈论它们的心理。所以，我喜欢把LLM看作是人的精神。嗯，它们是人的随机模拟。嗯，在这种情况下，模拟器恰好是一个自回归的变换器。所以，变换器是一个神经网络。嗯，它，它只是有点像——在令牌的层面上进行。</p>
<p class="en">Before we program LLMs, we have to kind of like spend some time to think about what these things are. And I especially like to kind of talk about their psychology. So, the way I like to think about LLMs is that they're kind of like people's spirits. Um, they are stochastic simulations of people. Um, and the simulator in this case happens to be an autoregressive transformer. So, the transformer is a neural net. Uh, it's, and it just kind of like is—goes on the level of tokens.</p>

<p class="cn">它一块一块地进行。对于每一块，计算量几乎是相等的。嗯，当然，这个模拟器——基本上涉及到一些权重，我们用我们在互联网上拥有的所有文本等等来拟合它。然后你得到了这种模拟器，因为它是在人类身上训练的，它有这种类似人类的涌现心理。所以，你首先会注意到的是，当然，LLM拥有百科全书般的知识和记忆。</p>
<p class="en">It goes chunk, chunk, chunk, chunk, chunk. And there's an almost equal amount of compute for every single chunk. Um, and this simulator, of course, is—is just—is basically there's some weights involved, and we fit it to all of the text that we have on the internet, and so on. And you end up with this kind of simulator, and because it is trained on humans, it's got this emergent psychology that is human like. So, the first thing you'll notice is, of course, LLMs have encyclopedic knowledge and memory.</p>

<p class="cn">他们能记住很多东西，比任何单个人类能记住的都多，因为他们读了太多东西。这实际上让我想起了这部电影，《雨人》，我真的推荐大家看。这是一部很棒的电影。我爱这部电影。嗯，达斯汀·霍夫曼在这里是一个自闭症天才，他有近乎完美的记忆力。所以，他可以读一本电话簿并记住所有的名字和电话号码。我觉得LLM非常相似。</p>
<p class="en">And they can remember lots of things, a lot more than any single individual human can because they read so many things. It's actually kind of reminds me of this movie, *Rain Man*, which I actually really recommend people watch. It's an amazing movie. I love this movie. Um, and Dustin Hoffman, here, is an autistic savant who has almost perfect memory. So, he can read a phone book and remember all of the names and phone numbers. And I kind of feel like LLMs are kind of like very similar.</p>

<p class="cn">他们可以非常非常容易地记住SHA 256哈希值和许多不同类型的东西。所以，他们在某些方面当然有超能力。但他们也有一堆，我想说，认知缺陷。所以，他们经常产生幻觉。嗯，他们会编造东西，并且没有一个很好的内部自我知识模型；至少不够。这方面有所改善，但并不完美。他们表现出参差不齐的智能。所以，他们在某些解决问题的领域会是超人，然后他们会犯一些基本上没有人类会犯的错误。</p>
<p class="en">They can remember SHA 256 hashes and lots of different kinds of things very, very easily. So, they certainly have superpowers in some respects. But they also have a bunch of, I would say, cognitive deficits. So, they hallucinate quite a bit. Um, and they kind of make up stuff and don't have a very good sort of internal model of self knowledge; not sufficient at least. And this has gotten better, but not perfect. They display jagged intelligence. So, they're going to be superhuman in some problem solving domains, and then they're going to make mistakes that basically no human will make.</p>

<p class="cn">比如，你知道，他们会坚持认为9/11大于9.9，或者“strawberry”中有两个“r”——这些是一些著名的例子，但基本上，有一些粗糙的边缘你可能会被绊倒。所以，这有点，我认为，也有点独特。他们也患有顺行性遗忘症。所以，我想我是在暗示，如果你有一个新同事加入你的组织，这个同事会随着时间的推移了解你的组织，他们会理解并获得大量关于组织的背景信息，他们回家睡觉，巩固知识，并随着时间的推移发展专业知识。LLM天生不会这样做，这在LLM的研发中还没有真正解决。我认为。所以，上下文窗口真的有点像工作记忆，你必须非常直接地对工作记忆进行编程，因为它们不会默认变得更聪明。我认为很多人在这方面的类比上被绊倒了。</p>
<p class="en">Like, you know, they will insist that 9/11 is greater than 9.9, or that there are two "r"s in "strawberry"—these are some famous examples, but basically, there are rough edges that you can trip on. So, that's kind of, I think, also kind of unique. They also kind of suffer from anterograde amnesia. So, I think I'm alluding to the fact that if you have a coworker who joins your organization, this coworker will, over time, learn your organization and they will understand and gain like a huge amount of context on the organization, and they go home and they sleep and they consolidate knowledge and they develop expertise over time. LLMs don't natively do this, and this is not something that has really been solved in the R&amp;D of LLMs. I think. And so, context windows are really kind of like working memory, and you have to sort of program the working memory quite directly because they don't just kind of like get smarter by default. And I think a lot of people get tripped up by the analogies in this way.</p>

<p class="cn">在流行文化中，我推荐大家看这两部电影：《记忆碎片》和《初恋50次》。在这两部电影中，主角的记忆都是固定的，他们的上下文窗口每天早上都会被清除。当这种情况发生时，去上班或维持人际关系都非常有问题，而这种情况一直都在发生。</p>
<p class="en">In popular culture, I recommend people watch these two movies: *Memento* and *50 First Dates*. In both of these movies, the protagonists' memories are fixed, and their context windows get wiped every single morning. And it's really problematic to go to work or have relationships when this happens, and this happens all the time.</p>

<p class="cn">我想我还要指出的一点是与使用LLM相关的安全限制。例如，LLM相当容易上当。它们容易受到提示注入风险的影响，可能会泄露你的数据等等，因此还有许多其他与安全相关的考虑因素。所以，基本上，长话短说，你必须加载你的……你必须加载你的……你必须同时思考这个拥有超人能力但又有一堆认知缺陷和问题的东西。我们如何，然而它们又极其有用，那么我们如何对它们进行编程，如何绕过它们的缺陷并享受它们的超人能力呢？</p>
<p class="en">I guess one more thing I would point to is security related limitations of the use of LLMs. So, for example, LLMs are quite gullible. They are susceptible to prompt injection risks, they might leak your data, etc., and so there are many other security related considerations. So, basically, long story short, you have to load your... you have to load your... you have to simultaneously think through this superhuman thing that has a bunch of cognitive deficits and issues. How do we, and yet they are extremely useful, and so how do we program them and how do we work around their deficits and enjoy their superhuman powers?</p>

<h2 class="cn">LLM是“人类精神”→可以构建部分自主的产品。</h2>
<h2 class="en">LLMs are "people spirits" → can build partially autonomous products.</h2>

<p class="cn">所以，我现在想转换一下话题，谈谈我们如何使用这些模型以及一些最大的机会。这不是一个详尽的列表，只是我认为对于这次演讲来说一些有趣的事情。</p>
<p class="en">So, what I want to switch to now is to talk about the opportunities of how do we use these models and what are some of the biggest opportunities. This is not a comprehensive list, just some of the things that I thought were interesting for this talk.</p>

<p class="cn">我感到兴奋的第一件事是我称之为部分自治应用程序。举个例子，让我们以编码为例。你当然可以直接去代码那里，然后开始复制粘贴代码，复制错误报告之类的东西，获取代码，然后到处复制粘贴。你为什么要那么做？你为什么要直接去操作系统？有一个专门为此设计的应用程序要合理得多。</p>
<p class="en">The first thing I'm kind of excited about is what I would call partial autonomy apps. So, for example, let's work with the example of coding. You can certainly go to the code directly and you can start copying and pasting code around and copying bug reports and stuff around and getting code and copying and pasting everything around. Why would you do that? Why would you go directly to the operating system? It makes a lot more sense to have an app dedicated for this.</p>

<p class="cn">所以，我想你们很多人都用Cursor。我也用。Cursor有点像你想要的东西。你不想只是直接去处理代码。我认为Cursor是一个很好的早期LLM应用的例子，它具有我认为在所有LLM应用中都有用的许多特性。</p>
<p class="en">And so, I think many of you use Cursor. I do as well. And Cursor is kind of like the thing you want instead. You don't want to just directly go to the code. And I think Cursor is a very good example of an early LLM app that has a bunch of properties that I think are useful across all the LLM apps.</p>

<p class="cn">所以，特别地，你会注意到我们有一个传统的界面，允许人类像以前一样手动完成所有工作。但除此之外，我们现在有了这个LLM集成，让我们能够以更大的块进行操作。</p>
<p class="en">So, in particular, you will notice that we have a traditional interface that allows a human to go in and do all the work manually, just as before. But in addition to that, we now have this LLM integration that allows us to go in bigger chunks.</p>

<p class="cn">所以，我认为LLM应用的一些共享且有用的特性需要指出：</p>
<p class="en">And so, some of the properties of LLM apps that I think are shared and useful to point out:</p>

<p class="cn">- LLM基本上做了大量的上下文管理。</p>
<p class="en">-  The LLMs basically do a ton of the context management.</p>

<p class="cn">- 他们协调对LLM的多次调用，对吧？所以，在Cursor的情况下，底层有用于所有文件的嵌入模型，实际的聊天模型，将差异应用于代码的模型，而这一切都是为你协调好的。</p>
<p class="en">-  They orchestrate multiple calls to LLMs, right? So, in the case of Cursor, there's under the hood embedding models for all your files, the actual chat models, models that apply diffs to the code, and this is all orchestrated for you.</p>

<p class="cn">- 一个我认为可能没有得到充分重视的非常重要的一点是特定于应用程序的GUI及其重要性。因为你不想直接用文本与操作系统对话。文本很难阅读、解释、理解，而且，你也不想用文本来本地执行这些操作。所以，最好是像红色和绿色的变化一样看到一个差异，你可以看到添加和删除了什么。</p>
<p class="en">-  A really big one that I think also maybe not fully appreciated always is application specific GUIs and the importance of it. Because you don't just want to talk to the operating system directly in text. Text is very hard to read, interpret, understand, and also, like, you don't want to take some of these actions natively in text. So, it's much better to just see a diff as like red and green changes, and you can see what's being added and subtracted.</p>

<p class="cn">接受只需按Command Y，拒绝只需按Command N，这样容易得多。我不应该用文本输入它。对吧？所以GUI允许人类审计这些易错系统的工作并加快速度。我稍后会再回到这一点。我想指出的最后一个特性是，有一个我称之为“自主性滑块”的东西。例如，在Cursor中，你只需进行点击补全。</p>
<p class="en">It's much easier to just do Command Y to accept or Command N to reject. I shouldn't have to type it in text. Right? So a GUI allows a human to audit the work of these fallible systems and to go faster. I'm going to come back to this point a little bit later as well. And the last kind of feature I want to point out is that there's what I call the autonomy slider. So, for example, in Cursor, you can just do tap completion.</p>

<p class="cn">你基本上是主导者。你可以选择一段代码，然后按command k只更改那段代码。你可以按command l更改整个文件。或者你可以按command i，它会，你知道，让它自由发挥，在整个代码库中做任何你想做的事，这就是完全自主的、代理式的版本。所以，你掌控着自主性滑块，根据手头任务的复杂性，你可以调整你愿意为该任务放弃的自主性程度。</p>
<p class="en">You're mostly in charge. You can select a chunk of code and command k to change just that chunk of code. You can do command l to change the entire file. Or you can do command i, which just, you know, let it rip, do whatever you want in the entire repo, and that's the sort of full autonomy, agent agentic version. And so, you are in charge of the autonomy slider, and depending on the complexity of the task at hand, you can tune the amount of autonomy that you're willing to give up for that task.</p>

<p class="cn">也许再举一个相当成功的LLM应用的例子，Perplexity，它也具有我刚才在Cursor中指出的非常相似的特性。它打包了大量信息。它协调多个LLM。它有一个GUI，可以让你审计它的一些工作。例如，它会引用来源，你可以想象去检查它们。它还有一个自主性滑块。你可以只做一个快速搜索，或者你可以做研究，或者你可以做深入研究，10分钟后再回来。所以，这都是你赋予工具的不同程度的自主性。</p>
<p class="en">Maybe to show one more example of a fairly successful LLM app, Perplexity, it also has very similar features to what I've just pointed out in Cursor. It packages up a lot of the information. It orchestrates multiple LLMs. It's got a GUI that allows you to audit some of its work. So, for example, it will cite sources, and you can imagine inspecting them. And it's got an autonomy slider. You can either just do a quick search, or you can do research, or you can do deep research and come back 10 minutes later. So, this is all just varying levels of autonomy that you give up to the tool.</p>

<p class="cn">所以，我想我的问题是，我觉得很多软件都会变得部分自主。我正在思考那会是什么样子？对于你们中许多维护产品和服务的人来说，你们将如何使你们的产品和服务部分自主？LLM能看到人类能看到的一切吗？LLM能以人类能做的所有方式行动吗？人类能监督并参与到这个活动中吗？因为，再说一次，这些是易错的系统，还不完美。在Photoshop或类似软件中，差异看起来像什么？你知道，而且现在很多传统软件，它有所有这些开关和各种各样的东西，都是为人类设计的。所有这些都必须改变，变得对LLM可访问。</p>
<p class="en">So, I guess my question is, I feel like a lot of software will become partially autonomous. I'm trying to think through like what does that look like? And for many of you who maintain products and services, how are you going to make your products and services partially autonomous? Can an LLM see everything that a human can see? Can an LLM act in all the ways that a human could act? And can humans supervise and stay in the loop of this activity? Because again, these are fallible systems that aren't yet perfect. And what does a diff look like in Photoshop or something like that? You know, and also a lot of the traditional software right now, it has all these switches and all this kind of stuff that's all designed for human. All of this has to change and become accessible to LLMs.</p>

<p class="cn">所以，我想强调的一点是，对于很多我不太确定是否得到应有关注的LLM应用来说：我们现在有点像在与AI合作，通常它们在做生成，而我们作为人类在做验证。让这个循环尽可能快地进行符合我们的利益。所以，我们完成了很多工作。我认为有两种主要的方法可以做到这一点。第一，你可以大大加快验证速度。嗯，我认为GUI，例如，对此极其重要，因为GUI利用了我们所有人头脑中的计算机视觉GPU。阅读文本费力且不好玩，但看东西很有趣，它就像通往你大脑的高速公路。所以我认为GUI对于审计系统和一般的视觉表示非常有用。</p>
<p class="en">So, one thing I want to stress with a lot of these LLM apps that I'm not sure gets as much attention as it should is: we're now kind of like cooperating with AIs, and usually they are doing the generation, and we as humans are doing the verification. It is in our interest to make this loop go as fast as possible. So, we're getting a lot of work done. There are two major ways that I think this can be done. Number one, you can speed up verification a lot. Um, and I think GUIs, for example, are extremely important to this because a GUI utilizes your computer vision GPU in all of our heads. Reading text is effortful and it's not fun, but looking at stuff is fun, and it's just a kind of like a highway to your brain. So, I think GUIs are very useful for auditing systems and visual representations in general.</p>

<p class="cn">第二，我想说的是我们必须把AI拴在链子上。我们——我认为很多人对AI代理过于兴奋了，给我一个10000行代码的差异对我的仓库来说没有用。就像，我必须——我仍然是瓶颈，对吧？尽管那10000行代码瞬间就出来了，我必须确保这东西没有引入错误；它就像……而且它在做正确的事情，对吧？而且没有安全问题，等等。所以我认为，是的，基本上，我们必须有点像——让这两者的流动非常非常快符合我们的利益，我们必须以某种方式把AI拴在链子上，因为它变得太过度反应了。</p>
<p class="en">And number two, I would say is we have to keep the AI on the leash. We—I think a lot of people are getting way over excited with AI agents, and it's not useful to me to get a diff of 10,000 lines of code to my repo. Like, I have to—I'm still the bottleneck, right? Even though that 10,000 lines come out instantly, I have to make sure that this thing is not introducing bugs; it's just like... and that it's doing the correct thing, right? And that there's no security issues, and so on. So, I think that, yeah, basically, we have to sort of like—it's in our interest to make the flow of these two go very, very fast, and we have to somehow keep the AI on the leash because it gets way too overreactive.</p>

<p class="cn">有点像这样。这就是我做AI辅助编码时的感觉。如果我只是在凭感觉编码，一切都很好很棒，但如果我真的想完成工作，有一个过度反应的代理做所有这些事情就不那么好了。所以，这张幻灯片不是很好。对不起，但我想我正在像你们中的许多人一样，开发一些在我的编码工作流程中利用这些代理的方法，并进行AI辅助编码。在我自己的工作中，我总是害怕得到太大的差异。我总是以小的、增量的块进行。我想确保一切都好。我想让这个循环非常非常快地旋转，我处理的是单一、具体事物的​​小块。</p>
<p class="en">It's kind of like this. This is how I feel when I do AI assisted coding. If I'm just vibe coding, everything is nice and great, but if I'm actually trying to get work done, it's not so great to have an overreactive agent doing all this kind of stuff. So, this slide is not very good. I'm sorry, but I guess I'm trying to develop, like many of you, some ways of utilizing these agents in my coding workflow and to do AI assisted coding. And in my own work, I'm always scared to get way too big diffs. I always go in small, incremental chunks. I want to make sure that everything is good. I want to spin this loop very, very fast, and I sort of work on small chunks of single, concrete things.</p>

<p class="cn">嗯，所以我认为你们中的许多人可能正在开发类似的使用LLM的方法。嗯，我也看到了一些博客文章，试图为使用LLM制定这些最佳实践。这是我最近读到的一篇，我觉得写得很好。它讨论了一些技巧，其中一些与如何控制AI有关。</p>
<p class="en">Uh, and so I think many of you probably are developing similar ways of working with LLMs. Um, I also saw a number of blog posts that try to develop these best practices for working with LLMs. And here's one that I read recently, and I thought was quite good. And it kind of discussed some techniques, and some of them have to do with how you keep the AI on the leash.</p>

<p class="cn">举个例子，如果你的提示很模糊，那么AI可能不会完全按照你的意愿去做，那样的话，验证就会失败。你会要求别的东西。如果验证失败，那么你就会开始兜圈子。所以，花更多的时间让你的提示更具体，这样可以增加成功验证的概率，你就可以继续前进，这更有意义。所以我认为我们中的许多人最终会找到这样的技巧。我认为，在我自己的工作中，我目前对与AI和LLM结合的教育是什么样的感兴趣。现在的教育是什么样的？我认为我的大量思考都集中在如何控制AI上。我不认为直接去聊天然后说“嘿，教我物理”就行了。我不认为这行得通，因为AI会在森林里迷路。</p>
<p class="en">And so, as an example, if you are prompting—if your prompt is vague, then the AI might not do exactly what you wanted, and in that case, verification will fail. You're going to ask for something else. If a verification fails, then you're going to start spinning. So, it makes a lot more sense to spend a bit more time to be more concrete in your prompts, which increases the probability of successful verification, and you can move forward. And so I think a lot of us are going to end up finding kind of techniques like this. I think, in my own work as well, I'm currently interested in what education looks like in conjunction with AI and LLMs. What does education look like now? And I think a large amount of thought for me goes into how we keep AI on the leash. I don't think it just works to go to chat and be like, "Hey, teach me physics." I don't think this works because the AI gets lost in the woods.</p>

<p class="cn">所以，对我来说，这实际上是两个独立的应用程序。例如，有一个供教师创建课程的应用程序，然后有一个接受课程并将其提供给学生的应用程序。在这两种情况下，我们现在都有一个可审计的课程的中间产物，我们可以确保它是好的。我们可以确保它是一致的。AI被限制在某个教学大纲、某个项目进展等方面。所以，这是控制AI的一种方式，我认为这有更高的成功可能性，AI不会在森林里迷路。</p>
<p class="en">And so, for me, this is actually two separate apps. For example, there's an app for a teacher that creates courses, and then there's an app that takes courses and serves them to students. And in both cases, we now have this intermediate artifact of a course that is auditable, and we can make sure it's good. We can make sure it's consistent. And the AI is kept on the leash with respect to a certain syllabus, a certain progression of projects, and so on. And so, this is one way of keeping the AI on leash, and I think has a much higher likelihood of working, and the AI is not getting lost in the woods.</p>

<p class="cn">我还想提到的一个类比是，我对部分自主并不陌生，我想我在特斯拉为此工作了五年。这也是一个部分自主的产品，并共享许多特性。例如，仪表盘上就是自动驾驶的图形用户界面，它向我展示了神经网络看到的东西，等等。我们有自主滑块，在我任职期间，我们为用户做了越来越多的自主任务。</p>
<p class="en">One more kind of analogy I wanted to sort of allude to is, I'm not—I'm no stranger to partial autonomy, and I kind of worked on this, I think, for five years at Tesla. This is also a partial autonomy product and shares a lot of the features. For example, right there in the instrument panel is the GUI of the autopilot, so it's showing me what the neural network sees, and so on. And we have the autonomy slider, where over the course of my tenure there, we did more and more autonomous tasks for the user.</p>

<p class="cn">我想简单讲的故事是，我第一次驾驶自动驾驶汽车是在2013年。我有一个在Waymo工作的朋友，他提出带我在帕洛阿尔托转一圈。我当时用谷歌眼镜拍了这张照片。你们中很多人太年轻了，可能都不知道那是什么。但是，是的，这在当时风靡一时。我们上了这辆车，在帕洛阿尔托的高速公路、街道上行驶了大约30分钟。</p>
<p class="en">Maybe the story that I wanted to tell very briefly is actually the first time I drove a self driving vehicle was in 2013. I had a friend who worked at Waymo, and he offered to give me a drive around Palo Alto. I took this picture using Google Glass at the time. Many of you are so young that you might not even know what that is. But yeah, this was like all the rage at the time. And we got into this car, and we went for about a 30 minute drive around Palo Alto highways, streets, and so on.</p>

<p class="cn">这次驾驶是完美的。零干预。那是2013年，距今已有12年。这让我很震惊，因为当时我有了这次完美的驾驶体验，这个完美的演示，我觉得，哇，自动驾驶指日可待，因为这简直太棒了。这太不可思议了。嗯，但12年后的今天，我们仍在研究自动驾驶。我们仍在研究驾驶代理，甚至现在我们还没有真正解决这个问题。</p>
<p class="en">This drive was perfect. There were zero interventions. This was 2013, which is now 12 years ago. And it kind of struck me because at the time when I had this perfect drive, this perfect demo, I felt like, wow, self driving is imminent because this just worked. This is incredible. Um, but here we are 12 years later, and we are still working on autonomy. We are still working on driving agents, and even now we haven't actually like really solved the problem.</p>

<p class="cn">就像你可能会看到Waymo的汽车在四处行驶，它们看起来是无人驾驶的，但你知道，很多这种驾驶仍然有很多远程操作和很多人在环路中。所以，我们甚至还没有宣布成功，但我认为它肯定会在这一点上成功。但这只是花了很长时间。所以，我认为，就像，这个软件真的很难，我认为和驾驶一样难。所以，当我看到像“2025年是代理人年”这样的东西时，我非常担心。我有点觉得，你知道，这是代理人的十年，这将是相当长的一段时间。我们需要人在环路中。我们需要小心地做这件事。这是软件。让我们认真对待。</p>
<p class="en">Like you may see Waymo cars going around, and they look driverless, but you know there's still a lot of teleoperation and a lot of human in the loop for a lot of this driving. So, we still haven't even declared success, but I think it's definitely going to succeed at this point. But it just took a long time. And so, I think that like, this software is really tricky, I think in the same way that driving is tricky. And so, when I see things like, "2025 is the year of agents," I get very concerned. And I kind of feel like, you know, this is the decade of agents, and this is going to be quite some time. We need humans in the loop. We need to do this carefully. This is software. Let's be serious here.</p>

<p class="cn">我总是想到的另一个类比是钢铁侠战衣。嗯，我认为这是——我一直很喜欢钢铁侠。我认为它在很多方面都非常正确，关于技术以及它将如何发展。我喜欢钢铁侠战衣的地方在于，它既是一种增强，托尼·斯塔克可以驾驶它，它也是一个代理。在一些电影中，钢铁侠战衣非常自主，可以飞来飞去找到托尼等等。所以，这个自主滑块是：我们可以构建增强功能，或者我们可以构建代理，我们有点想两者都做。但在现阶段，我想说，与易错的LLM等合作，我想说，你知道，你想要构建的更多是钢铁侠战衣，而不是钢铁侠机器人。更多的是构建部分自主产品，而不是构建自主代理的华而不实的演示。</p>
<p class="en">One more kind of analogy that I always think through is the Iron Man suit. Uh, I think this is—I always love Iron Man. I think it's like so correct in a bunch of ways with respect to technology and how it will play out. And what I love about the Iron Man suit is that it's both an augmentation, and Tony Stark can drive it, and it's also an agent. And in some of the movies, the Iron Man suit is quite autonomous and can fly around and find Tony and all this kind of stuff. And so, this autonomy slider is: we can build augmentations, or we can build agents, and we kind of want to do a bit of both. But at this stage, I would say, working with fallible LLMs and so on, I would say, you know, it's less Iron Man robots and more Iron Man suits that you want to build. It's less like building flashy demos of autonomous agents and more building partial autonomy products.</p>

<p class="cn">这些产品有定制的GUI和UI。我们正在努力——这样做是为了让人的生成/验证循环非常非常快。但我们没有忽视这样一个事实，即原则上，这项工作是可以自动化的。你的产品中应该有一个自主滑块。你应该考虑如何滑动那个自主滑块，让你的产品随着时间的推移变得更加自主。但这有点像我认为在这些类型的产品中有很多机会。</p>
<p class="en">And these products have custom GUIs and UIs. And we're trying to—and this is done so that the generation/verification loop of the human is very, very fast. But we are not losing sight of the fact that it is, in principle, possible to automate this work. And there should be an autonomy slider in your product. And you should be thinking about how you can slide that autonomy slider and make your product sort of more autonomous over time. But this is kind of how I think there's lots of opportunities in these kinds of products.</p>

<h2 class="cn">LLM用英语编程→让软件高度可访问！（是的，vibe coding）</h2>
<h2 class="en">LLMs are programmed in English → make software highly accessible! (yes, vibe coding)</h2>

<p class="cn">我现在想稍微转换一下思路，谈谈我认为非常独特的另一个维度。不仅有一种新型的编程语言允许软件实现自主，而且，正如我提到的，它是用英语编程的，这是一种自然的界面。突然之间，每个人都成了程序员，因为每个人都说像英语这样的自然语言。所以，这对我来说非常乐观和有趣，而且也完全是前所未有的。我想说，过去的情况是，你需要花五到十年的时间学习一些东西才能在软件领域有所作为。现在情况不再是这样了。所以，我不知道有没有人听说过vibe coding。嗯，这是介绍这个概念的推文，但我听说这现在已经成了一个主要的梗。</p>
<p class="en">I want to now switch gears a little bit and talk about one other dimension that I think is very unique. Not only is there a new type of programming language that allows for autonomy in software, but also, as I mentioned, it's programmed in English, which is this natural interface. And suddenly, everyone is a programmer because everyone speaks natural language like English. So, this is extremely bullish and very interesting to me, and also completely unprecedented. I would say it used to be the case that you needed to spend five to ten years studying something to be able to do something in software. This is not the case anymore. So, I don't know if by any chance anyone has heard of vibe coding. Uh, this is the tweet that kind of like introduced this, but I'm told that this now like a major meme.</p>

<p class="cn">嗯，关于这个有个有趣的故事，我用推特大概有15年了，我仍然不知道哪条推文会火，哪条推文会无人问津。我以为这条推文会是后者。我不知道。它只是像洗澡时的胡思乱想。但它成了一个彻头彻尾的梗，我真的看不出来。但我想它触动了人们的心弦，它为一个每个人都感觉到但无法用言语表达的东西起了个名字。所以现在有了一个维基百科页面和所有东西。这就像，是的，这现在像是一个重大贡献之类的。</p>
<p class="en">Um, a fun story about this is that I've been on Twitter for like 15 years or something like that at this point, and I still have no clue which tweet will become viral and which tweet like fizzles and no one cares. And I thought that this tweet was going to be the latter. I don't know. It was just like a shower of thoughts. But this became like a total meme, and I really just can't tell. But I guess like it struck a chord, and it gave a name to something that everyone was feeling but couldn't quite say in words. So now there's a Wikipedia page and everything. This is like, yeah, this is like a major contribution now or something like that.</p>

<p class="cn">所以，来自Hugging Face的Tom Wolf分享了这个我非常喜欢的优美视频。嗯，这些是孩子们在vibe coding。我发现这是一个如此有益健康的视频。就像，我爱这个视频。就像，你怎么能看着这个视频对未来感到糟糕呢？未来是美好的。我认为这最终会成为软件开发的入门毒品。嗯，我对这一代人的未来并不悲观，我认为，是的，我爱这个视频。</p>
<p class="en">So, Tom Wolf from Hugging Face shared this beautiful video that I really love. Um, these are kids vibe coding. And I find that this is such a wholesome video. Like, I love this video. Like, how can you look at this video and feel bad about the future? The future is great. I think this will end up being like a gateway drug to software development. Um, I'm not a doomer about the future of the generation, and I think, yeah, I love this video.</p>

<p class="cn">所以，我也试了一下vibe coding，因为它太有趣了。嗯，所以当你想构建一些超级超级定制的东西，而它似乎又不存在时，vibe coding就太棒了，你只是想即兴发挥，因为今天是星期六之类的。所以，我构建了这个iOS应用，我实际上不会用Swift编程，但我真的很震惊，我能构建一个超级基础的应用。我不打算解释它。它真的很傻，但这有点像一天的工作，那天晚些时候它就在我的手机上运行了，我当时想，“哇，这太神奇了。”我不需要像花五天时间读Swift之类的才能开始。</p>
<p class="en">So, I tried vibe coding a little bit as well because it's so fun. Uh, so vibe coding is so great when you want to build something super duper custom that doesn't appear to exist, and you just want to wing it because it's a Saturday or something like that. So, I built this iOS app, and I don't—I can't actually program in Swift, but I was really shocked that I was able to build like a super basic app. And I'm not going to explain it. It's really dumb, but I kind of like this was just like a day of work, and this was running on my phone like later that day, and I was like, "Wow, this is amazing." I didn't have to like read through Swift for like five days or something like that to get started.</p>

<p class="cn">我还用vibe coding做了这个叫MenuGen的应用。它现在是上线的。你可以在menu.app上试试。我基本上有这个问题，就是我去一家餐厅，我看完菜单，我完全不知道那些东西是什么。我需要图片。所以，这个东西不存在。所以，我就想，“嘿，我要用vibe coding来做它。”所以，它看起来是这样的。你去menuapp，拍一张菜单的照片。</p>
<p class="en">I also vibe coded this app called MenuGen. And this is live. You can try it at menu.app. And I basically had this problem where I show up at a restaurant, I read through the menu, and I have no idea what any of the things are. And I need pictures. So, this doesn't exist. So, I was like, "Hey, I'm going to vibe code it." So, this is what it looks like. You go to menuapp and take a picture of a menu.</p>

<p class="cn">然后menugen会生成图片。每个人注册时都可以免费获得5美元的积分。因此，这成了我生活中的一个主要成本中心。所以，这对我来说现在是一个负收入的应用。我在MenuGen上亏了一大笔钱。好吧。但对我来说，关于MenuGen最有趣的事情是，代码部分，Vibe Coding部分，代码实际上是Vibe Coding MenuGen中最简单的部分，而大部分工作实际上是在我试图让它变得真实的时候，这样你就可以有身份验证、支付、域名和整体部署。这真的很难，所有这些都不是代码。所有这些DevOps的东西都是我在浏览器里点击东西，这非常慢，又花了一周时间。所以，非常有趣的是，我几个小时就在我的笔记本电脑上把MenuGen的演示版做好了，然后又花了一周时间，因为我试图让它变得真实。原因就是这真的很烦人。</p>
<p class="en">Then menugen generates the images. Everyone gets $5 in credits for free when they sign up. Therefore, this is a major cost center in my life. So, this is a negative negative revenue app for me right now. I've lost a huge amount of money on MenuGen. Okay. But the fascinating thing about MenuGen for me is that the code of the, the Vibe Coding part, the code was actually the easy part of Vibe Coding MenuGen, and most of it actually was when I tried to make it real so that you can actually have authentication and payments and the domain name and overall deployment. This was really hard, and all of this was not code. All of this DevOps stuff was me in the browser clicking stuff, and this was extremely slow and took another week. So, it was really fascinating that I had the MenuGen basically demo working on my laptop in a few hours, and then it took me a week because I was trying to make it real. And the reason for this is this was just really annoying.</p>

<p class="cn">嗯，所以举个例子，如果你想在你的网页上添加谷歌登录，我知道这很小，但这只是这个客户端库告诉我如何集成这个的大量说明。这太疯狂了。就像，它告诉我转到这个URL，点击这个下拉菜单，选择这个，转到这个，然后点击那个。它就像在告诉我我应该采取的行动。就像，你来做。我为什么要这么做？搞什么鬼？我必须遵循所有这些说明。这太疯狂了。</p>
<p class="en">Um, so for example, if you try to add Google login to your web page, I know this is very small, but just a huge amount of instructions of this client library telling me how to integrate this. And this is crazy. Like, it's telling me to go to this URL, click on this dropdown, choose this, go to this, and click on that. And it's like telling me what to do. Like a computer is telling me the actions I should be taking. Like, you do it. Why am I doing this? What the hell? I had to follow all these instructions. This was crazy.</p>

<p class="cn">所以，我想我演讲的最后一部分，因此，重点是：我们能只为代理构建吗？</p>
<p class="en">So, I think the last part of my talk, therefore, focuses on: Can we just build for agents?</p>

<h2 class="cn">LLM是数字信息新的主要消费者/操纵者（增加了GUI/人类和API/程序）→为代理构建！</h2>
<h2 class="en">LLMs are new primary consumer/manipulator of digital information (adding to GUIs/humans and APIs/programs) → Build for agents!</h2>

<p class="cn">我不想做这项工作。代理能做吗？谢谢。</p>
<p class="en">I don't want to do this work. Can agents do this? Thank you.</p>

<p class="cn">好的。所以，粗略地说，我认为出现了一类新的数字信息消费者和操纵者。过去只有通过GUI的人类或通过API的计算机。现在我们有了一个全新的东西。代理——它们是计算机，但它们有点像人，对吧？它们是互联网上的人类精神，它们需要与我们的软件基础设施互动。比如，我们能为它们构建吗？这是一个新事物。</p>
<p class="en">Okay. So, roughly speaking, I think there's a new category of consumer and manipulator of digital information. It used to be just humans through GUIs or computers through APIs. And now we have a completely new thing. And agents—they're computers, but they are human like, kind of, right? They're people spirits; there are people spirits on the internet, and they need to interact with our software infrastructure. Like, can we build for them? It's a new thing.</p>

<p class="cn">所以，举个例子，你可以在你的域名上有一个robots.txt，你可以指示或者说，我猜是建议，网络爬虫在你的网站上如何行为。同样地，你可能可以有一个LLM.txt文件，它只是一个简单的markdown，告诉LLM这个域名是关于什么的。这对LLM来说非常易读。如果它必须获取你网页的HTML并尝试解析它，这非常容易出错且困难，并且会搞砸，而且行不通。</p>
<p class="en">So, as an example, you can have a robots.txt on your domain, and you can instruct or, like, advise, I suppose, web crawlers on how to behave on your website. In the same way, you can have maybe an LLM.txt file, which is just a simple markdown that's telling LLMs what this domain is about. And this is very readable to an LLM. If it had to instead get the HTML of your web page and try to parse it, this is very error prone and difficult and will screw it up, and it's not going to work.</p>

<p class="cn">所以，我们可以直接和LLM对话。这是值得的。嗯，大量的文档目前是为人类编写的。所以你会看到像列表、粗体文本和图片这样的东西，LLM无法直接访问。所以我看到一些服务现在正在将他们的许多文档过渡到专门为LLM服务。Vercel和Stripe，举个例子，是这里的先行者，但我已经看到了更多，他们用Markdown提供他们的文档。Markdown对于LLM来说超级容易理解。这很棒。</p>
<p class="en">So, we can just directly speak to the LLM. It's worth it. Um, a huge amount of documentation is currently written for people. So you will see things like lists, bold text, and pictures are not directly accessible by an LLM. So, I see some services now transitioning a lot of their documentation to be specifically for LLMs. Vercel and Stripe, as an example, are early movers here, but there are a few more that I've seen already, and they offer their documentation in Markdown. Markdown is super easy for LLMs to understand. This is great.</p>

<p class="cn">嗯，也许从我的经验中举一个简单的例子。也许你们中有人知道3Blue1Brown。他在YouTube上制作了精美的动画视频。是的，我喜欢这个库。所以，他写的Manon，我想自己做一个，关于如何使用Manon有详尽的文档。所以我实际上不想通读它。所以，我把整个东西复制粘贴到一个LLM里，我描述了我想要的，它就开箱即用了。就像，LLM直接给我生成了一个我想要的动画，我当时想，哇，这太神奇了。</p>
<p class="en">Um, maybe one simple example from my experience as well. Maybe some of you know 3Blue1Brown. He makes beautiful animation videos on YouTube. Yeah, I love this library. So, that he wrote, Manon, and I wanted to make my own, and there's extensive documentation on how to use Manon. And so I didn't want to actually read through it. So, I copied and pasted the whole thing to an LLM, and I described what I wanted, and it just worked out of the box. Like, the LLM just generated me an animation exactly what I wanted, and I was like, wow, this is amazing.</p>

<p class="cn">所以，如果我们能让文档对LLM可读，这将解锁大量的使用，我认为这很棒，应该更多地发生。</p>
<p class="en">So, if we can make documentation legible to LLMs, it's going to unlock a huge amount of use, and I think this is wonderful and should happen more.</p>

<p class="cn">我想指出的另一件事是，不幸的是，你必须——这不仅仅是把你的文档拿来让它们以Markdown格式出现。那是简单的部分。我们实际上必须改变文档，因为每当你的文档说“点击这个”，这就不好了。LLM现在无法本地执行这个操作。所以，Vercel，例如，正在用你的LLM代理可以代表你执行的等效curl命令替换每一个“点击”的出现。</p>
<p class="en">The other thing I wanted to point out is that you do unfortunately have to—it's not just about taking your docs and making them appear in Markdown. That's the easy part. We actually have to change the docs because anytime your docs say "click this," it's bad. An LLM will not be able to natively take this action right now. So, Vercel, for example, is replacing every occurrence of "click" with an equivalent curl command that your LLM agent could take on your behalf.</p>

<p class="cn">嗯，所以我认为这非常有趣。然后，当然，还有来自Anthropic的模型上下文协议。这也是另一种方式；它是一种直接与代理作为数字信息的这个新消费者和操纵者对话的协议。所以我对这些想法非常看好。</p>
<p class="en">Um, and so I think this is very interesting. And then, of course, there's a model context protocol from Anthropic. And this is also another way; it's a protocol of speaking directly to agents as this new consumer and manipulator of digital information. So, I'm very bullish on these ideas.</p>

<p class="cn">我真正喜欢的另一件事是一些零散的小工具，它们帮助以非常LLM友好的格式摄取数据。所以，例如，当我去一个像我的nanoGPT仓库这样的GitHub仓库时，我不能把它喂给LLM并问关于它的问题，因为它，你知道，这是GitHub上的人类界面。所以，当你把URL从GitHub改成get ingest时，它实际上会把所有文件连接成一个巨大的文本，并会创建一个目录结构等等。这就可以复制粘贴到你最喜欢的LLM里，你就可以做事情了。</p>
<p class="en">The other thing I really like is a number of little tools here and there that are helping ingest data in very LLM friendly formats. So, for example, when I go to a GitHub repo like my nanoGPT repo, I can't feed this to an LLM and ask questions about it because it's, you know, this is a human interface on GitHub. So, when you just change the URL from GitHub to get ingest, then this will actually concatenate all the files into a single giant text and will create a directory structure, etc. And this is ready to be copied and pasted into your favorite LLM, and you can do stuff.</p>

<p class="cn">也许一个更戏剧化的例子是Deep Wiki，它不仅仅是这些文件的原始内容。这是来自Devon的，而且，就像，他们让Devon基本上对GitHub仓库进行分析，Devon基本上为你的仓库构建了整个文档页面，你可以想象这对于复制粘贴到你的LLM中更有帮助。所以我喜欢所有那些基本上你只要改变URL就能让某些东西对LLM可访问的小工具。所以，这一切都很好，我认为应该有更多这样的东西。</p>
<p class="en">Maybe even a more dramatic example of this is Deep Wiki, where it's not just the raw content of these files. This is from Devon, but also, like, they have Devon basically do analysis of the GitHub repo, and Devon basically builds up a whole documentation pages just for your repo, and you can imagine that this is even more helpful to copy paste into your LLM. So, I love all the little tools that basically, where you just change the URL, and it makes something accessible to an LLM. So, this is all well and great, and I think there should be a lot more of it.</p>

<p class="cn">我还想补充一点，未来LLM绝对有可能——这甚至不是未来，而是今天——它们能够四处走动，能够点击东西等等。但我仍然认为，你基本上与LLM半途相遇，让它们更容易访问所有这些信息，这是非常值得的，因为这使用起来仍然相当昂贵，我想说，而且要困难得多。所以，我确实认为很多软件将是一个长尾，它不会像适应应用程序一样，因为这些不像实时播放器那样的存储库或数字基础设施，我们将需要这些工具。嗯，但我认为对于其他人来说，我认为在某个中间点相遇是非常值得的。</p>
<p class="en">One more note I wanted to make is that it is absolutely possible that in the future, LLMs will be able to—this is not even future, this is today—they'll be able to go around and they'll be able to click stuff and so on. But I still think it's very worth, you basically meeting LLMs halfway and making it easier for them to access all this information because this is still fairly expensive, I would say, to use and a lot more difficult. And so, I do think that lots of software will be a long tail where it won't like adapt apps because these are not like live player sort of repositories or digital infrastructure, and we will need these tools. Uh, but I think for everyone else, I think it's very worth kind of like meeting in some middle point.</p>

<p class="cn">所以，我对两者都看好，如果这说得通的话。</p>
<p class="en">So, I'm bullish on both, if that makes sense.</p>

<p class="cn">总而言之，现在是进入这个行业的绝佳时机。我们需要重写大量的代码。大量的代码将由专业人士和编码人员编写。这些LLM有点像公用事业，有点像晶圆厂，但它们尤其像操作系统。但这还为时过早。就像1960年代的操作系统，我认为很多类比都适用。嗯，这些LLM有点像这些易犯错的，你知道，我们必须学会与之合作的人类精神。为了正确地做到这一点，我们需要调整我们的基础设施来适应它。</p>
<p class="en">In summary, what an amazing time to get into the industry. We need to rewrite a ton of code. A ton of code will be written by professionals and by coders. These LLMs are kind of like utilities, kind of like fabs, but they're kind of especially like operating systems. But it's so early. It's like the 1960s of operating systems, and I think a lot of the analogies cross over. Um, and these LLMs are kind of like these fallible, you know, people spirits that we have to learn to work with. And in order to do that properly, we need to adjust our infrastructure towards it.</p>

<p class="cn">所以，当你在构建这些LLM应用时，我描述了一些有效使用这些LLM的方法，以及一些使之成为可能的工具，以及你如何能非常非常快地旋转这个循环，并基本上创建部分隧道产品。然后，是的，很多代码也必须更直接地为代理编写。</p>
<p class="en">So, when you're building these LLM apps, I describe some of the ways of working effectively with these LLMs and some of the tools that make that kind of possible, and how you can spin this loop very, very quickly and basically create partial tunneling products. And then, yeah, a lot of code has to also be written for the agents more directly.</p>

<p class="cn">但无论如何，回到钢铁侠战衣的类比，我认为在未来十年左右，我们将看到的是，我们会把滑块从左向右移动。我非常感兴趣。看到那会是什么样子会非常有趣。我迫不及待地想和大家一起构建它。谢谢。</p>
<p class="en">But in any case, going back to the Iron Man suit analogy, I think what we'll see over the next decade roughly is we're going to take the slider from left to right. And I'm very interested. It's going to be very interesting to see what that looks like. And I can't wait to build it with all of you. Thank you.</p>

</div>

<div class="yt">
    <iframe src="https://www.youtube.com/embed/LCEmiRjPEtQ" title="Andrej Karpathy: Software Is Changing (Again)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</div>


<script id="res-script" src="/res/dist/res/main.js" type="text/javascript"></script>
</body></html>