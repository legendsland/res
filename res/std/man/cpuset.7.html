<!DOCTYPE html><html><!-- This is an automatically generated file.  Do not edit.
   Copyright (c) 2008 Silicon Graphics, Inc.
  
   Author: Paul Jackson (http://oss.sgi.com/projects/cpusets)
  
   SPDX-License-Identifier: GPL-2.0-only
   --><head>
<meta name="dc.identifier" content="res/8823a4a3ba9e53d936e847f96f7152f44f93c77d">

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    .Nd, .Bf, .Op { display: inline; }
    .Pa, .Ad { font-style: italic; }
    .Ms { font-weight: bold; }
    .Bl-diag > dt { font-weight: bold; }
    code.Nm, .Fl, .Cm, .Ic, code.In, .Fd, .Fn, .Cd { font-weight: bold;
      font-family: inherit; }
  </style>
  <title>cpuset(7)</title>
<link id="res-style" rel="stylesheet" href="/res/dist/res/style.css" type="text/css">
</head>
<body>
<div id="book-container">
<table class="head">
  <tbody><tr>
    <td class="head-ltitle">cpuset(7)</td>
    <td class="head-vol">Miscellaneous Information Manual</td>
    <td class="head-rtitle">cpuset(7)</td>
  </tr>
</tbody></table>
<div class="manual-text">
<section class="Sh">
<h1 class="Sh" id="NAME"><a class="permalink" href="#NAME">NAME</a></h1>
<p class="Pp">cpuset - confine processes to processor and memory node
  subsets</p>
</section>
<section class="Sh">
<h1 class="Sh" id="DESCRIPTION"><a class="permalink" href="#DESCRIPTION">DESCRIPTION</a></h1>
<p class="Pp">The cpuset filesystem is a pseudo-filesystem interface to the
    kernel cpuset mechanism, which is used to control the processor placement
    and memory placement of processes. It is commonly mounted at
    <i>/dev/cpuset</i>.</p>
<p class="Pp">On systems with kernels compiled with built in support for
    cpusets, all processes are attached to a cpuset, and cpusets are always
    present. If a system supports cpusets, then it will have the entry <b>nodev
    cpuset</b> in the file <i>/proc/filesystems</i>. By mounting the cpuset
    filesystem (see the <b>EXAMPLES</b> section below), the administrator can
    configure the cpusets on a system to control the processor and memory
    placement of processes on that system. By default, if the cpuset
    configuration on a system is not modified or if the cpuset filesystem is not
    even mounted, then the cpuset mechanism, though present, has no effect on
    the system's behavior.</p>
<p class="Pp">A cpuset defines a list of CPUs and memory nodes.</p>
<p class="Pp">The CPUs of a system include all the logical processing units on
    which a process can execute, including, if present, multiple processor cores
    within a package and Hyper-Threads within a processor core. Memory nodes
    include all distinct banks of main memory; small and SMP systems typically
    have just one memory node that contains all the system's main memory, while
    NUMA (non-uniform memory access) systems have multiple memory nodes.</p>
<p class="Pp">Cpusets are represented as directories in a hierarchical
    pseudo-filesystem, where the top directory in the hierarchy
    (<i>/dev/cpuset</i>) represents the entire system (all online CPUs and
    memory nodes) and any cpuset that is the child (descendant) of another
    parent cpuset contains a subset of that parent's CPUs and memory nodes. The
    directories and files representing cpusets have normal filesystem
    permissions.</p>
<p class="Pp">Every process in the system belongs to exactly one cpuset. A
    process is confined to run only on the CPUs in the cpuset it belongs to, and
    to allocate memory only on the memory nodes in that cpuset. When a process
    <b>fork</b>(2)s, the child process is placed in the same cpuset as its
    parent. With sufficient privilege, a process may be moved from one cpuset to
    another and the allowed CPUs and memory nodes of an existing cpuset may be
    changed.</p>
<p class="Pp">When the system begins booting, a single cpuset is defined that
    includes all CPUs and memory nodes on the system, and all processes are in
    that cpuset. During the boot process, or later during normal system
    operation, other cpusets may be created, as subdirectories of this top
    cpuset, under the control of the system administrator, and processes may be
    placed in these other cpusets.</p>
<p class="Pp">Cpusets are integrated with the <b>sched_setaffinity</b>(2)
    scheduling affinity mechanism and the <b>mbind</b>(2) and
    <b>set_mempolicy</b>(2) memory-placement mechanisms in the kernel. Neither
    of these mechanisms let a process make use of a CPU or memory node that is
    not allowed by that process's cpuset. If changes to a process's cpuset
    placement conflict with these other mechanisms, then cpuset placement is
    enforced even if it means overriding these other mechanisms. The kernel
    accomplishes this overriding by silently restricting the CPUs and memory
    nodes requested by these other mechanisms to those allowed by the invoking
    process's cpuset. This can result in these other calls returning an error,
    if for example, such a call ends up requesting an empty set of CPUs or
    memory nodes, after that request is restricted to the invoking process's
    cpuset.</p>
<p class="Pp">Typically, a cpuset is used to manage the CPU and memory-node
    confinement for a set of cooperating processes such as a batch scheduler
    job, and these other mechanisms are used to manage the placement of
    individual processes or memory regions within that set or job.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="FILES"><a class="permalink" href="#FILES">FILES</a></h1>
<p class="Pp">Each directory below <i>/dev/cpuset</i> represents a cpuset and
    contains a fixed set of pseudo-files describing the state of that
  cpuset.</p>
<p class="Pp">New cpusets are created using the <b>mkdir</b>(2) system call or
    the <b>mkdir</b>(1) command. The properties of a cpuset, such as its flags,
    allowed CPUs and memory nodes, and attached processes, are queried and
    modified by reading or writing to the appropriate file in that cpuset's
    directory, as listed below.</p>
<p class="Pp">The pseudo-files in each cpuset directory are automatically
    created when the cpuset is created, as a result of the <b>mkdir</b>(2)
    invocation. It is not possible to directly add or remove these
  pseudo-files.</p>
<p class="Pp">A cpuset directory that contains no child cpuset directories, and
    has no attached processes, can be removed using <b>rmdir</b>(2) or
    <b>rmdir</b>(1). It is not necessary, or possible, to remove the
    pseudo-files inside the directory before removing it.</p>
<p class="Pp">The pseudo-files in each cpuset directory are small text files
    that may be read and written using traditional shell utilities such as
    <b>cat</b>(1), and <b>echo</b>(1), or from a program by using file I/O
    library functions or system calls, such as <b>open</b>(2), <b>read</b>(2),
    <b>write</b>(2), and <b>close</b>(2).</p>
<p class="Pp">The pseudo-files in a cpuset directory represent internal kernel
    state and do not have any persistent image on disk. Each of these per-cpuset
    files is listed and described below.</p>
<dl class="Bl-tag">
  <dt id="tasks"><a class="permalink" href="#tasks"><i>tasks</i></a></dt>
  <dd>List of the process IDs (PIDs) of the processes in that cpuset. The list
      is formatted as a series of ASCII decimal numbers, each followed by a
      newline. A process may be added to a cpuset (automatically removing it
      from the cpuset that previously contained it) by writing its PID to that
      cpuset's <i>tasks</i> file (with or without a trailing newline).</dd>
</dl>
<dl class="Bl-tag">
  <dt></dt>
  <dd><b>Warning:</b> only one PID may be written to the <i>tasks</i> file at a
      time. If a string is written that contains more than one PID, only the
      first one will be used.</dd>
</dl>
<dl class="Bl-tag">
  <dt id="notify_on_release"><a class="permalink" href="#notify_on_release"><i>notify_on_release</i></a></dt>
  <dd>Flag (0 or 1). If set (1), that cpuset will receive special handling after
      it is released, that is, after all processes cease using it (i.e.,
      terminate or are moved to a different cpuset) and all child cpuset
      directories have been removed. See the <b>Notify On Release</b> section,
      below.</dd>
  <dt id="cpuset.cpus"><a class="permalink" href="#cpuset.cpus"><i>cpuset.cpus</i></a></dt>
  <dd>List of the physical numbers of the CPUs on which processes in that cpuset
      are allowed to execute. See <b>List Format</b> below for a description of
      the format of <i>cpus</i>.</dd>
</dl>
<dl class="Bl-tag">
  <dt></dt>
  <dd>The CPUs allowed to a cpuset may be changed by writing a new list to its
      <i>cpus</i> file.</dd>
</dl>
<dl class="Bl-tag">
  <dt id="cpuset.cpu_exclusive"><a class="permalink" href="#cpuset.cpu_exclusive"><i>cpuset.cpu_exclusive</i></a></dt>
  <dd>Flag (0 or 1). If set (1), the cpuset has exclusive use of its CPUs (no
      sibling or cousin cpuset may overlap CPUs). By default, this is off (0).
      Newly created cpusets also initially default this to off (0).</dd>
</dl>
<dl class="Bl-tag">
  <dt></dt>
  <dd>Two cpusets are <i>sibling</i> cpusets if they share the same parent
      cpuset in the <i>/dev/cpuset</i> hierarchy. Two cpusets are <i>cousin</i>
      cpusets if neither is the ancestor of the other. Regardless of the
      <i>cpu_exclusive</i> setting, if one cpuset is the ancestor of another,
      and if both of these cpusets have nonempty <i>cpus</i>, then their
      <i>cpus</i> must overlap, because the <i>cpus</i> of any cpuset are always
      a subset of the <i>cpus</i> of its parent cpuset.</dd>
</dl>
<dl class="Bl-tag">
  <dt id="cpuset.mems"><a class="permalink" href="#cpuset.mems"><i>cpuset.mems</i></a></dt>
  <dd>List of memory nodes on which processes in this cpuset are allowed to
      allocate memory. See <b>List Format</b> below for a description of the
      format of <i>mems</i>.</dd>
  <dt id="cpuset.mem_exclusive"><a class="permalink" href="#cpuset.mem_exclusive"><i>cpuset.mem_exclusive</i></a></dt>
  <dd>Flag (0 or 1). If set (1), the cpuset has exclusive use of its memory
      nodes (no sibling or cousin may overlap). Also if set (1), the cpuset is a
      <b>Hardwall</b> cpuset (see below). By default, this is off (0). Newly
      created cpusets also initially default this to off (0).</dd>
</dl>
<dl class="Bl-tag">
  <dt></dt>
  <dd>Regardless of the <i>mem_exclusive</i> setting, if one cpuset is the
      ancestor of another, then their memory nodes must overlap, because the
      memory nodes of any cpuset are always a subset of the memory nodes of that
      cpuset's parent cpuset.</dd>
</dl>
<dl class="Bl-tag">
  <dt id="cpuset.mem_hardwall"><a class="permalink" href="#cpuset.mem_hardwall"><i>cpuset.mem_hardwall</i>
    (since Linux 2.6.26)</a></dt>
  <dd>Flag (0 or 1). If set (1), the cpuset is a <b>Hardwall</b> cpuset (see
      below). Unlike <b>mem_exclusive</b>, there is no constraint on whether
      cpusets marked <b>mem_hardwall</b> may have overlapping memory nodes with
      sibling or cousin cpusets. By default, this is off (0). Newly created
      cpusets also initially default this to off (0).</dd>
  <dt id="cpuset.memory_migrate"><a class="permalink" href="#cpuset.memory_migrate"><i>cpuset.memory_migrate</i>
    (since Linux 2.6.16)</a></dt>
  <dd>Flag (0 or 1). If set (1), then memory migration is enabled. By default,
      this is off (0). See the <b>Memory Migration</b> section, below.</dd>
  <dt id="cpuset.memory_pressure"><a class="permalink" href="#cpuset.memory_pressure"><i>cpuset.memory_pressure</i>
    (since Linux 2.6.16)</a></dt>
  <dd>A measure of how much memory pressure the processes in this cpuset are
      causing. See the <b>Memory Pressure</b> section, below. Unless
      <i>memory_pressure_enabled</i> is enabled, always has value zero (0). This
      file is read-only. See the <b>WARNINGS</b> section, below.</dd>
  <dt id="cpuset.memory_pressure_enabled"><a class="permalink" href="#cpuset.memory_pressure_enabled"><i>cpuset.memory_pressure_enabled</i>
    (since Linux 2.6.16)</a></dt>
  <dd>Flag (0 or 1). This file is present only in the root cpuset, normally
      <i>/dev/cpuset</i>. If set (1), the <i>memory_pressure</i> calculations
      are enabled for all cpusets in the system. By default, this is off (0).
      See the <b>Memory Pressure</b> section, below.</dd>
  <dt id="cpuset.memory_spread_page"><a class="permalink" href="#cpuset.memory_spread_page"><i>cpuset.memory_spread_page</i>
    (since Linux 2.6.17)</a></dt>
  <dd>Flag (0 or 1). If set (1), pages in the kernel page cache (filesystem
      buffers) are uniformly spread across the cpuset. By default, this is off
      (0) in the top cpuset, and inherited from the parent cpuset in newly
      created cpusets. See the <b>Memory Spread</b> section, below.</dd>
  <dt id="cpuset.memory_spread_slab"><a class="permalink" href="#cpuset.memory_spread_slab"><i>cpuset.memory_spread_slab</i>
    (since Linux 2.6.17)</a></dt>
  <dd>Flag (0 or 1). If set (1), the kernel slab caches for file I/O (directory
      and inode structures) are uniformly spread across the cpuset. By default,
      is off (0) in the top cpuset, and inherited from the parent cpuset in
      newly created cpusets. See the <b>Memory Spread</b> section, below.</dd>
  <dt id="cpuset.sched_load_balance"><a class="permalink" href="#cpuset.sched_load_balance"><i>cpuset.sched_load_balance</i>
    (since Linux 2.6.24)</a></dt>
  <dd>Flag (0 or 1). If set (1, the default) the kernel will automatically load
      balance processes in that cpuset over the allowed CPUs in that cpuset. If
      cleared (0) the kernel will avoid load balancing processes in this cpuset,
      <i>unless</i> some other cpuset with overlapping CPUs has its
      <i>sched_load_balance</i> flag set. See <b>Scheduler Load Balancing</b>,
      below, for further details.</dd>
  <dt id="cpuset.sched_relax_domain_level"><a class="permalink" href="#cpuset.sched_relax_domain_level"><i>cpuset.sched_relax_domain_level</i>
    (since Linux 2.6.26)</a></dt>
  <dd>Integer, between -1 and a small positive value. The
      <i>sched_relax_domain_level</i> controls the width of the range of CPUs
      over which the kernel scheduler performs immediate rebalancing of runnable
      tasks across CPUs. If <i>sched_load_balance</i> is disabled, then the
      setting of <i>sched_relax_domain_level</i> does not matter, as no such
      load balancing is done. If <i>sched_load_balance</i> is enabled, then the
      higher the value of the <i>sched_relax_domain_level</i>, the wider the
      range of CPUs over which immediate load balancing is attempted. See
      <b>Scheduler Relax Domain Level</b>, below, for further details.</dd>
</dl>
<p class="Pp">In addition to the above pseudo-files in each directory below
    <i>/dev/cpuset</i>, each process has a pseudo-file,
    <i>/proc/&lt;pid&gt;/cpuset</i>, that displays the path of the process's
    cpuset directory relative to the root of the cpuset filesystem.</p>
<p class="Pp">Also the <i>/proc/&lt;pid&gt;/status</i> file for each process has
    four added lines, displaying the process's <i>Cpus_allowed</i> (on which
    CPUs it may be scheduled) and <i>Mems_allowed</i> (on which memory nodes it
    may obtain memory), in the two formats <b>Mask Format</b> and <b>List
    Format</b> (see below) as shown in the following example:</p>
<p class="Pp">
  <br>
</p>
<pre>Cpus_allowed:   ffffffff,ffffffff,ffffffff,ffffffff
Cpus_allowed_list:     0-127
Mems_allowed:   ffffffff,ffffffff
Mems_allowed_list:     0-63
</pre>
<br>
<p class="Pp">The "allowed" fields were added in Linux 2.6.24; the
    "allowed_list" fields were added in Linux 2.6.26.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="EXTENDED_CAPABILITIES"><a class="permalink" href="#EXTENDED_CAPABILITIES">EXTENDED
  CAPABILITIES</a></h1>
<p class="Pp">In addition to controlling which <i>cpus</i> and <i>mems</i> a
    process is allowed to use, cpusets provide the following extended
    capabilities.</p>
<section class="Ss">
<h2 class="Ss" id="Exclusive_cpusets"><a class="permalink" href="#Exclusive_cpusets">Exclusive
  cpusets</a></h2>
<p class="Pp">If a cpuset is marked <i>cpu_exclusive</i> or
    <i>mem_exclusive</i>, no other cpuset, other than a direct ancestor or
    descendant, may share any of the same CPUs or memory nodes.</p>
<p class="Pp">A cpuset that is <i>mem_exclusive</i> restricts kernel allocations
    for buffer cache pages and other internal kernel data pages commonly shared
    by the kernel across multiple users. All cpusets, whether
    <i>mem_exclusive</i> or not, restrict allocations of memory for user space.
    This enables configuring a system so that several independent jobs can share
    common kernel data, while isolating each job's user allocation in its own
    cpuset. To do this, construct a large <i>mem_exclusive</i> cpuset to hold
    all the jobs, and construct child, non-<i>mem_exclusive</i> cpusets for each
    individual job. Only a small amount of kernel memory, such as requests from
    interrupt handlers, is allowed to be placed on memory nodes outside even a
    <i>mem_exclusive</i> cpuset.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Hardwall"><a class="permalink" href="#Hardwall">Hardwall</a></h2>
<p class="Pp">A cpuset that has <i>mem_exclusive</i> or <i>mem_hardwall</i> set
    is a <i>hardwall</i> cpuset. A <i>hardwall</i> cpuset restricts kernel
    allocations for page, buffer, and other data commonly shared by the kernel
    across multiple users. All cpusets, whether <i>hardwall</i> or not, restrict
    allocations of memory for user space.</p>
<p class="Pp">This enables configuring a system so that several independent jobs
    can share common kernel data, such as filesystem pages, while isolating each
    job's user allocation in its own cpuset. To do this, construct a large
    <i>hardwall</i> cpuset to hold all the jobs, and construct child cpusets for
    each individual job which are not <i>hardwall</i> cpusets.</p>
<p class="Pp">Only a small amount of kernel memory, such as requests from
    interrupt handlers, is allowed to be taken outside even a <i>hardwall</i>
    cpuset.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Notify_on_release"><a class="permalink" href="#Notify_on_release">Notify
  on release</a></h2>
<p class="Pp">If the <i>notify_on_release</i> flag is enabled (1) in a cpuset,
    then whenever the last process in the cpuset leaves (exits or attaches to
    some other cpuset) and the last child cpuset of that cpuset is removed, the
    kernel will run the command <i>/sbin/cpuset_release_agent</i>, supplying the
    pathname (relative to the mount point of the cpuset filesystem) of the
    abandoned cpuset. This enables automatic removal of abandoned cpusets.</p>
<p class="Pp">The default value of <i>notify_on_release</i> in the root cpuset
    at system boot is disabled (0). The default value of other cpusets at
    creation is the current value of their parent's <i>notify_on_release</i>
    setting.</p>
<p class="Pp">The command <i>/sbin/cpuset_release_agent</i> is invoked, with the
    name (<i>/dev/cpuset</i> relative path) of the to-be-released cpuset in
    <i>argv[1]</i>.</p>
<p class="Pp">The usual contents of the command
    <i>/sbin/cpuset_release_agent</i> is simply the shell script:</p>
<p class="Pp">
  <br>
</p>
<pre>#!/bin/sh
rmdir /dev/cpuset/$1
</pre>
<br>
<p class="Pp">As with other flag values below, this flag can be changed by
    writing an ASCII number 0 or 1 (with optional trailing newline) into the
    file, to clear or set the flag, respectively.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Memory_pressure"><a class="permalink" href="#Memory_pressure">Memory
  pressure</a></h2>
<p class="Pp">The <i>memory_pressure</i> of a cpuset provides a simple
    per-cpuset running average of the rate that the processes in a cpuset are
    attempting to free up in-use memory on the nodes of the cpuset to satisfy
    additional memory requests.</p>
<p class="Pp">This enables batch managers that are monitoring jobs running in
    dedicated cpusets to efficiently detect what level of memory pressure that
    job is causing.</p>
<p class="Pp">This is useful both on tightly managed systems running a wide mix
    of submitted jobs, which may choose to terminate or reprioritize jobs that
    are trying to use more memory than allowed on the nodes assigned them, and
    with tightly coupled, long-running, massively parallel scientific computing
    jobs that will dramatically fail to meet required performance goals if they
    start to use more memory than allowed to them.</p>
<p class="Pp">This mechanism provides a very economical way for the batch
    manager to monitor a cpuset for signs of memory pressure. It's up to the
    batch manager or other user code to decide what action to take if it detects
    signs of memory pressure.</p>
<p class="Pp">Unless memory pressure calculation is enabled by setting the
    pseudo-file <i>/dev/cpuset/cpuset.memory_pressure_enabled</i>, it is not
    computed for any cpuset, and reads from any <i>memory_pressure</i> always
    return zero, as represented by the ASCII string "0\n". See the
    <b>WARNINGS</b> section, below.</p>
<p class="Pp">A per-cpuset, running average is employed for the following
    reasons:</p>
<dl class="Bl-tag">
  <dt>•</dt>
  <dd>Because this meter is per-cpuset rather than per-process or per virtual
      memory region, the system load imposed by a batch scheduler monitoring
      this metric is sharply reduced on large systems, because a scan of the
      tasklist can be avoided on each set of queries.</dd>
  <dt>•</dt>
  <dd>Because this meter is a running average rather than an accumulating
      counter, a batch scheduler can detect memory pressure with a single read,
      instead of having to read and accumulate results for a period of
    time.</dd>
  <dt>•</dt>
  <dd>Because this meter is per-cpuset rather than per-process, the batch
      scheduler can obtain the key information—memory pressure in a
      cpuset—with a single read, rather than having to query and
      accumulate results over all the (dynamically changing) set of processes in
      the cpuset.</dd>
</dl>
<p class="Pp">The <i>memory_pressure</i> of a cpuset is calculated using a
    per-cpuset simple digital filter that is kept within the kernel. For each
    cpuset, this filter tracks the recent rate at which processes attached to
    that cpuset enter the kernel direct reclaim code.</p>
<p class="Pp">The kernel direct reclaim code is entered whenever a process has
    to satisfy a memory page request by first finding some other page to
    repurpose, due to lack of any readily available already free pages. Dirty
    filesystem pages are repurposed by first writing them to disk. Unmodified
    filesystem buffer pages are repurposed by simply dropping them, though if
    that page is needed again, it will have to be reread from disk.</p>
<p class="Pp">The <i>cpuset.memory_pressure</i> file provides an integer number
    representing the recent (half-life of 10 seconds) rate of entries to the
    direct reclaim code caused by any process in the cpuset, in units of
    reclaims attempted per second, times 1000.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Memory_spread"><a class="permalink" href="#Memory_spread">Memory
  spread</a></h2>
<p class="Pp">There are two Boolean flag files per cpuset that control where the
    kernel allocates pages for the filesystem buffers and related in-kernel data
    structures. They are called <i>cpuset.memory_spread_page</i> and
    <i>cpuset.memory_spread_slab</i>.</p>
<p class="Pp">If the per-cpuset Boolean flag file
    <i>cpuset.memory_spread_page</i> is set, then the kernel will spread the
    filesystem buffers (page cache) evenly over all the nodes that the faulting
    process is allowed to use, instead of preferring to put those pages on the
    node where the process is running.</p>
<p class="Pp">If the per-cpuset Boolean flag file
    <i>cpuset.memory_spread_slab</i> is set, then the kernel will spread some
    filesystem-related slab caches, such as those for inodes and directory
    entries, evenly over all the nodes that the faulting process is allowed to
    use, instead of preferring to put those pages on the node where the process
    is running.</p>
<p class="Pp">The setting of these flags does not affect the data segment (see
    <b>brk</b>(2)) or stack segment pages of a process.</p>
<p class="Pp">By default, both kinds of memory spreading are off and the kernel
    prefers to allocate memory pages on the node local to where the requesting
    process is running. If that node is not allowed by the process's NUMA memory
    policy or cpuset configuration or if there are insufficient free memory
    pages on that node, then the kernel looks for the nearest node that is
    allowed and has sufficient free memory.</p>
<p class="Pp">When new cpusets are created, they inherit the memory spread
    settings of their parent.</p>
<p class="Pp">Setting memory spreading causes allocations for the affected page
    or slab caches to ignore the process's NUMA memory policy and be spread
    instead. However, the effect of these changes in memory placement caused by
    cpuset-specified memory spreading is hidden from the <b>mbind</b>(2) or
    <b>set_mempolicy</b>(2) calls. These two NUMA memory policy calls always
    appear to behave as if no cpuset-specified memory spreading is in effect,
    even if it is. If cpuset memory spreading is subsequently turned off, the
    NUMA memory policy most recently specified by these calls is automatically
    reapplied.</p>
<p class="Pp">Both <i>cpuset.memory_spread_page</i> and
    <i>cpuset.memory_spread_slab</i> are Boolean flag files. By default, they
    contain "0", meaning that the feature is off for that cpuset. If a
    "1" is written to that file, that turns the named feature on.</p>
<p class="Pp">Cpuset-specified memory spreading behaves similarly to what is
    known (in other contexts) as round-robin or interleave memory placement.</p>
<p class="Pp">Cpuset-specified memory spreading can provide substantial
    performance improvements for jobs that:</p>
<dl class="Bl-tag">
  <dt>•</dt>
  <dd>need to place thread-local data on memory nodes close to the CPUs which
      are running the threads that most frequently access that data; but
    also</dd>
  <dt>•</dt>
  <dd>need to access large filesystem data sets that must to be spread across
      the several nodes in the job's cpuset in order to fit.</dd>
</dl>
<p class="Pp">Without this policy, the memory allocation across the nodes in the
    job's cpuset can become very uneven, especially for jobs that might have
    just a single thread initializing or reading in the data set.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Memory_migration"><a class="permalink" href="#Memory_migration">Memory
  migration</a></h2>
<p class="Pp">Normally, under the default setting (disabled) of
    <i>cpuset.memory_migrate</i>, once a page is allocated (given a physical
    page of main memory), then that page stays on whatever node it was
    allocated, so long as it remains allocated, even if the cpuset's
    memory-placement policy <i>mems</i> subsequently changes.</p>
<p class="Pp">When memory migration is enabled in a cpuset, if the <i>mems</i>
    setting of the cpuset is changed, then any memory page in use by any process
    in the cpuset that is on a memory node that is no longer allowed will be
    migrated to a memory node that is allowed.</p>
<p class="Pp">Furthermore, if a process is moved into a cpuset with
    <i>memory_migrate</i> enabled, any memory pages it uses that were on memory
    nodes allowed in its previous cpuset, but which are not allowed in its new
    cpuset, will be migrated to a memory node allowed in the new cpuset.</p>
<p class="Pp">The relative placement of a migrated page within the cpuset is
    preserved during these migration operations if possible. For example, if the
    page was on the second valid node of the prior cpuset, then the page will be
    placed on the second valid node of the new cpuset, if possible.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Scheduler_load_balancing"><a class="permalink" href="#Scheduler_load_balancing">Scheduler
  load balancing</a></h2>
<p class="Pp">The kernel scheduler automatically load balances processes. If one
    CPU is underutilized, the kernel will look for processes on other more
    overloaded CPUs and move those processes to the underutilized CPU, within
    the constraints of such placement mechanisms as cpusets and
    <b>sched_setaffinity</b>(2).</p>
<p class="Pp">The algorithmic cost of load balancing and its impact on key
    shared kernel data structures such as the process list increases more than
    linearly with the number of CPUs being balanced. For example, it costs more
    to load balance across one large set of CPUs than it does to balance across
    two smaller sets of CPUs, each of half the size of the larger set. (The
    precise relationship between the number of CPUs being balanced and the cost
    of load balancing depends on implementation details of the kernel process
    scheduler, which is subject to change over time, as improved kernel
    scheduler algorithms are implemented.)</p>
<p class="Pp">The per-cpuset flag <i>sched_load_balance</i> provides a mechanism
    to suppress this automatic scheduler load balancing in cases where it is not
    needed and suppressing it would have worthwhile performance benefits.</p>
<p class="Pp">By default, load balancing is done across all CPUs, except those
    marked isolated using the kernel boot time "isolcpus=" argument.
    (See <b>Scheduler Relax Domain Level</b>, below, to change this
  default.)</p>
<p class="Pp">This default load balancing across all CPUs is not well suited to
    the following two situations:</p>
<dl class="Bl-tag">
  <dt>•</dt>
  <dd>On large systems, load balancing across many CPUs is expensive. If the
      system is managed using cpusets to place independent jobs on separate sets
      of CPUs, full load balancing is unnecessary.</dd>
  <dt>•</dt>
  <dd>Systems supporting real-time on some CPUs need to minimize system overhead
      on those CPUs, including avoiding process load balancing if that is not
      needed.</dd>
</dl>
<p class="Pp">When the per-cpuset flag <i>sched_load_balance</i> is enabled (the
    default setting), it requests load balancing across all the CPUs in that
    cpuset's allowed CPUs, ensuring that load balancing can move a process (not
    otherwise pinned, as by <b>sched_setaffinity</b>(2)) from any CPU in that
    cpuset to any other.</p>
<p class="Pp">When the per-cpuset flag <i>sched_load_balance</i> is disabled,
    then the scheduler will avoid load balancing across the CPUs in that cpuset,
    <i>except</i> in so far as is necessary because some overlapping cpuset has
    <i>sched_load_balance</i> enabled.</p>
<p class="Pp">So, for example, if the top cpuset has the flag
    <i>sched_load_balance</i> enabled, then the scheduler will load balance
    across all CPUs, and the setting of the <i>sched_load_balance</i> flag in
    other cpusets has no effect, as we're already fully load balancing.</p>
<p class="Pp">Therefore in the above two situations, the flag
    <i>sched_load_balance</i> should be disabled in the top cpuset, and only
    some of the smaller, child cpusets would have this flag enabled.</p>
<p class="Pp">When doing this, you don't usually want to leave any unpinned
    processes in the top cpuset that might use nontrivial amounts of CPU, as
    such processes may be artificially constrained to some subset of CPUs,
    depending on the particulars of this flag setting in descendant cpusets.
    Even if such a process could use spare CPU cycles in some other CPUs, the
    kernel scheduler might not consider the possibility of load balancing that
    process to the underused CPU.</p>
<p class="Pp">Of course, processes pinned to a particular CPU can be left in a
    cpuset that disables <i>sched_load_balance</i> as those processes aren't
    going anywhere else anyway.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Scheduler_relax_domain_level"><a class="permalink" href="#Scheduler_relax_domain_level">Scheduler
  relax domain level</a></h2>
<p class="Pp">The kernel scheduler performs immediate load balancing whenever a
    CPU becomes free or another task becomes runnable. This load balancing works
    to ensure that as many CPUs as possible are usefully employed running tasks.
    The kernel also performs periodic load balancing off the software clock
    described in <b>time</b>(7). The setting of <i>sched_relax_domain_level</i>
    applies only to immediate load balancing. Regardless of the
    <i>sched_relax_domain_level</i> setting, periodic load balancing is
    attempted over all CPUs (unless disabled by turning off
    <i>sched_load_balance</i>.) In any case, of course, tasks will be scheduled
    to run only on CPUs allowed by their cpuset, as modified by
    <b>sched_setaffinity</b>(2) system calls.</p>
<p class="Pp">On small systems, such as those with just a few CPUs, immediate
    load balancing is useful to improve system interactivity and to minimize
    wasteful idle CPU cycles. But on large systems, attempting immediate load
    balancing across a large number of CPUs can be more costly than it is worth,
    depending on the particular performance characteristics of the job mix and
    the hardware.</p>
<p class="Pp">The exact meaning of the small integer values of
    <i>sched_relax_domain_level</i> will depend on internal implementation
    details of the kernel scheduler code and on the non-uniform architecture of
    the hardware. Both of these will evolve over time and vary by system
    architecture and kernel version.</p>
<p class="Pp">As of this writing, when this capability was introduced in Linux
    2.6.26, on certain popular architectures, the positive values of
    <i>sched_relax_domain_level</i> have the following meanings.</p>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt><b>1</b></dt>
  <dd>Perform immediate load balancing across Hyper-Thread siblings on the same
      core.</dd>
  <dt><b>2</b></dt>
  <dd>Perform immediate load balancing across other cores in the same
    package.</dd>
  <dt><b>3</b></dt>
  <dd>Perform immediate load balancing across other CPUs on the same node or
      blade.</dd>
  <dt><b>4</b></dt>
  <dd>Perform immediate load balancing across over several (implementation
      detail) nodes [On NUMA systems].</dd>
  <dt><b>5</b></dt>
  <dd>Perform immediate load balancing across over all CPUs in system [On NUMA
      systems].</dd>
</dl>
<p class="Pp">The <i>sched_relax_domain_level</i> value of zero (0) always means
    don't perform immediate load balancing, hence that load balancing is done
    only periodically, not immediately when a CPU becomes available or another
    task becomes runnable.</p>
<p class="Pp">The <i>sched_relax_domain_level</i> value of minus one (-1) always
    means use the system default value. The system default value can vary by
    architecture and kernel version. This system default value can be changed by
    kernel boot-time "relax_domain_level=" argument.</p>
<p class="Pp">In the case of multiple overlapping cpusets which have conflicting
    <i>sched_relax_domain_level</i> values, then the highest such value applies
    to all CPUs in any of the overlapping cpusets. In such cases, the value
    <b>minus one (-1)</b> is the lowest value, overridden by any other value,
    and the value <b>zero (0)</b> is the next lowest value.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="FORMATS"><a class="permalink" href="#FORMATS">FORMATS</a></h1>
<p class="Pp">The following formats are used to represent sets of CPUs and
    memory nodes.</p>
<section class="Ss">
<h2 class="Ss" id="Mask_format"><a class="permalink" href="#Mask_format">Mask
  format</a></h2>
<p class="Pp">The <b>Mask Format</b> is used to represent CPU and memory-node
    bit masks in the <i>/proc/&lt;pid&gt;/status</i> file.</p>
<p class="Pp">This format displays each 32-bit word in hexadecimal (using ASCII
    characters "0" - "9" and "a" - "f");
    words are filled with leading zeros, if required. For masks longer than one
    word, a comma separator is used between words. Words are displayed in
    big-endian order, which has the most significant bit first. The hex digits
    within a word are also in big-endian order.</p>
<p class="Pp">The number of 32-bit words displayed is the minimum number needed
    to display all bits of the bit mask, based on the size of the bit mask.</p>
<p class="Pp">Examples of the <b>Mask Format</b>:</p>
<p class="Pp">
  <br>
</p>
<pre>00000001                        # just bit 0 set
40000000,00000000,00000000      # just bit 94 set
00000001,00000000,00000000      # just bit 64 set
000000ff,00000000               # bits 32-39 set
00000000,000e3862               # 1,5,6,11-13,17-19 set
</pre>
<br>
<p class="Pp">A mask with bits 0, 1, 2, 4, 8, 16, 32, and 64 set displays
  as:</p>
<p class="Pp">
  <br>
</p>
<pre>00000001,00000001,00010117
</pre>
<br>
<p class="Pp">The first "1" is for bit 64, the second for bit 32, the
    third for bit 16, the fourth for bit 8, the fifth for bit 4, and the
    "7" is for bits 2, 1, and 0.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="List_format"><a class="permalink" href="#List_format">List
  format</a></h2>
<p class="Pp">The <b>List Format</b> for <i>cpus</i> and <i>mems</i> is a
    comma-separated list of CPU or memory-node numbers and ranges of numbers, in
    ASCII decimal.</p>
<p class="Pp">Examples of the <b>List Format</b>:</p>
<p class="Pp">
  <br>
</p>
<pre>0-4,9           # bits 0, 1, 2, 3, 4, and 9 set
0-2,7,12-14     # bits 0, 1, 2, 7, 12, 13, and 14 set
</pre>
<br>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="RULES"><a class="permalink" href="#RULES">RULES</a></h1>
<p class="Pp">The following rules apply to each cpuset:</p>
<dl class="Bl-tag">
  <dt>•</dt>
  <dd>Its CPUs and memory nodes must be a (possibly equal) subset of its
      parent's.</dd>
  <dt>•</dt>
  <dd>It can be marked <i>cpu_exclusive</i> only if its parent is.</dd>
  <dt>•</dt>
  <dd>It can be marked <i>mem_exclusive</i> only if its parent is.</dd>
  <dt>•</dt>
  <dd>If it is <i>cpu_exclusive</i>, its CPUs may not overlap any sibling.</dd>
  <dt>•</dt>
  <dd>If it is <i>mem_exclusive</i>, its memory nodes may not overlap any
      sibling.</dd>
</dl>
</section>
<section class="Sh">
<h1 class="Sh" id="PERMISSIONS"><a class="permalink" href="#PERMISSIONS">PERMISSIONS</a></h1>
<p class="Pp">The permissions of a cpuset are determined by the permissions of
    the directories and pseudo-files in the cpuset filesystem, normally mounted
    at <i>/dev/cpuset</i>.</p>
<p class="Pp">For instance, a process can put itself in some other cpuset (than
    its current one) if it can write the <i>tasks</i> file for that cpuset. This
    requires execute permission on the encompassing directories and write
    permission on the <i>tasks</i> file.</p>
<p class="Pp">An additional constraint is applied to requests to place some
    other process in a cpuset. One process may not attach another to a cpuset
    unless it would have permission to send that process a signal (see
    <b>kill</b>(2)).</p>
<p class="Pp">A process may create a child cpuset if it can access and write the
    parent cpuset directory. It can modify the CPUs or memory nodes in a cpuset
    if it can access that cpuset's directory (execute permissions on the each of
    the parent directories) and write the corresponding <i>cpus</i> or
    <i>mems</i> file.</p>
<p class="Pp">There is one minor difference between the manner in which these
    permissions are evaluated and the manner in which normal filesystem
    operation permissions are evaluated. The kernel interprets relative
    pathnames starting at a process's current working directory. Even if one is
    operating on a cpuset file, relative pathnames are interpreted relative to
    the process's current working directory, not relative to the process's
    current cpuset. The only ways that cpuset paths relative to a process's
    current cpuset can be used are if either the process's current working
    directory is its cpuset (it first did a <b>cd</b> or <b>chdir</b>(2) to its
    cpuset directory beneath <i>/dev/cpuset</i>, which is a bit unusual) or if
    some user code converts the relative cpuset path to a full filesystem
  path.</p>
<p class="Pp">In theory, this means that user code should specify cpusets using
    absolute pathnames, which requires knowing the mount point of the cpuset
    filesystem (usually, but not necessarily, <i>/dev/cpuset</i>). In practice,
    all user level code that this author is aware of simply assumes that if the
    cpuset filesystem is mounted, then it is mounted at <i>/dev/cpuset</i>.
    Furthermore, it is common practice for carefully written user code to verify
    the presence of the pseudo-file <i>/dev/cpuset/tasks</i> in order to verify
    that the cpuset pseudo-filesystem is currently mounted.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="WARNINGS"><a class="permalink" href="#WARNINGS">WARNINGS</a></h1>
<section class="Ss">
<h2 class="Ss" id="Enabling_memory_pressure"><a class="permalink" href="#Enabling_memory_pressure">Enabling
  memory_pressure</a></h2>
<p class="Pp">By default, the per-cpuset file <i>cpuset.memory_pressure</i>
    always contains zero (0). Unless this feature is enabled by writing
    "1" to the pseudo-file
    <i>/dev/cpuset/cpuset.memory_pressure_enabled</i>, the kernel does not
    compute per-cpuset <i>memory_pressure</i>.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Using_the_echo_command"><a class="permalink" href="#Using_the_echo_command">Using
  the echo command</a></h2>
<p class="Pp">When using the <b>echo</b> command at the shell prompt to change
    the values of cpuset files, beware that the built-in <b>echo</b> command in
    some shells does not display an error message if the <b>write</b>(2) system
    call fails. For example, if the command:</p>
<p class="Pp">
  <br>
</p>
<pre>echo 19 &gt; cpuset.mems
</pre>
<br>
<p class="Pp">failed because memory node 19 was not allowed (perhaps the current
    system does not have a memory node 19), then the <b>echo</b> command might
    not display any error. It is better to use the <b>/bin/echo</b> external
    command to change cpuset file settings, as this command will display
    <b>write</b>(2) errors, as in the example:</p>
<p class="Pp">
  <br>
</p>
<pre>/bin/echo 19 &gt; cpuset.mems
/bin/echo: write error: Invalid argument
</pre>
<br>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="EXCEPTIONS"><a class="permalink" href="#EXCEPTIONS">EXCEPTIONS</a></h1>
<section class="Ss">
<h2 class="Ss" id="Memory_placement"><a class="permalink" href="#Memory_placement">Memory
  placement</a></h2>
<p class="Pp">Not all allocations of system memory are constrained by cpusets,
    for the following reasons.</p>
<p class="Pp">If hot-plug functionality is used to remove all the CPUs that are
    currently assigned to a cpuset, then the kernel will automatically update
    the <i>cpus_allowed</i> of all processes attached to CPUs in that cpuset to
    allow all CPUs. When memory hot-plug functionality for removing memory nodes
    is available, a similar exception is expected to apply there as well. In
    general, the kernel prefers to violate cpuset placement, rather than
    starving a process that has had all its allowed CPUs or memory nodes taken
    offline. User code should reconfigure cpusets to refer only to online CPUs
    and memory nodes when using hot-plug to add or remove such resources.</p>
<p class="Pp">A few kernel-critical, internal memory-allocation requests, marked
    GFP_ATOMIC, must be satisfied immediately. The kernel may drop some request
    or malfunction if one of these allocations fail. If such a request cannot be
    satisfied within the current process's cpuset, then we relax the cpuset, and
    look for memory anywhere we can find it. It's better to violate the cpuset
    than stress the kernel.</p>
<p class="Pp">Allocations of memory requested by kernel drivers while processing
    an interrupt lack any relevant process context, and are not confined by
    cpusets.</p>
</section>
<section class="Ss">
<h2 class="Ss" id="Renaming_cpusets"><a class="permalink" href="#Renaming_cpusets">Renaming
  cpusets</a></h2>
<p class="Pp">You can use the <b>rename</b>(2) system call to rename cpusets.
    Only simple renaming is supported; that is, changing the name of a cpuset
    directory is permitted, but moving a directory into a different directory is
    not permitted.</p>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="ERRORS"><a class="permalink" href="#ERRORS">ERRORS</a></h1>
<p class="Pp">The Linux kernel implementation of cpusets sets <i>errno</i> to
    specify the reason for a failed system call affecting cpusets.</p>
<p class="Pp">The possible <i>errno</i> settings and their meaning when set on a
    failed cpuset call are as listed below.</p>
<dl class="Bl-tag">
  <dt id="E2BIG"><a class="permalink" href="#E2BIG"><b>E2BIG</b></a></dt>
  <dd>Attempted a <b>write</b>(2) on a special cpuset file with a length larger
      than some kernel-determined upper limit on the length of such writes.</dd>
  <dt id="EACCES"><a class="permalink" href="#EACCES"><b>EACCES</b></a></dt>
  <dd>Attempted to <b>write</b>(2) the process ID (PID) of a process to a cpuset
      <i>tasks</i> file when one lacks permission to move that process.</dd>
  <dt id="EACCES~2"><a class="permalink" href="#EACCES~2"><b>EACCES</b></a></dt>
  <dd>Attempted to add, using <b>write</b>(2), a CPU or memory node to a cpuset,
      when that CPU or memory node was not already in its parent.</dd>
  <dt id="EACCES~3"><a class="permalink" href="#EACCES~3"><b>EACCES</b></a></dt>
  <dd>Attempted to set, using <b>write</b>(2), <i>cpuset.cpu_exclusive</i> or
      <i>cpuset.mem_exclusive</i> on a cpuset whose parent lacks the same
      setting.</dd>
  <dt id="EACCES~4"><a class="permalink" href="#EACCES~4"><b>EACCES</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a <i>cpuset.memory_pressure</i> file.</dd>
  <dt id="EACCES~5"><a class="permalink" href="#EACCES~5"><b>EACCES</b></a></dt>
  <dd>Attempted to create a file in a cpuset directory.</dd>
  <dt id="EBUSY"><a class="permalink" href="#EBUSY"><b>EBUSY</b></a></dt>
  <dd>Attempted to remove, using <b>rmdir</b>(2), a cpuset with attached
      processes.</dd>
  <dt id="EBUSY~2"><a class="permalink" href="#EBUSY~2"><b>EBUSY</b></a></dt>
  <dd>Attempted to remove, using <b>rmdir</b>(2), a cpuset with child
    cpusets.</dd>
  <dt id="EBUSY~3"><a class="permalink" href="#EBUSY~3"><b>EBUSY</b></a></dt>
  <dd>Attempted to remove a CPU or memory node from a cpuset that is also in a
      child of that cpuset.</dd>
  <dt id="EEXIST"><a class="permalink" href="#EEXIST"><b>EEXIST</b></a></dt>
  <dd>Attempted to create, using <b>mkdir</b>(2), a cpuset that already
    exists.</dd>
  <dt id="EEXIST~2"><a class="permalink" href="#EEXIST~2"><b>EEXIST</b></a></dt>
  <dd>Attempted to <b>rename</b>(2) a cpuset to a name that already exists.</dd>
  <dt id="EFAULT"><a class="permalink" href="#EFAULT"><b>EFAULT</b></a></dt>
  <dd>Attempted to <b>read</b>(2) or <b>write</b>(2) a cpuset file using a
      buffer that is outside the writing processes accessible address
    space.</dd>
  <dt id="EINVAL"><a class="permalink" href="#EINVAL"><b>EINVAL</b></a></dt>
  <dd>Attempted to change a cpuset, using <b>write</b>(2), in a way that would
      violate a <i>cpu_exclusive</i> or <i>mem_exclusive</i> attribute of that
      cpuset or any of its siblings.</dd>
  <dt id="EINVAL~2"><a class="permalink" href="#EINVAL~2"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) an empty <i>cpuset.cpus</i> or
      <i>cpuset.mems</i> list to a cpuset which has attached processes or child
      cpusets.</dd>
  <dt id="EINVAL~3"><a class="permalink" href="#EINVAL~3"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a <i>cpuset.cpus</i> or <i>cpuset.mems</i>
      list which included a range with the second number smaller than the first
      number.</dd>
  <dt id="EINVAL~4"><a class="permalink" href="#EINVAL~4"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a <i>cpuset.cpus</i> or <i>cpuset.mems</i>
      list which included an invalid character in the string.</dd>
  <dt id="EINVAL~5"><a class="permalink" href="#EINVAL~5"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a list to a <i>cpuset.cpus</i> file that did
      not include any online CPUs.</dd>
  <dt id="EINVAL~6"><a class="permalink" href="#EINVAL~6"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a list to a <i>cpuset.mems</i> file that did
      not include any online memory nodes.</dd>
  <dt id="EINVAL~7"><a class="permalink" href="#EINVAL~7"><b>EINVAL</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a list to a <i>cpuset.mems</i> file that
      included a node that held no memory.</dd>
  <dt id="EIO"><a class="permalink" href="#EIO"><b>EIO</b></a></dt>
  <dd>Attempted to <b>write</b>(2) a string to a cpuset <i>tasks</i> file that
      does not begin with an ASCII decimal integer.</dd>
  <dt id="EIO~2"><a class="permalink" href="#EIO~2"><b>EIO</b></a></dt>
  <dd>Attempted to <b>rename</b>(2) a cpuset into a different directory.</dd>
  <dt id="ENAMETOOLONG"><a class="permalink" href="#ENAMETOOLONG"><b>ENAMETOOLONG</b></a></dt>
  <dd>Attempted to <b>read</b>(2) a <i>/proc/&lt;pid&gt;/cpuset</i> file for a
      cpuset path that is longer than the kernel page size.</dd>
  <dt id="ENAMETOOLONG~2"><a class="permalink" href="#ENAMETOOLONG~2"><b>ENAMETOOLONG</b></a></dt>
  <dd>Attempted to create, using <b>mkdir</b>(2), a cpuset whose base directory
      name is longer than 255 characters.</dd>
  <dt id="ENAMETOOLONG~3"><a class="permalink" href="#ENAMETOOLONG~3"><b>ENAMETOOLONG</b></a></dt>
  <dd>Attempted to create, using <b>mkdir</b>(2), a cpuset whose full pathname,
      including the mount point (typically "/dev/cpuset/") prefix, is
      longer than 4095 characters.</dd>
  <dt id="ENODEV"><a class="permalink" href="#ENODEV"><b>ENODEV</b></a></dt>
  <dd>The cpuset was removed by another process at the same time as a
      <b>write</b>(2) was attempted on one of the pseudo-files in the cpuset
      directory.</dd>
  <dt id="ENOENT"><a class="permalink" href="#ENOENT"><b>ENOENT</b></a></dt>
  <dd>Attempted to create, using <b>mkdir</b>(2), a cpuset in a parent cpuset
      that doesn't exist.</dd>
  <dt id="ENOENT~2"><a class="permalink" href="#ENOENT~2"><b>ENOENT</b></a></dt>
  <dd>Attempted to <b>access</b>(2) or <b>open</b>(2) a nonexistent file in a
      cpuset directory.</dd>
  <dt id="ENOMEM"><a class="permalink" href="#ENOMEM"><b>ENOMEM</b></a></dt>
  <dd>Insufficient memory is available within the kernel; can occur on a variety
      of system calls affecting cpusets, but only if the system is extremely
      short of memory.</dd>
  <dt id="ENOSPC"><a class="permalink" href="#ENOSPC"><b>ENOSPC</b></a></dt>
  <dd>Attempted to <b>write</b>(2) the process ID (PID) of a process to a cpuset
      <i>tasks</i> file when the cpuset had an empty <i>cpuset.cpus</i> or empty
      <i>cpuset.mems</i> setting.</dd>
  <dt id="ENOSPC~2"><a class="permalink" href="#ENOSPC~2"><b>ENOSPC</b></a></dt>
  <dd>Attempted to <b>write</b>(2) an empty <i>cpuset.cpus</i> or
      <i>cpuset.mems</i> setting to a cpuset that has tasks attached.</dd>
  <dt id="ENOTDIR"><a class="permalink" href="#ENOTDIR"><b>ENOTDIR</b></a></dt>
  <dd>Attempted to <b>rename</b>(2) a nonexistent cpuset.</dd>
  <dt id="EPERM"><a class="permalink" href="#EPERM"><b>EPERM</b></a></dt>
  <dd>Attempted to remove a file from a cpuset directory.</dd>
  <dt id="ERANGE"><a class="permalink" href="#ERANGE"><b>ERANGE</b></a></dt>
  <dd>Specified a <i>cpuset.cpus</i> or <i>cpuset.mems</i> list to the kernel
      which included a number too large for the kernel to set in its bit
    masks.</dd>
  <dt id="ESRCH"><a class="permalink" href="#ESRCH"><b>ESRCH</b></a></dt>
  <dd>Attempted to <b>write</b>(2) the process ID (PID) of a nonexistent process
      to a cpuset <i>tasks</i> file.</dd>
</dl>
</section>
<section class="Sh">
<h1 class="Sh" id="VERSIONS"><a class="permalink" href="#VERSIONS">VERSIONS</a></h1>
<p class="Pp">Cpusets appeared in Linux 2.6.12.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="NOTES"><a class="permalink" href="#NOTES">NOTES</a></h1>
<p class="Pp">Despite its name, the <i>pid</i> parameter is actually a thread
    ID, and each thread in a threaded group can be attached to a different
    cpuset. The value returned from a call to <b>gettid</b>(2) can be passed in
    the argument <i>pid</i>.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="BUGS"><a class="permalink" href="#BUGS">BUGS</a></h1>
<p class="Pp"><i>cpuset.memory_pressure</i> cpuset files can be opened for
    writing, creation, or truncation, but then the <b>write</b>(2) fails with
    <i>errno</i> set to <b>EACCES</b>, and the creation and truncation options
    on <b>open</b>(2) have no effect.</p>
</section>
<section class="Sh">
<h1 class="Sh" id="EXAMPLES"><a class="permalink" href="#EXAMPLES">EXAMPLES</a></h1>
<p class="Pp">The following examples demonstrate querying and setting cpuset
    options using shell commands.</p>
<section class="Ss">
<h2 class="Ss" id="Creating_and_attaching_to_a_cpuset."><a class="permalink" href="#Creating_and_attaching_to_a_cpuset.">Creating
  and attaching to a cpuset.</a></h2>
<p class="Pp">To create a new cpuset and attach the current command shell to it,
    the steps are:</p>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt>(1)</dt>
  <dd>mkdir /dev/cpuset (if not already done)</dd>
  <dt>(2)</dt>
  <dd>mount -t cpuset none /dev/cpuset (if not already done)</dd>
  <dt>(3)</dt>
  <dd>Create the new cpuset using <b>mkdir</b>(1).</dd>
  <dt>(4)</dt>
  <dd>Assign CPUs and memory nodes to the new cpuset.</dd>
  <dt>(5)</dt>
  <dd>Attach the shell to the new cpuset.</dd>
</dl>
<p class="Pp">For example, the following sequence of commands will set up a
    cpuset named "Charlie", containing just CPUs 2 and 3, and memory
    node 1, and then attach the current shell to that cpuset.</p>
<p class="Pp">
  <br>
</p>
<pre>$<b> mkdir /dev/cpuset</b>
$<b> mount -t cpuset cpuset /dev/cpuset</b>
$<b> cd /dev/cpuset</b>
$<b> mkdir Charlie</b>
$<b> cd Charlie</b>
$<b> /bin/echo 2-3 &gt; cpuset.cpus</b>
$<b> /bin/echo 1 &gt; cpuset.mems</b>
$<b> /bin/echo $$ &gt; tasks</b>
# The current shell is now running in cpuset Charlie
# The next line should display '/Charlie'
$<b> cat /proc/self/cpuset</b>
</pre>
<br>
</section>
<section class="Ss">
<h2 class="Ss" id="Migrating_a_job_to_different_memory_nodes."><a class="permalink" href="#Migrating_a_job_to_different_memory_nodes.">Migrating
  a job to different memory nodes.</a></h2>
<p class="Pp">To migrate a job (the set of processes attached to a cpuset) to
    different CPUs and memory nodes in the system, including moving the memory
    pages currently allocated to that job, perform the following steps.</p>
<p class="Pp"></p>
<dl class="Bl-tag">
  <dt>(1)</dt>
  <dd>Let's say we want to move the job in cpuset <i>alpha</i> (CPUs 4–7
      and memory nodes 2–3) to a new cpuset <i>beta</i> (CPUs
      16–19 and memory nodes 8–9).</dd>
  <dt>(2)</dt>
  <dd>First create the new cpuset <i>beta</i>.</dd>
  <dt>(3)</dt>
  <dd>Then allow CPUs 16–19 and memory nodes 8–9 in
    <i>beta</i>.</dd>
  <dt>(4)</dt>
  <dd>Then enable <i>memory_migration</i> in <i>beta</i>.</dd>
  <dt>(5)</dt>
  <dd>Then move each process from <i>alpha</i> to <i>beta</i>.</dd>
</dl>
<p class="Pp">The following sequence of commands accomplishes this.</p>
<p class="Pp">
  <br>
</p>
<pre>$<b> cd /dev/cpuset</b>
$<b> mkdir beta</b>
$<b> cd beta</b>
$<b> /bin/echo 16-19 &gt; cpuset.cpus</b>
$<b> /bin/echo 8-9 &gt; cpuset.mems</b>
$<b> /bin/echo 1 &gt; cpuset.memory_migrate</b>
$<b> while read i; do /bin/echo $i; done &lt; ../alpha/tasks &gt; tasks</b>
</pre>
<br>
<p class="Pp">The above should move any processes in <i>alpha</i> to
    <i>beta</i>, and any memory held by these processes on memory nodes
    2–3 to memory nodes 8–9, respectively.</p>
<p class="Pp">Notice that the last step of the above sequence did not do:</p>
<p class="Pp">
  <br>
</p>
<pre>$<b> cp ../alpha/tasks tasks</b>
</pre>
<br>
<p class="Pp">The <i>while</i> loop, rather than the seemingly easier use of the
    <b>cp</b>(1) command, was necessary because only one process PID at a time
    may be written to the <i>tasks</i> file.</p>
<p class="Pp">The same effect (writing one PID at a time) as the <i>while</i>
    loop can be accomplished more efficiently, in fewer keystrokes and in syntax
    that works on any shell, but alas more obscurely, by using the <b>-u</b>
    (unbuffered) option of <b>sed</b>(1):</p>
<p class="Pp">
  <br>
</p>
<pre>$<b> sed -un p &lt; ../alpha/tasks &gt; tasks</b>
</pre>
<br>
</section>
</section>
<section class="Sh">
<h1 class="Sh" id="SEE_ALSO"><a class="permalink" href="#SEE_ALSO">SEE
  ALSO</a></h1>
<p class="Pp"><b>taskset</b>(1), <b>get_mempolicy</b>(2), <b>getcpu</b>(2),
    <b>mbind</b>(2), <b>sched_getaffinity</b>(2), <b>sched_setaffinity</b>(2),
    <b>sched_setscheduler</b>(2), <b>set_mempolicy</b>(2), <b>CPU_SET</b>(3),
    <b>proc</b>(5), <b>cgroups</b>(7), <b>numa</b>(7), <b>sched</b>(7),
    <b>migratepages</b>(8), <b>numactl</b>(8)</p>
<p class="Pp"><i>Documentation/admin-guide/cgroup-v1/cpusets.rst</i> in the
    Linux kernel source tree (or <i>Documentation/cgroup-v1/cpusets.txt</i>
    before Linux 4.18, and <i>Documentation/cpusets.txt</i> before Linux
  2.6.29)</p>
</section>
</div>
<table class="foot">
  <tbody><tr>
    <td class="foot-date">(date)</td>
    <td class="foot-os">Linux man-pages (unreleased)</td>
  </tr>
</tbody></table>
</div>


<script id="res-script" src="/res/dist/res/main.js" type="text/javascript"></script>
</body></html>